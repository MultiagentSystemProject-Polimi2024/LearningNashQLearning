{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nash Q learning basic implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nashpy as nash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 4#Number of games\n",
    "N = 2 #Number of players\n",
    "A = 2 #Number of actions per player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player1 action / Player2 action / starting state / ending state / probability\n",
    "#Player 1 - column player - 0: .3, 1: .4\n",
    "#Player 2 - row player - 0: .1, 1: .2\n",
    "TRANSITION_MATRIX = np.array(\n",
    "    [\n",
    "        # Player 1 - Action 0\n",
    "        [\n",
    "            # Player 2 - Action 0 - .1 .3\n",
    "            [\n",
    "                \n",
    "                [0, 0.5, 0, 0.5],\n",
    "                [0, 1, 0, 0],\n",
    "                [0, 0, 1, 0],\n",
    "                [0.5, 0, 0, 0.5]\n",
    "                \n",
    "            ],\n",
    "\n",
    "            # Player 2 - Action 1 .2 .3\n",
    "            [\n",
    "                \n",
    "                [1, 0, 0, 0],\n",
    "                [0, 0, 1, 0],\n",
    "                [0, 0, 0, 1],\n",
    "                [0.5, 0, 0, 0.5]\n",
    "                \n",
    "            ]\n",
    "        ],\n",
    "\n",
    "        # Player 1 - Action 1\n",
    "        [\n",
    "            # Player 2 - Action 0 .1 .4\n",
    "            [\n",
    "                \n",
    "                [1, 0, 0, 0],\n",
    "                [0, 0, 0, 1],\n",
    "                [0, 0, 0, 1],\n",
    "                [0.5, 0, 0, 0.5]\n",
    "                \n",
    "            ],\n",
    "\n",
    "            # Player 2 - Action 1 .2 .4\n",
    "            [\n",
    "                \n",
    "                [0, 0.5, 0, 0.5],\n",
    "                [0, 0, 1, 0],\n",
    "                [0, 0, 0, 1],\n",
    "                [0.5, 0, 0, 0.5]\n",
    "                \n",
    "            ]\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSITION_MATRIX[0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state / player1 action / player2 action / [player1 reward, player2 reward]\n",
    "PAYOFF_MATRIX = np.array([\n",
    "    # State 0\n",
    "    [\n",
    "        [ [2, 1], [0, 0] ],\n",
    "        [ [0, 0], [1, 2] ]\n",
    "    ],\n",
    "    # State 1\n",
    "    [\n",
    "        [ [1, 1], [3, 0] ],\n",
    "        [ [0, 3], [2, 2] ]\n",
    "    ],\n",
    "    # State \n",
    "    [\n",
    "        [ [2, 0], [0, 2] ],\n",
    "        [ [0, 1], [1, 0] ]\n",
    "    ],\n",
    "    # State 33\n",
    "    [\n",
    "        [ [1, 1], [0, 0] ],\n",
    "        [ [0, 0], [2, 2] ]\n",
    "    ],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAYOFF_MATRIX[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_probability(state, player1_action, player2_action, next):\n",
    "    return TRANSITION_MATRIX[player1_action, player2_action, state, next]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(state, player1_action, player2_action):\n",
    "    return PAYOFF_MATRIX[state, player1_action, player2_action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "Total reward: [0.864 0.901]\n"
     ]
    }
   ],
   "source": [
    "state = 0\n",
    "totalReward = np.array([0, 0])\n",
    "n_games = 1000\n",
    "for _ in range(n_games):\n",
    "    print(\"State:\", state)\n",
    "    player1_action = np.random.choice(A, p=[0.5, 0.5])\n",
    "    player2_action = np.random.choice(A, p=[0.5, 0.5])\n",
    "    print(\"Player 1 action:\", player1_action)\n",
    "    print(\"Player 2 action:\", player2_action)\n",
    "    next_state = np.random.choice(range(Q), p=TRANSITION_MATRIX[player1_action, player2_action, state])\n",
    "    print(\"Next state:\", next_state)\n",
    "    r = reward(state, player1_action, player2_action)\n",
    "    print(\"Reward:\", r)\n",
    "    state = next_state\n",
    "    totalReward += r\n",
    "print(\"Total reward:\", totalReward / n_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeNashEq(state, payoff_matrix):\n",
    "    game = nash.Game(payoff_matrix[state, :, :, 0], PAYOFF_MATRIX[state, :, :, 1])\n",
    "    eqs = game.vertex_enumeration()\n",
    "\n",
    "    try:\n",
    "        eq = next(eqs)\n",
    "        return eq\n",
    "    except StopIteration:\n",
    "        a = np.random.rand()\n",
    "        b = np.random.rand()\n",
    "        return [[a, 1 - a], [b, 1 - b]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([0., 1.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeNashEq(3, PAYOFF_MATRIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 0\n",
      "Nash equilibrium: (array([0., 1.]), array([0., 1.]))\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "Total reward: [1.    1.001]\n"
     ]
    }
   ],
   "source": [
    "#Simulate plays with nash policy\n",
    "state = 0\n",
    "totalReward = np.array([0, 0])\n",
    "for _ in range(n_games):\n",
    "    print(\"State:\", state)\n",
    "    nashEq = computeNashEq(state, PAYOFF_MATRIX)\n",
    "    print(\"Nash equilibrium:\", nashEq)\n",
    "    player1_action = np.random.choice(A, p=nashEq[0])\n",
    "    player2_action = np.random.choice(A, p=nashEq[1])\n",
    "    print(\"Player 1 action:\", player1_action)\n",
    "    print(\"Player 2 action:\", player2_action)\n",
    "    next_state = np.random.choice(range(Q), p=TRANSITION_MATRIX[player1_action, player2_action, state])\n",
    "    print(\"Next state:\", next_state)\n",
    "    r = reward(state, player1_action, player2_action)\n",
    "    print(\"Reward:\", r)\n",
    "    state = next_state\n",
    "    totalReward += r\n",
    "print(\"Total reward:\", totalReward/n_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qTable = np.zeros((Q, A, A, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paolo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nashpy\\polytope\\polytope.py:109: RuntimeWarning: divide by zero encountered in divide\n",
      "  hs = HalfspaceIntersection(halfspaces, feasible_point)\n",
      "C:\\Users\\Paolo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nashpy\\polytope\\polytope.py:109: RuntimeWarning: invalid value encountered in divide\n",
      "  hs = HalfspaceIntersection(halfspaces, feasible_point)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.1123323784159036, 0.8876676215840964],\n",
       " [0.274774288142864, 0.725225711857136]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeNashEq(0, qTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectedPayoff(payoff_matrix, player1_strategy, player2_strategy):\n",
    "    expected_payoff = np.dot(np.dot(player1_strategy, payoff_matrix), player2_strategy)\n",
    "    return expected_payoff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2 1]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [1 2]]]\n"
     ]
    }
   ],
   "source": [
    "print(PAYOFF_MATRIX[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expectedPayoff(PAYOFF_MATRIX[2, :, :, 1], np.array([0.5, .5]), np.array([1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 0\n",
      "Nash equilibrium: [[0.3048923  0.6951077 ]\n",
      " [0.79629182 0.20370818]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.98989529 0.01010471]\n",
      " [0.29730659 0.70269341]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.0294879  0.9705121 ]\n",
      " [0.73394019 0.26605981]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.80282092 0.19717908]\n",
      " [0.92116299 0.07883701]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[1.  0.5]\n",
      "  [0.  0. ]]\n",
      "\n",
      " [[0.  0. ]\n",
      "  [0.  0. ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.3103629  0.6896371 ]\n",
      " [0.96498783 0.03501217]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[0.5 0.5]\n",
      "  [0.  0. ]]\n",
      "\n",
      " [[0.  0. ]\n",
      "  [0.  0. ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[0.95 0.95]\n",
      "  [0.   0.  ]]\n",
      "\n",
      " [[0.   0.  ]\n",
      "  [0.   0.  ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[0.95 0.95]\n",
      "  [0.   0.  ]]\n",
      "\n",
      " [[0.   1.5 ]\n",
      "  [0.   0.  ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.27643804 0.72356196]\n",
      " [0.17834787 0.82165213]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.  0. ]\n",
      "  [0.  0. ]]\n",
      "\n",
      " [[0.  0. ]\n",
      "  [1.4 1.2]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 1.11022302e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[1.88 1.13]\n",
      "  [0.   0.  ]]\n",
      "\n",
      " [[0.   0.  ]\n",
      "  [0.   0.  ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paolo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nashpy\\polytope\\polytope.py:109: RuntimeWarning: divide by zero encountered in divide\n",
      "  hs = HalfspaceIntersection(halfspaces, feasible_point)\n",
      "C:\\Users\\Paolo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nashpy\\polytope\\polytope.py:109: RuntimeWarning: invalid value encountered in divide\n",
      "  hs = HalfspaceIntersection(halfspaces, feasible_point)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QTable: [[[1.355 1.355]\n",
      "  [0.    0.   ]]\n",
      "\n",
      " [[0.    1.5  ]\n",
      "  [0.    0.   ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[1.7195 1.7195]\n",
      "  [0.     0.    ]]\n",
      "\n",
      " [[0.     1.5   ]\n",
      "  [0.     0.    ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[2.04755 2.04755]\n",
      "  [0.      0.     ]]\n",
      "\n",
      " [[0.      1.5    ]\n",
      "  [0.      0.     ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "QTable: [[[2.04755 2.04755]\n",
      "  [1.5     0.     ]]\n",
      "\n",
      " [[0.      1.5    ]\n",
      "  [0.      0.     ]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.62308709 0.37691291]\n",
      " [0.71292251 0.28707749]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "QTable: [[[1. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.74307286 0.25692714]\n",
      " [0.44162569 0.55837431]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "QTable: [[[1.54884191 0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.26143263 0.73856737]\n",
      " [0.92242644 0.07757356]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "QTable: [[[2.01819246 0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.39609873 0.60390127]\n",
      " [0.36532287 0.63467713]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[2.01819246 0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.56       0.98      ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.   0.  ]\n",
      "  [0.   0.  ]]\n",
      "\n",
      " [[0.   0.  ]\n",
      "  [2.26 2.08]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [2.50910404e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.    0.   ]\n",
      "  [0.    0.   ]]\n",
      "\n",
      " [[0.    0.   ]\n",
      "  [2.882 2.492]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[3.0928 2.0618]\n",
      "  [0.     0.    ]]\n",
      "\n",
      " [[0.     0.    ]\n",
      "  [0.     0.    ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.      0.     ]\n",
      "  [0.      0.     ]]\n",
      "\n",
      " [[0.      0.     ]\n",
      "  [3.67812 3.07072]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[3.36542 2.34992]\n",
      "  [0.      0.     ]]\n",
      "\n",
      " [[0.      0.     ]\n",
      "  [0.      0.     ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.68309289e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[2.342795 2.342795]\n",
      "  [1.5      0.      ]]\n",
      "\n",
      " [[0.       1.5     ]\n",
      "  [0.       0.      ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[2.6085155 2.6085155]\n",
      "  [1.5       0.       ]]\n",
      "\n",
      " [[0.        1.5      ]\n",
      "  [0.        0.       ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[2.84766395 2.84766395]\n",
      "  [1.5        0.        ]]\n",
      "\n",
      " [[0.         1.5       ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[2.84766395 2.84766395]\n",
      "  [1.5        0.        ]]\n",
      "\n",
      " [[1.471248   3.478288  ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.08353351e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.       0.      ]\n",
      "  [0.       0.      ]]\n",
      "\n",
      " [[0.       0.      ]\n",
      "  [4.185228 3.475328]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[3.82177558 2.81402558]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[3.06289756 3.06289756]\n",
      "  [1.5        0.        ]]\n",
      "\n",
      " [[1.471248   3.478288  ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[3.2566078 3.2566078]\n",
      "  [1.5       0.       ]]\n",
      "\n",
      " [[1.471248  3.478288 ]\n",
      "  [0.        0.       ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[3.43094702 3.43094702]\n",
      "  [1.5        0.        ]]\n",
      "\n",
      " [[1.471248   3.478288  ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.76139547e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[3.58785232 3.58785232]\n",
      "  [1.5        0.        ]]\n",
      "\n",
      " [[1.471248   3.478288  ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[3.72906709 3.72906709]\n",
      "  [1.5        0.        ]]\n",
      "\n",
      " [[1.471248   3.478288  ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "QTable: [[[3.72906709 3.72906709]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[1.471248   3.478288  ]\n",
      "  [0.         0.        ]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.06051724 0.93948276]\n",
      " [0.27891032 0.72108968]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "QTable: [[[2.01819246 0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.56       0.98      ]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [2.32326824e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.        0.       ]\n",
      "  [0.        0.       ]]\n",
      "\n",
      " [[0.        0.       ]\n",
      "  [4.7667052 4.1277952]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [2.64605293e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [4.91206283 4.18950783]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[4.40251462 3.39863962]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.17512017e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[3.85616038 3.85616038]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[1.471248   3.478288  ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.35149755e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[3.97054434 3.97054434]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[1.471248   3.478288  ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[3.97054434 3.97054434]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [2.72674263e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [5.21703727 4.45420977]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[4.78947505 3.78753755]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.07348991 4.07348991]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.16614092 4.16614092]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.24952682 4.24952682]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.32457414 4.32457414]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.39211673 4.39211673]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.0952864e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.45290505 4.45290505]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.50761455 4.50761455]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.55685309 4.55685309]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.60116778 4.60116778]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.64105101 4.64105101]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.67694591 4.67694591]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.70925131 4.70925131]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.73832618 4.73832618]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.76449357 4.76449357]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.78804421 4.78804421]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.80923979 4.80923979]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.82831581 4.82831581]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.84548423 4.84548423]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[2.70044913 4.91494713]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[4.84548423 4.84548423]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[3.43703947 5.73915747]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [5.69533354 5.00878879]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [3.16154521e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [5.76345679 5.01940941]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[5.33293122 4.33196247]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.86093581 4.86093581]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[3.43703947 5.73915747]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.87484222 4.87484222]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[3.43703947 5.73915747]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.887358   4.887358  ]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[3.43703947 5.73915747]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.8986222  4.8986222 ]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[3.43703947 5.73915747]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.90875998 4.90875998]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[3.43703947 5.73915747]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.91788398 4.91788398]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[3.43703947 5.73915747]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.92609559 4.92609559]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[3.43703947 5.73915747]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.93348603 4.93348603]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[3.43703947 5.73915747]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.94013742 4.94013742]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[3.43703947 5.73915747]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.94612368 4.94612368]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[3.43703947 5.73915747]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.95151131 4.95151131]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[3.43703947 5.73915747]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.95636018 4.95636018]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[3.43703947 5.73915747]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.87833149e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[4.95636018 4.95636018]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[4.02390245 6.3773425 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [6.18711111 5.51746847]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [6.22672804 5.49151922]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[6.15715682 4.86258892]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [6.57622675 5.69079518]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 3.41790864e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[6.06112248 4.91383853]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.96072416 4.96072416]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[4.02390245 6.3773425 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.96465175 4.96465175]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[4.02390245 6.3773425 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.96818657 4.96818657]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[4.02390245 6.3773425 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.97136792 4.97136792]\n",
      "  [2.29940502 0.03696427]]\n",
      "\n",
      " [[4.02390245 6.3773425 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "QTable: [[[4.97136792 4.97136792]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[4.02390245 6.3773425 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.33333333 0.66666667]\n",
      " [0.59854665 0.40145335]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[2.01819246 0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[2.9104907  3.26631807]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [3.65053918e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [6.71256237 5.810933  ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 3.36459887e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[6.71558619 5.28129247]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [7.04130613 6.2298397 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.81652245 2.49193588]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [7.04130613 6.2298397 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [3.9087101e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.81652245 2.49193588]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [7.33717552 6.60685573]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [4.0729506e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.81652245 2.49193588]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [7.35482224 6.41594485]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.29972199 5.70702418]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.81652245 2.49193588]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [7.61934001 6.77435037]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.22958336e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.81652245 2.49193588]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [7.7295588  6.66998485]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.05215971e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[6.63840816 5.34205925]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.97423112 4.97423112]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[4.02390245 6.3773425 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[4.97423112 4.97423112]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[5.10377475 7.35666519]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [8.58153415e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.81652245 2.49193588]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [7.52014267 6.47181613]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 3.68505679e-16]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.63840816 5.34205925]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[2.65536326 2.1368237 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 3.68505679e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[6.36071398 6.1136957 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[2.65536326 2.1368237 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[4.97423112 4.97423112]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[5.55994444 7.76705905]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.17451777e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.81652245 2.49193588]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [7.7681284  6.82463452]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [4.3121775e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.81652245 2.49193588]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [7.99131556 7.14217106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.43607127e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.81652245 2.49193588]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [8.192184   7.42795396]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.54757565e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.81652245 2.49193588]]\n",
      "\n",
      " [[3.2768736  2.97118158]\n",
      "  [8.192184   7.42795396]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.81652245 2.49193588]]\n",
      "\n",
      " [[3.2768736  2.97118158]\n",
      "  [8.3729656  7.68515856]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.1619824e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.81652245 2.49193588]]\n",
      "\n",
      " [[3.2768736  2.97118158]\n",
      "  [7.73076839 7.28805756]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 3.53090556e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.27266435 6.47207088]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[2.65536326 2.1368237 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.36429817e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.81652245 2.49193588]]\n",
      "\n",
      " [[3.2768736  2.97118158]\n",
      "  [7.95769155 7.55925181]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.52175774e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.81652245 2.49193588]]\n",
      "\n",
      " [[3.2768736  2.97118158]\n",
      "  [8.1619224  7.80332663]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.66347136e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.81652245 2.49193588]]\n",
      "\n",
      " [[3.2768736  2.97118158]\n",
      "  [7.99002694 7.49049166]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 4.0371397e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.83234295 6.7322321 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[2.65536326 2.1368237 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.54419492e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [4.54119841 3.93886078]]\n",
      "\n",
      " [[3.2768736  2.97118158]\n",
      "  [7.99002694 7.49049166]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.11218225 6.86231272]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[2.65536326 2.1368237 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [4.54119841 3.93886078]]\n",
      "\n",
      " [[3.2768736  2.97118158]\n",
      "  [8.23988637 7.49017092]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.50316576e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.2800689  7.03797998]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[2.65536326 2.1368237 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 7.71597292e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.21109334 6.09393918]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[5.55994444 7.76705905]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[5.21109334 6.09393918]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[6.07592677 8.37959789]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.71756973e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [4.54119841 3.93886078]]\n",
      "\n",
      " [[3.2768736  2.97118158]\n",
      "  [8.41589773 7.74115383]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [4.54119841 3.93886078]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.41589773 7.74115383]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.83970215e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [4.54119841 3.93886078]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.11997643 7.6857689 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.04125006e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.88802502 7.09329755]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[2.65536326 2.1368237 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.1268731e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [4.54119841 3.93886078]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.21519822 7.68020347]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.37438322 7.39848793]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[2.65536326 2.1368237 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[5.21109334 6.09393918]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[6.32404267 8.76188033]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [4.54119841 3.93886078]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.0573524  7.79949691]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.09360502e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.91013257 7.31904273]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[2.65536326 2.1368237 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.59091134e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.0573524  7.79949691]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.91013257 7.31904273]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[4.49173466 3.99602894]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.39100565e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.48468335 7.6642735 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[4.49173466 3.99602894]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[5.21109334 6.09393918]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[6.3849623  9.00073893]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.59091134e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.02254954 7.96545785]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.29632659 7.93243232]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[4.49173466 3.99602894]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[5.21109334 6.09393918]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[6.40150096 9.18655261]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.56676201e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.22029459 8.16891207]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.7039752e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.02867793 8.25742896]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.05027489e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.20876368 8.1408372 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[4.49173466 3.99602894]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[5.21109334 6.09393918]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[6.41222165 9.39624789]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.11420289e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.22581014 8.43168607]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.71234071e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.40322912 8.58851746]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.83091153e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.56290621 8.72966571]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.70661559 8.85669914]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20828564e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.23681327 8.68468445]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.20876368 8.1408372 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.1692705  8.32891776]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 8.89874515e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[5.21109334 6.09393918]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[6.50083613 9.67199773]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.71543734e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [7.98611484 8.67390933]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 3.97974459e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.77908119 8.13402261]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.10829607e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.10468989 8.59056371]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.13141655 8.00323679]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.62375833e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.30491157 8.49657657]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.51384294e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.3876729  7.90024902]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.76269002e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.47442041 8.64691891]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.88031041e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.59227936 8.48355907]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.6307482  7.84354814]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.96209149e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.74843896 8.37919879]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.81474968 7.77345358]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07044898e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[5.00479589 4.58205232]\n",
      "  [8.90011935 8.29898083]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.96742258 7.70631912]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17569839e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.90011935 8.29898083]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [9.03702871 8.23201806]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.08404575 8.22195865]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 9.02172244e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[5.21109334 6.09393918]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[6.86522955 9.62880609]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27069834e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [9.13332584 8.40881626]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.3375179e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [9.21999326 8.56793463]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.84361493 8.57275078]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.48754686e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.78811469 8.46250176]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[5.21109334 6.09393918]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[6.97006075 9.74350335]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.95925343 8.7154757 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [9.06332809 8.84392813]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [9.15699528 8.95953532]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.27078837e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.69374352 8.86476836]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.32327213e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.37155475 8.27715823]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.82436917 8.97829153]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.94193225 9.08046237]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.24094238e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.81958803 8.85109448]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.71361259 8.1790169 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.11981856e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.93762922 8.96598503]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [9.0438663  9.06938653]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27544287e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [9.00737819 8.80630002]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.83702666e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.14483059 8.48690979]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[5.21109334 6.09393918]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[7.08798165 9.89427169]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.25002483e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [9.10664037 8.92567002]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31900113e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.43465223 4.89704748]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.81125242 8.85759893]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.52128923e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.90760795 8.70116357]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.94073933 7.50467827]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[7.08798165 9.89427169]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[5.94073933 7.50467827]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[7.06849179 9.99017541]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.11403457e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.81125242 8.85759893]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.38960421e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.78120069 8.84665195]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.94073933  7.50467827]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.05874686 10.03812728]\n",
      "  [ 0.          0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.51810649 8.96746024]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.71409909 8.93857689]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.94073933  7.50467827]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.93661603 10.10604774]\n",
      "  [ 0.          0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.66629584 9.07071422]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01345074e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.41878756 9.11078787]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.63169596 9.01170754]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 9.62648853e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 5.94073933  7.50467827]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.93661603 10.10604774]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[2.01819246 0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[4.82276037 5.77747418]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.26207216 9.16007695]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.12067684 8.66988455]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.73296422e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.37930682 9.04799229]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.83498483 8.87736137]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.81324427e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.94073933  7.50467827]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.82003074 10.17222079]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.8143121e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.54137614 9.14319306]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.92677028e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.404682   9.12254108]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.64550471 9.007569  ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.73234697e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.94073933  7.50467827]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.77188817 10.23512682]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.83191967e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.5642138  9.21028697]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.70779242 9.28925827]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20844895e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.83701318 9.36033245]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13190969e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.95331186 9.4242992 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.53485782 9.3151772 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.24410768e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.53150762 9.09783523]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.94073933  7.50467827]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.79988721 10.34363429]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.68137203 9.38365948]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.02391195e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.81323483 9.44529353]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.93191135 9.50076418]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19775852e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [9.03872021 9.55068776]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.53196316 9.41447797]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.4857087  9.18637133]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.1293728  5.25434935]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.71836959e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.94073933  7.50467827]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.81272887 10.43760834]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.92023871e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.67876684 9.47303018]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.02210423e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.3336669  9.41106362]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.4857087  9.18637133]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.07632111 8.85761111]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.39736189 9.24857626]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.39710531 8.62823606]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.5576257  9.32371863]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.63765498 9.11315374]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.65361465 8.45937953]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99357715e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.77388948 9.20183836]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08810882e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [5.8803693  5.92898917]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.89650053 9.28165453]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23463747e-16 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.89650053 9.28165453]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17318733e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [9.00685048 9.35348908]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24975799e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.9648711  9.06049635]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.91275576 8.3538883 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [9.04753785 8.87180349]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.91275576 8.3538883 ]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.07539302 8.22566555]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [9.14278407 8.98462315]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [9.20154924 8.78257779]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.26278806 8.78787611]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.94073933  7.50467827]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.08698413 10.23183528]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [9.28139432 8.90432001]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [9.35325489 9.01388801]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.49012433e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.98174267 9.02209445]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.73346097e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.7240911  8.50277583]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.23233594e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.98050777 8.91215756]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.1968392  8.84412203]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.9175831e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.94073933  7.50467827]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.13569517 10.18078067]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.23147906e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.76898957 8.99372759]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.60601543 8.51955205]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08470882e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.06244569 5.61061849]\n",
      "  [8.89209061 9.09435483]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23402547e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.89209061 9.09435483]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.9716228e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.15728578 8.83208829]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.95138317e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.94073933  7.50467827]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.12468383 10.22813227]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23402547e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [9.00288155 9.18491935]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24700399e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [9.10259339 9.26642741]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31619298e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [9.19233405 9.33978467]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [9.27310065 9.40580621]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.89946464 9.23573842]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.66025406e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.92851642 9.00729705]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.94073933  7.50467827]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.12212777 10.3083615 ]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [9.00951817 9.31216458]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25160907e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [9.10856636 9.38094812]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.32033756e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.72568975 9.29339288]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.81310932 9.12699313]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.9419689e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.12212777 10.3083615 ]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.05133978 10.3715379 ]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.85312077 9.36405359]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14308658e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.9678087  9.42764823]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22266731e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [9.07102783 9.48488341]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.29428997e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.66075764 9.39323896]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.72709057 9.21211172]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.98997295 10.44306453]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20192157e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.42121505 9.38146417]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.23203131 8.85864153]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.16867836e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.50342005 9.2341887 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.91200483 9.10654658]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.85026807e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.89635449 10.41520774]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.41651196 9.25971298]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.71454421 9.21935639]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.78530722e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.81478203 10.41148906]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.84012835e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.57486076 9.33374168]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.37324807 9.3546134 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.35304038e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.58318492 9.27427382]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.72870495e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.75669024 10.44758989]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.000000e+00 1.000000e+00]\n",
      " [5.810108e-17 1.000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.53592326 9.41915206]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.68233093 9.47723685]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.02457732e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.81409784 9.52951317]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.11600898e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.93268806 9.57656185]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23965949e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.499618   9.49799045]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.19143966 8.93633309]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.6496562  9.54819141]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20038093e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.60140396 9.34862894]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.53628141 8.70761812]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.96842295e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.47362901 6.21313007]\n",
      "  [8.74126356 9.41376605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.06547005e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.65132707 6.58961228]\n",
      "  [8.74126356 9.41376605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.76464613 8.61931548]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.06547005e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.74126356 9.41376605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.08499916 8.9886937 ]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.87485055 10.48930136]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.60463145 9.3023605 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.7924398  9.19006739]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.87927785 10.46559488]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.19413249e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.7441683  9.37212445]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.06748561e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.86975147 9.43491201]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.98277633 9.49142081]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.24661064e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.08449869 9.54227872]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.30363726e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.17604882 9.58805085]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.70500033 9.47005238]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.4070913e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.37822003 8.88305465]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[5.55896988 6.30172321]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04030737e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.70378818 9.28824805]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.81355799e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.37822003 8.88305465]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.67062529 8.65682655]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03946627e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.83340936 9.35942325]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12940904e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.8849548  9.14244224]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.0164549e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.08702378 9.01465123]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.77345792e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.99362084 10.38977434]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16517587e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.67728691 9.17708161]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.84096023 9.16323535]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.8527993e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.96772519 10.36571981]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.02107733e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.80955822 9.25937345]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.9286024  9.3334361 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.60068529 9.33201219]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.36075423 8.81442255]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.64464434 9.19177512]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.96746719 9.0534992 ]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.83483058e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.94172033 10.35956995]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99842699e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.7801799  9.2725976 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09247368e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.90216191 9.34533784]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.1771157e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.63806783 9.2940686 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.76042173 9.17057758]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.81678609e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.9260873  10.39741242]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99386362e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.77426105 9.36466174]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.89683494 9.42819557]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.00715145 9.48537601]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.60774442 9.41091904]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.65064578 9.24425376]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.80593849e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.90614142 10.46307382]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.97282253e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.36413052 9.40316102]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.30870194e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.58777946 9.30735641]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.79872292 10.49280132]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.21717704 9.42452307]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.08076055 8.92348743]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.34089274 9.28165651]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.75986944 9.15886425]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.7175617e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.73571855 10.45906326]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.78765698e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.50680347 9.35349086]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.35734951 9.34029113]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.38449107e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.22287452 8.81554857]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.52161456 9.40626202]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.91305793e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.6694531  9.46563581]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.62387636 9.25903734]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.70576539e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.80572468 9.09139959]\n",
      "  [3.5651023  3.34155532]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.67384364e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.81740982 10.43314657]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.98401631e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.43422805 9.26607851]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.80572468 9.09139959]\n",
      "  [4.90484103 5.3073375 ]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.62982627 9.21895842]\n",
      "  [4.90484103 5.3073375 ]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.73052834e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.78239613 10.42300469]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.85242136e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.26904453 9.32062262]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.12253095 8.83772826]\n",
      "  [4.90484103 5.3073375 ]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.73780227e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.44214008 9.38856036]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.47008242 9.22937148]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.77422393 9.088066  ]\n",
      "  [4.90484103 5.3073375 ]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.77923103 10.40325094]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.62307418 9.30643434]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.76076676 9.3757909 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07900311e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.49007295 9.32312185]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.3944515e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.28314114 8.77328174]\n",
      "  [4.90484103 5.3073375 ]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.64106566 9.39080967]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99594378e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.63378929 9.20471753]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.74758376e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.59508629 8.56852788]\n",
      "  [4.90484103 5.3073375 ]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99089478e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.75492916 9.02976992]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.96403918e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.79951481 8.39617191]\n",
      "  [4.90484103 5.3073375 ]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07495246e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.87943624 9.12679293]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.99149262 9.21411363]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.23910133e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.09234336 9.29270227]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.30908059e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.49878486 6.6771564 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.18310902 9.36343204]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.18310902 9.36343204]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.37206192e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.26479812 9.42708884]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.42874512e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.15220498 9.07201318]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.11144982 8.85938633]\n",
      "  [4.90484103 5.3073375 ]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.70403649e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.05049751 10.33043074]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.23698448 9.16481187]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.28188911e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.31328604 9.24833068]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.29247807e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.90122294 9.16791987]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.61621409 8.59686111]\n",
      "  [4.90484103 5.3073375 ]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17646416e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.01110065 9.25112788]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.95203596 9.06430839]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.61621409 8.59686111]\n",
      "  [5.89890615 6.09241319]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.88892143 8.42415391]\n",
      "  [5.89890615 6.09241319]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.03158655 8.90181576]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.05709533 8.27280326]\n",
      "  [5.89890615 6.09241319]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.26692209e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.1284279  9.01163418]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.33411927e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.18705208 8.81493839]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.2033685  8.16237699]\n",
      "  [5.89890615 6.09241319]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.37479797e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.27487344 8.67241999]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.42188325 8.71336079]\n",
      "  [5.89890615 6.09241319]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.23519813 10.13418337]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.28714726e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.3473861  8.80517799]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.48605204e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.04244635 8.88793331]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.82792017 8.41185372]\n",
      "  [5.89890615 6.09241319]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.05239124 8.80870814]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.03491658 8.22941012]\n",
      "  [5.89890615 6.09241319]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.28135824e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.14016225 8.69611812]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.17352319 8.09315231]\n",
      "  [5.89890615 6.09241319]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.22614603 8.82650631]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.30353142 8.94385568]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.45562175e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.37317828 9.04947011]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.50394896e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.43586045 9.1445231 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.49227441 9.23007079]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.41554648 8.85229632]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[9.17352319 8.09315231]\n",
      "  [6.61886235 6.28346752]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[9.17352319 8.09315231]\n",
      "  [6.97884045 6.37899468]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.48084085 8.6002495 ]\n",
      "  [6.97884045 6.37899468]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.02042722e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.38381766 10.10801021]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.53334781e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.10010958 8.86624796]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.48084085 8.6002495 ]\n",
      "  [6.88175656 6.62959714]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.48084085 8.6002495 ]\n",
      "  [6.83321462 6.75489837]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.19394749 8.84332883]\n",
      "  [6.83321462 6.75489837]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.33195266 10.10050429]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31446949e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.92263604 7.08395102]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.19009862 8.97962316]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.27538239e-16 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.19009862 8.97962316]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.19394749 8.84332883]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.77301319 8.51351368]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.10425459 8.89521705]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.31928766 8.79695856]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.30767817 10.10833897]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31734567e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.19382913 9.00569535]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.27444622 9.10512581]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.34700159 9.19461323]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.41230143 9.27515191]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.5310961e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.03386578 9.15635938]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.0827151  8.94181486]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.07072035e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.2673854  10.21671323]\n",
      "  [ 2.16419628  2.30652723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.75001893 9.15490563]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.94831171 9.05759273]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.13077295 6.70408346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.04276162e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.2673854  10.21671323]\n",
      "  [ 4.01120229  4.46425329]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[4.82276037 5.77747418]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[5.91138776 7.05069934]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.0715453e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.87501704 9.23941507]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23165603e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.98751533 9.31547356]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.24726831e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.67308235 9.28077387]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.94831171 9.05759273]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.24471116 6.97507882]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.94831171 9.05759273]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.30168026 7.1105765 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.88111001 9.11548166]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.30168026 7.1105765 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.10292564 10.32066617]\n",
      "  [ 4.01120229  4.46425329]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20363196e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.80577411 9.35269649]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22204665e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.9251967  9.41742684]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.61504236 9.35490608]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.78172526 9.18600729]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.30168026 7.1105765 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.92864474e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.99747976 10.40229552]\n",
      "  [ 4.01120229  4.46425329]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.97788649e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.42021128 9.35185596]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.25894714 8.83374603]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.30168026 7.1105765 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.84269527e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.57819015 9.41667036]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.19046303e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.59267393 9.24183359]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.92846548 9.07779122]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.30168026 7.1105765 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.93580945 10.3978812 ]\n",
      "  [ 4.01120229  4.46425329]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.73889701 7.07930704]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.46772316 9.25203329]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.73855652 9.19804809]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.30168026 7.1105765 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.81268459e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.85499399 10.39975391]\n",
      "  [ 4.01120229  4.46425329]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.87566326e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.75653777 7.24046683]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.46772316 9.25203329]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.87566326e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.75653777 7.24046683]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.32928419 9.30523588]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.36970227e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.20099193 8.8211184 ]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.30168026 7.1105765 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.77960193e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.75653777 7.24046683]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.44503887 9.1810653 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.84249356 9.07046076]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.30168026 7.1105765 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.80551254 10.37230307]\n",
      "  [ 4.01120229  4.46425329]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.75653777 7.24046683]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.35951686 9.21871695]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.26505353 8.72271716]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.30168026 7.1105765 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.80058006e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.75653777 7.24046683]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.48577984 9.09844534]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.5268387  8.50073672]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.30168026 7.1105765 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.77258082 7.25961155]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.48577984 9.09844534]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.77258082 7.25961155]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.6536254  8.94951736]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.5268387  8.50073672]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.56157561 6.95558294]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.72486951 8.3301753 ]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.56157561 6.95558294]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.77258082 7.25961155]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.78826286 9.05456562]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09808236e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.77258082 7.25961155]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.88407923 8.85935293]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.91606645 8.20882882]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.56157561 6.95558294]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.77258082 7.25961155]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.99567131 8.97341764]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.77258082 7.25961155]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.06426223 8.77024035]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.18676391e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.08373812 8.11251055]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.56157561 6.95558294]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.25791908e-16 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.06426223 8.77024035]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.16562636 8.6301244 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.2081196  8.00830503]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.56157561 6.95558294]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.24906373 8.76711196]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.41782719e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.32415735 8.89040076]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.46993386e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.34532652 8.64852239]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.34219041 7.96356147]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.56157561 6.95558294]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.40953942 8.50968579]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.43491097 7.88565505]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.56157561 6.95558294]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.52917957e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.46858548 8.65871721]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.50825713 8.48362062]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.4396605  8.59174876]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.56157561 6.95558294]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.72227295e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.20605912 10.07959979]\n",
      "  [ 4.01120229  4.46425329]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.59767874e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.55743142 8.63525856]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.60168828 8.77173271]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.66250962e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.17670834 8.82256586]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.1022539  8.82771429]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.56157561 6.95558294]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.00020797e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.2737129  10.06882624]\n",
      "  [ 4.01120229  4.46425329]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.27352411e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.82925573 8.94236864]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.1022539  8.82771429]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.52168937 7.00887719]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.58282924 8.4908046 ]\n",
      "  [6.69418631 6.91478072]]\n",
      "\n",
      " [[6.52168937 7.00887719]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12652688e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.84775956 8.86750616]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.58282924 8.4908046 ]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.52168937 7.00887719]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.20089978 8.7729328 ]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.52168937 7.00887719]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.17596027 10.08141558]\n",
      "  [ 4.01120229  4.46425329]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13936649e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.70423969 8.9429262 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.69051735e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.58214577 8.46363688]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.52168937 7.00887719]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20795591e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.83381572 9.04863358]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12969101e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.95043415 9.14377022]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.05539074 9.2293932 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.28343956e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.0119953  7.13790192]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.96055368 9.00015135]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.87529435 8.33187898]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.52168937 7.00887719]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.09021912 7.1690115 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [8.96055368 9.00015135]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.21763313e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.09021912 7.1690115 ]]\n",
      "\n",
      " [[6.83152199 6.74253233]\n",
      "  [9.03039458 8.83282727]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.04980501 8.1990704 ]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.52168937 7.00887719]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.26609499e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.09021912 7.1690115 ]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.03039458 8.83282727]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.13706034 8.13266611]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.52168937 7.00887719]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.09021912 7.1690115 ]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.12735512 8.94954454]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.09021912 7.1690115 ]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.21850169 8.72783871]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.25593085 8.05746854]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.52168937 7.00887719]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.39662052e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.09021912 7.1690115 ]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.29665153 8.85505484]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.09021912 7.1690115 ]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.36698637 8.96954936]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.49965246e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.09021912 7.1690115 ]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.38586552 8.70776209]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.49834953 8.5613005 ]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.52168937 7.00887719]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.17596027 10.08141558]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[6.71004009 7.50845451]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.51275251e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.09021912 7.1690115 ]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.44727897 8.83698588]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.09021912 7.1690115 ]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.50255108 8.9532873 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.59371937e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.09021912 7.1690115 ]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.55229597 9.05795857]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.62823683e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.09021912 7.1690115 ]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.1754878  8.95349948]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.91936988 8.36205004]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.52168937 7.00887719]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.09021912 7.1690115 ]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.15549185 8.82156976]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.12188168 8.20965293]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.52168937 7.00887719]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.35289866e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.09021912 7.1690115 ]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.23994267 8.93941278]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.09021912 7.1690115 ]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.26872401 8.75356756]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.26843044 8.10625349]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.52168937 7.00887719]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.43146925e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.26872401 8.75356756]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.50459933 8.58569298]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.52168937 7.00887719]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.29546974 10.04213482]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.43146925e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.34185161 8.87821081]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.29644234e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.40766645 8.99038973]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.52787993e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.4668998  9.09135075]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.13528963 8.97995257]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.50459933 8.58569298]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.66268442 6.93871578]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.17048756 8.80970042]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.66268442 6.93871578]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.30185072 10.11304844]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.33888055e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.22176067 9.08195731]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.2995846  9.17376158]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.36962614 9.25638542]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.43266353 9.33074688]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.48939718 9.39767219]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.58459202e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [9.01289361 9.22271626]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.66941463e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.00598407 8.95006958]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.66268442 6.93871578]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.25608281 10.24561072]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.25079025e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [8.70884043 9.19138596]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.55526741e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.48652821 8.65158918]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.66268442 6.93871578]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04297198e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [8.7490315  9.05632865]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.88871189e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.7428767  8.44832605]\n",
      "  [6.78022485 6.8537122 ]]\n",
      "\n",
      " [[6.66268442 6.93871578]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07086013e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [8.87166643 8.90749475]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.7428767  8.44832605]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[6.66268442 6.93871578]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.27387147 8.82240731]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[6.66268442 6.93871578]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.17670798 10.18580326]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15595521e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.035683   6.65089433]\n",
      "  [8.98449979 9.01674527]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[6.82739009 6.85441009]\n",
      "  [8.98449979 9.01674527]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.73073565 8.51790177]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[6.66268442 6.93871578]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.23424908e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[6.82739009 6.85441009]\n",
      "  [9.08604981 9.11507074]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[6.82739009 6.85441009]\n",
      "  [9.17744483 9.20356367]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.3681316e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[6.82739009 6.85441009]\n",
      "  [9.25970035 9.2832073 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.42520783e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[6.82739009 6.85441009]\n",
      "  [9.33373031 9.35488657]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.47657644e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[6.82739009 6.85441009]\n",
      "  [9.15915942 9.08460399]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.02903159 8.39279248]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[6.66268442 6.93871578]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.35544354e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.02530768 6.78432204]\n",
      "  [9.15915942 9.08460399]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.17817956 8.33023784]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[6.66268442 6.93871578]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.35544354e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.02530768 6.78432204]\n",
      "  [9.24324348 9.17614359]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.02530768 6.78432204]\n",
      "  [9.29289356 8.92016693]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.30624721 8.23318569]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[6.66268442 6.93871578]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.25248174 6.82700714]]\n",
      "\n",
      " [[7.02530768 6.78432204]\n",
      "  [9.36894566 8.75335774]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.52380679 8.69091415]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[6.66268442 6.93871578]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.33593225 10.09424473]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.03576359 6.88986923]]\n",
      "\n",
      " [[7.02530768 6.78432204]\n",
      "  [9.36894566 8.75335774]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.1962763  8.88315497]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[6.66268442 6.93871578]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.09032556e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.41554439 10.04846546]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.000000e+00 1.000000e+00]\n",
      " [6.501012e-17 1.000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.03576359 6.88986923]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.36894566 8.75335774]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.68730916e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.84571641 8.44292058]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[6.66268442 6.93871578]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.000000e+00 1.000000e+00]\n",
      " [6.501012e-17 1.000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.03576359 6.88986923]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.4320511  8.87802197]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.54480019e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.03576359 6.88986923]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.48884599 8.99021977]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.03576359 6.88986923]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.28270956 8.87227812]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.13794877e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.84571641 8.44292058]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[6.86962877 6.84652612]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.13594203 8.27037154]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[6.86962877 6.84652612]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.03576359 6.88986923]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.29573159 8.74428767]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.28626365 8.13290084]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[6.86962877 6.84652612]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.03576359 6.88986923]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.36237126 8.62530417]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.44363983e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.38808033 8.01657209]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[6.86962877 6.84652612]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.03576359 6.88986923]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.43641776 8.51928092]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.46860727 7.91599841]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[6.86962877 6.84652612]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.54783017e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.03576359 6.88986923]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.49277598 8.66735283]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.58693654e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.03576359 6.88986923]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.54349839 8.80061755]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.03576359 6.88986923]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.58914855 8.92055579]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.65380844e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.03576359 6.88986923]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.63023369 9.02850021]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.68231699e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.03576359 6.88986923]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.66721032 9.12565019]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.03576359 6.88986923]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.70048929 9.21308517]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.7310666e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.03576359 6.88986923]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.63768755 8.77294195]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.58937866 7.96717599]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[6.86962877 6.84652612]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.68748914e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.35363326 6.63180501]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.63768755 8.77294195]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[9.58937866 7.96717599]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.27056585 6.61013346]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.76090708 8.50297418]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.27056585 6.61013346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.56284722 10.03340951]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.35363326 6.63180501]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.6739188  8.89564776]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.71262962e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.35363326 6.63180501]]\n",
      "\n",
      " [[6.79116436 6.945423  ]\n",
      "  [9.70652692 9.00608298]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.35363326 6.63180501]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [9.70652692 9.00608298]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.73525605e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [9.70652692 9.00608298]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.40559243 8.76485089]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.27056585 6.61013346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.24777945e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.66403438 10.11913795]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.73525605e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [9.21550043 9.00898185]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.83255141e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.26840997 8.93008063]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.27056585 6.61013346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.51821736 10.16316171]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [9.29395039 9.10808366]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.28979471e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [9.36455535 9.1972753 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.4979656e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.98964166 9.1706699 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.14149193 9.030305  ]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.27056585 6.61013346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.21681126e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.35496534 10.24984882]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.23781697e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.7514176  9.19745695]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.0127321  9.11509203]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.27056585 6.61013346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.10353242e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.17804971 10.30390719]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07251582e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.58080164 9.24476528]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.43868671 8.75545213]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.27056585 6.61013346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.95412722e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.72272148 9.32028876]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.85044933 9.38825988]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.9654044  9.44943389]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.85817688 9.2268978 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.76261411 8.56848518]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.27056585 6.61013346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22931899e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.93413408 9.04084297]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.25252694 8.90580547]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.27056585 6.61013346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.16267849 10.26829078]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.76807782 9.08274367]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.99133486 9.06021905]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.27056585 6.61013346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.97010661e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.08857037 10.26724286]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08407617e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.89127003 9.1744693 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16955794e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.64216896 9.21132227]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.54510248e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.83109558 9.13700667]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.27056585 6.61013346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.00115277 10.31815034]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99670935e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.45352271 9.2604638 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.7160089  9.19576347]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.27056585 6.61013346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.88198547 10.36326069]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.17316194e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.60817044 9.33441742]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.97311814e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.7473534  9.40097568]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.06969572e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.87261806 9.46087811]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15661554e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [7.18117946 6.71709218]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.98535625 9.5147903 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.98535625 9.5147903 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.61079864 9.24318601]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.27056585 6.61013346]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.7753367e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.03513524 10.48754647]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.53699758 9.45466955]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.22019835 8.90346083]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.27056585 6.61013346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.92373205e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.55657813 9.28871911]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.70390842e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.53273043 8.66721806]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.27056585 6.61013346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.70092032 9.3598472 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20749526e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.83082829 9.42386248]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12761806e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.94774546 9.48147623]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20874564e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.8869649  9.20762534]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.82115117 8.51665916]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.27056585 6.61013346]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23331413e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.99826841 9.2868628 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24380298e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [9.02759467 9.05009507]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.12090321e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.82115117 8.51665916]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.16374339 6.71173039]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.02161346 8.37836761]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.16374339 6.71173039]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.26415217e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [9.12244272 8.87639458]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.15978382 8.23974164]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.16374339 6.71173039]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [9.21019845 8.98875512]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.39085899e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [9.2891786  9.08987961]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.44566248e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [9.30850283 8.84083646]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.35587681e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[9.15978382 8.23974164]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.393946   8.8148894 ]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.24096875 10.28010782]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.45907135e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [9.01182982 8.94637399]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.0933605  9.01948783]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.2252163  10.2186035 ]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2532131e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [9.11064683 9.05173659]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.26435624e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.79266762 9.13366343]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.61589698e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.5637473  8.66320928]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.91340086 9.22029708]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.88219935 9.07543226]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.94229339e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.17196017 8.91904604]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.01350093e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.16548789 10.23947465]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16326389e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.99397941 9.16788903]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24082689e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.76577377 9.15156293]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.95217524 9.05531288]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.08905345 10.2803625 ]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08247742e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.8891964  9.23640664]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23362381e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.62546829 9.24032847]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.42627494 8.72378783]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.68324412 9.10967937]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.68643512 8.50576566]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20504219e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.81491971 9.19871143]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.8820339  9.00166198]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.89603112 8.35354762]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16314909e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.27819295 7.07514469]\n",
      "  [8.99383051 9.10149578]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24072357e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [8.99383051 9.10149578]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24072357e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [9.09444746 9.1913462 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.3105406e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [9.18500271 9.27221158]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.37337593e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [9.15091381 8.97752484]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.10838108 8.26778375]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [9.23582242 9.07977236]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.40863919e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [9.26126365 8.84699968]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.38981192 8.74603687]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.24903219 10.17898112]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.42629258e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [8.98655659 8.92191459]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.09451884 8.94461089]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.21913873 10.1582564 ]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [8.73108583 9.03880165]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.61670074e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.53969375 8.5878261 ]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05840782e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [8.78142041 8.95453127]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.92560289e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.15750237 8.85721561]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.00928377e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.12213753 10.1609407 ]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [8.78142041 8.95453127]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.9276062  8.99298409]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.07363693 10.16228286]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09333446e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [8.90327837 9.05907814]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.1778904e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [8.62268166 9.1267327 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.79325787 9.06140519]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.90832162e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.98589113 10.23183451]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.98318732e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [8.7604135  9.21405943]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07875798e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [8.88437215 9.29265349]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [8.99593493 9.36338814]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24218381e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [9.09634144 9.42704933]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [9.1867073  9.48434439]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [8.7106568  9.36673427]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.69098539 9.1234364 ]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.97720828 10.36261096]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.67699329 7.03685148]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [8.83959112 9.43006084]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13369849e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87433309 7.29045008]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [8.83959112 9.43006084]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13369849e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87433309 7.29045008]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [8.955632   9.48705476]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.24284361e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87433309 7.29045008]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [9.0600688  9.53834928]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.28668562e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87433309 7.29045008]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [9.15406192 9.58451436]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.27038129e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87433309 7.29045008]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [9.23865573 9.62606292]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.13262884 7.49565021]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [9.23865573 9.62606292]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.41060519e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.13262884 7.49565021]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [8.69572202 9.46240602]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.3237815  8.84668061]\n",
      "  [6.88726311 6.80618652]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03386925e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[7.23662868 7.17817066]\n",
      "  [8.69572202 9.46240602]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03386925e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.69572202 9.46240602]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.3237815  8.84668061]\n",
      "  [6.77314415 6.9417655 ]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.95277406 9.06838469]\n",
      "  [6.77314415 6.9417655 ]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.96689295 10.46626789]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.52897064 9.35855689]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.76314421 9.2206995 ]\n",
      "  [6.77314415 6.9417655 ]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.8342531e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.89503473 10.4765567 ]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.67607357 9.4227012 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.0202354e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.80846622 9.48043108]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22242025e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.92761959 9.53238797]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.2389561e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.56906748 9.45447378]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.3091991  8.89213926]\n",
      "  [6.77314415 6.9417655 ]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.94598501e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.60821338 9.2840926 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.7656651e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.5978849  8.65970667]\n",
      "  [6.77314415 6.9417655 ]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.74739204 9.35568334]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.06972253e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.81284998 9.14172434]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.82408244 8.48654307]\n",
      "  [6.77314415 6.9417655 ]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.1151431e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.93156498 9.2275519 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19751818e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.99541547 9.00839318]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.12293719e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.01020741 8.34662881]\n",
      "  [6.77314415 6.9417655 ]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [9.1017907  8.84284811]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.14581998 8.21045365]\n",
      "  [6.77314415 6.9417655 ]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [9.19161163 8.9585633 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [9.27245047 9.06270697]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [9.29455323 8.81553495]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.34618745e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.33092388 8.7958495 ]\n",
      "  [6.77314415 6.9417655 ]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.78439145e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.16533866 10.26449233]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.97964617 8.92610727]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.7807397e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.0315974  9.00372168]\n",
      "  [6.77314415 6.9417655 ]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.17452779 10.20268907]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2308812e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.70246205 9.06454231]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.88560982 9.08293647]\n",
      "  [6.77314415 6.9417655 ]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.97832872e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.06824872 10.22716146]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03854608e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.83221584 9.15808808]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12858087e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.57035185 9.21221863]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.7701044  9.13233282]\n",
      "  [6.77314415 6.9417655 ]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.90458279e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.9622651  10.29846818]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.94687622e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.71331666 9.29099677]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.841985   9.36189709]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13535958e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.9577865  9.42570738]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.21571301e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.58693501 9.36578682]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.7701044  9.13233282]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.000000e+00 0.000000e+00]\n",
      " [1.000000e+00 5.391593e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.3198262  8.81248114]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.9583831e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.72824151 9.42920814]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05643418e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.69205123 9.23959652]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.94481914 9.02562784]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.83104188e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.95795304 10.3450727 ]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.04460323 7.53278751]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.52395327 9.2300494 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.75559079 9.150843  ]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.82804979e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.88855783 10.36455611]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.91468074e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.62453793 7.42673096]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.52395327 9.2300494 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.63321853 9.22124394]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.85386022 10.37429781]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.62453793 7.42673096]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.31526405 9.30352228]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.55815335 9.2603411 ]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.75582089e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.75303573 10.40855782]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.1539747e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.62453793 7.42673096]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.18089336 9.35589758]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.48029097 9.29359368]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.68585985e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.64887521 10.44663794]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.67663511e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.62453793 7.42673096]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.08256307 9.39538626]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.39969557 9.32545201]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.61358397e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.55746283 10.48147347]\n",
      "  [ 5.37015625  6.05240638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.60840476e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.62453793 7.42673096]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.27430676 9.45584763]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.62453793 7.42673096]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.09703161 9.45810462]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.93866043 8.94596786]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.62453793 7.42673096]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.28732845 9.51229416]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.75048928e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.62453793 7.42673096]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.4585956  9.56106474]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.86932975e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.4585956  9.56106474]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.35276846 8.79740983]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.86932975e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.61273604 9.60495827]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.75146244 9.64446244]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.87631619 9.6800162 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.77926548 9.35897203]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.79589741e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.79936936 9.0912943 ]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.55015389e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.55746283 10.48147347]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[6.86672624 7.99781607]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.21836783e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.50938048 9.31600374]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.30343687 8.77204865]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.90456884e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.65844244 9.38440336]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.79259819 9.44596303]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22021812e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.91333837 9.50136672]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.18487093e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [9.02200454 9.55123005]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [9.11980408 9.59610705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.88127679 9.30687298]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.76166675e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.70422915 8.60877351]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16262374e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.92233006 9.0969459 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.97509971 8.99697615]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.55015389e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.84766344 10.3795151 ]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19111016e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [9.03009705 9.18725131]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.26588854e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.70508841 9.19241611]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.46958522 8.67545452]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04036849e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.83457957 9.2731745 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.95112161 9.34585705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.21108832e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.86339489 9.14311033]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.87695532e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.97385799 8.9895333 ]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.96918968 10.34700168]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23004314e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.9770554  9.2287993 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.6780709  9.21021297]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.45815735 8.67885184]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20432426e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.81026381 9.28919167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.11334858e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.92923743 9.3602725 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.94782694 7.12775757]\n",
      "  [8.84788165 9.15167699]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.76823134 8.50009671]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13945121e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.84788165 9.15167699]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.92326833 8.41071915]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.96309349 9.23650929]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [9.05085408 8.9825423 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.24931004 8.84416025]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.31922077  8.37568373]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.10493647 10.26651776]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.28029162e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.82515105 9.02893525]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.96662961 9.02868723]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.93004004e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.10493647 10.26651776]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.08252866 10.24483298]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12367868e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.59922737 9.12594252]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.42300575 8.66472062]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.73930463 9.21334827]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.73885462 9.07256238]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.70704472 8.46138526]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.0637985e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.86496915 9.16530614]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.91530247 8.96720718]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.18653382 8.82862582]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.91449149e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.10738531 10.20929936]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [9.02377222 9.07048646]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2614998e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.78649964 9.06669356]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.60786677 8.54099034]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09685888e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.90784967 9.1600242 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [9.01706471 9.24402178]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25684553e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.95167906 9.03840703]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.97290742e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.14688751 8.85421491]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.13436428 10.22001249]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.21147513e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.73459453 9.06088948]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.92718947 9.01511245]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.95045968e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.06101995 10.23436204]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.53817305 9.13648972]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.50059267e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.78800272 9.10130104]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.9457792  10.27177691]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.18490954e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.68435575 9.22284075]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.02598232e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.81592017 9.30055667]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.11727347e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.48773314 7.29175262]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.52316117 9.29079875]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.30326583 8.76697002]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.52316117 9.29079875]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.67084506 9.36171888]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01660739e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.80376055 9.42554699]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10883604e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.92338449 9.48299229]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19184183e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.78299858 9.24828415]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.66483234 8.58279867]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09442953e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[6.981206   6.96391747]\n",
      "  [8.85743223 9.05726155]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.87538906 8.41430395]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14607825e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[7.04075863 6.84768032]\n",
      "  [8.85743223 9.05726155]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.15853831e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.98066742 8.3300566 ]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14607825e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[7.04075863 6.84768032]\n",
      "  [8.971689   9.15153539]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22535981e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[7.04075863 6.84768032]\n",
      "  [9.07811147 8.90779033]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.26864539 8.77373906]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.81960249e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.10413419 10.19900459]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.29920523e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[7.04075863 6.84768032]\n",
      "  [9.17030032 9.0170113 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.3631741e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[7.04075863 6.84768032]\n",
      "  [9.25327029 9.11531017]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.42074608e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[7.04075863 6.84768032]\n",
      "  [8.9340933  9.06715071]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.97597637 8.96647136]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.92948334e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.12570441 10.22636258]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19927255e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[7.04075863 6.84768032]\n",
      "  [9.04068397 9.16043564]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27323469e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[7.04075863 6.84768032]\n",
      "  [9.13661557 9.24439207]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.33980061e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[7.04075863 6.84768032]\n",
      "  [8.75869834 9.20878458]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.49146752 8.66674952]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07756785e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[7.04075863 6.84768032]\n",
      "  [8.8828285  9.28790612]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16370045e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[7.04075863 6.84768032]\n",
      "  [8.99454565 9.35911551]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2412198e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[7.11819757 7.16748636]\n",
      "  [8.99454565 9.35911551]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2412198e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[7.11819757 7.16748636]\n",
      "  [8.89385983 9.14625756]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.80327769 8.49187778]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.65313104 7.36219581]]\n",
      "\n",
      " [[7.11819757 7.16748636]\n",
      "  [9.00447385 9.23163181]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24810887e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.11819757 7.16748636]\n",
      "  [9.00447385 9.23163181]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.00342839 8.43859161]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24810887e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.11819757 7.16748636]\n",
      "  [9.10402647 9.30846863]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.11819757 7.16748636]\n",
      "  [9.19362382 9.37762176]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.37935803e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.11819757 7.16748636]\n",
      "  [9.27426144 9.43985959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.43531161e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.11819757 7.16748636]\n",
      "  [9.34683529 9.49587363]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.11819757 7.16748636]\n",
      "  [9.41215176 9.54628627]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.11819757 7.16748636]\n",
      "  [9.30744724 9.14857978]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.35199596 8.80984084]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.2858311  10.2726132 ]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.28207768 7.24317509]\n",
      "  [9.30744724 9.14857978]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.45833889e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.28207768 7.24317509]\n",
      "  [9.37670251 9.2337218 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.30127888e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.28207768 7.24317509]\n",
      "  [9.02914964 9.14079724]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.78765784 8.56123931]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.28207768 7.24317509]\n",
      "  [9.12623468 9.22671751]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [9.12623468 9.22671751]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.33259742e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [9.07818047 9.03785448]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.02510111 8.39576145]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.29925311e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [9.17036243 9.13406903]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.36321719e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [9.19522166 8.9253391 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.19063922 8.26801636]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.38046675e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [9.27569949 9.03280519]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [9.31410543 8.82360914]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.50965205 8.74305346]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.36855772 10.16575026]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.46295894e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [9.06091353 8.90902595]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.20224911 8.93782683]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.30864428 10.14648551]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.28727177e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [9.15482218 9.01812336]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.2704868e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [9.23933996 9.11631102]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [9.31540597 9.20467992]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.46386137e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.93860263 9.17747069]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.02458227 9.02750762]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.22976319 10.24423103]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [9.04474237 9.25972362]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27605077e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.73220409 9.24086486]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.50517277 8.71009975]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.76817115 9.10447233]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.75985485 8.49683881]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.24578522 6.65176185]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.88802751 8.95097169]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.75985485 8.49683881]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.12683455 6.72461645]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.07837034e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.2718327  8.84611182]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.12683455 6.72461645]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.01665597e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.1700926  10.20250419]\n",
      "  [ 6.36909416  7.02958499]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16730799e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.99922476 9.05587452]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24446658e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [9.09930229 9.15028707]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.85838422 9.11358826]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.00395339 9.00405759]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.12683455 6.72461645]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.1700926  10.20250419]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[6.97671681 8.14434334]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22934777e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.9725458  9.20222944]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22595434e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.68785426 9.20273775]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.55385834e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.4771184  8.68312389]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.12683455 6.72461645]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.02840989e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.73477449 9.07461843]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.10659624 8.92256362]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.12683455 6.72461645]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.0789561  10.23109947]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.06096734e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.86129704 9.16715659]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.000000e+00 1.000000e+00]\n",
      " [1.229752e-16 1.000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.67328701 9.15260374]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.88488056 9.0537216 ]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.12683455 6.72461645]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.00879285 10.27659123]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.49059573 9.19779051]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.33867857 8.705977  ]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[7.12683455 6.72461645]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.8915343e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.58076929 9.08128606]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.33867857 8.705977  ]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.97285643 8.963625  ]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.93670414 10.27081004]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.95410477e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.8478766  7.07784902]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.72269236 9.17315745]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05258369e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.72269236 9.17315745]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.76110987 9.09013651]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.95742902 10.304668  ]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05258369e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.46579013 9.22263333]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.26687099 8.73412159]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.87432195e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.61921112 9.30037   ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[7.29153271 7.31227455]\n",
      "  [8.61635395 9.14383363]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.9164071  8.98892799]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.82768618e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.92525609 10.30986745]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.97879659e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.61635395 9.14383363]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.40474513 8.65199745]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.97879659e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.75471856 9.22945027]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07480632e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.8792467  9.30650524]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16121508e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.8015214  9.1140516 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.83196348e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.972475   8.94994571]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.80536173e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.98323661 10.30055437]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.5897507  9.13700408]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.77953214 9.0951946 ]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.84559379e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.92751858 10.30507882]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.96033688e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.73077563 9.22330368]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.21163852e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.85769807 9.30097331]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14626271e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.54066189 9.28856449]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.30603083 8.7630231 ]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.6865957  9.35970805]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.0275366e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.66571018 9.18506326]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.92402285 9.00354308]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.93004337 10.32656471]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.50246423 9.19394886]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.36299712 8.67935108]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.89976972e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.59643096 9.06871486]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.62007094 8.46716149]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.73678787 9.16184338]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61308087 7.12437451]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.86310908 9.24565904]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23000347e-16 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.86310908 9.24565904]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.98137577e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.08205282 8.86420663]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.80868357e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.01026531 10.36154597]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15001736e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.97679817 9.32109314]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [9.07911835 9.38898382]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2999039e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.7723803  9.24017456]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.54997853 8.62817314]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08706162e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.80618156 9.07135654]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.07909539 8.95870496]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.02760528 10.3093156 ]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.11051596e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.8123292  7.25170847]\n",
      "  [8.63472894 9.11916025]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.60599858e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.85058981 9.10307872]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.96769422 10.3023219 ]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.9915468e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.63472894 9.11916025]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.37918648 8.69920346]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.9915468e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.66903906 9.03926151]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.8142286e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.97667093 8.97053049]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.95146273 10.26686555]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01535423e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.5251879  9.10784295]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.76892056 9.09201147]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.82354624e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.88580653 10.27656996]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.91553744e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.67266911 9.19705866]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.8054022  9.27735279]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10997516e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.51026932 9.27548098]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.63878289 9.15663372]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.84701099 10.34847737]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.65924239 9.34793288]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.79331815 9.4131396 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10159017e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.45217223 9.36922328]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.3004704e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.20026034 8.82600617]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.60695501 9.43230096]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.19445495e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.74625951 9.48907086]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.06893668e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.87163356 9.54016377]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.71592091 9.30048436]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.58649853 8.63319683]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04788505e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.84432882 9.37043592]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13698593e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.85676382 9.13849669]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.03205366 8.95598936]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.75106828e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.96621103 10.32963736]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14561445e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.64120338 9.15164409]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.47250818 8.63865232]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.75456881 6.94905185]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.70960496 9.03128297]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.0227385  8.9511811 ]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.8988887  6.84469903]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.9669475  10.27733187]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04350248e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.58637981 7.05499837]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.70960496 9.03128297]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.0227385  8.9511811 ]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.65853975 7.00282195]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.79814825 9.0865233 ]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.65853975 7.00282195]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.83429095e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.96731573 10.25117912]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04350248e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.58637981 7.05499837]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.47406178 9.15025081]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.28869884 8.70336197]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.65853975 7.00282195]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.88006156e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.58637981 7.05499837]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.55251043 9.05647019]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.28869884 8.70336197]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.56535359 8.47426906]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.58637981 7.05499837]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.70239665 8.91794272]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.06960309 8.83760618]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.96461653 10.19276665]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03850071e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.58637981 7.05499837]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.57903956 8.99401383]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.46641737 8.51640862]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.95290453e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.58637981 7.05499837]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.7211356  9.09461245]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.58637981 7.05499837]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.84902204 9.1851512 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14024251e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.58637981 7.05499837]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.81107797 8.99913905]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.01905529 8.83531097]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.83267352e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.00673945 10.19603895]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.58637981 7.05499837]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.6131611  9.03369391]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.81222343 8.99607106]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.94863417 10.21149704]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.58637981 7.05499837]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.75184499 9.13032452]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.58637981 7.05499837]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.50081187 9.16359069]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.30643646 8.66347181]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.89862316e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.58637981 7.05499837]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.65073068 9.24723162]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.00265024e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61576449 6.99288791]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.65073068 9.24723162]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.6135105  8.53062855]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61576449 6.99288791]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.78565761 9.32250846]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61576449 6.99288791]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.83823301 9.07350565]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.08620892 8.84991309]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.82158353e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.00961029 10.23515078]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13275611e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61576449 6.99288791]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.65360007 9.07671806]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.50454449 8.55564377]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.61576449 6.99288791]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.78824006 9.16904625]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.78824006 9.16904625]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.76756827 8.44544039]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09806654e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.90941606 9.25214163]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.96173534 9.00424697]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.18762825 8.81678051]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.86389421e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.08949928 10.21927418]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.21845307e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [9.0655618  9.10382227]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.25809943e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.8078322  9.07862334]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.616947   8.53983959]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.11166132e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.92704898 9.170761  ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19438458e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [9.03434408 9.2536849 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.26883551e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [9.13090967 9.32831641]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [9.01223364 9.08009404]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.9792081e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.14427321 8.85762946]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.50158497  8.79444897]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.14964309 10.24167471]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25349331e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [9.11101028 9.17208464]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [9.19990925 9.25487617]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.38371942e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [9.27991832 9.32938856]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.89766845 9.20774606]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.63120399 8.61191316]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17399773e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [9.0079016  9.28697146]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25048735e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [9.10711144 9.35827431]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.2638656e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [9.00603732 9.12390242]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.98910087e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.17545923 8.90262646]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.14964309 10.24167471]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.17723647 10.27039832]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.77320235 9.12300179]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.59701056 8.60051395]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08763203e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.8254054  9.00170648]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.96537441e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.82866744 8.40093956]\n",
      "  [6.49461384 7.12381588]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [8.94286486 9.10153583]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20535904e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [9.04857837 9.19138225]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.54640052 7.26708572]\n",
      "  [9.05575616 8.95606695]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.12611867e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.82866744 8.40093956]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.03663618 8.28289656]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.28369312e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.88785473 6.94670149]\n",
      "  [9.05575616 8.95606695]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.38921268 8.74960761]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.2109207  10.21762594]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.28369312e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.88785473 6.94670149]\n",
      "  [9.15018054 9.06046025]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.88785473 6.94670149]\n",
      "  [9.23516249 9.15441423]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.88785473 6.94670149]\n",
      "  [8.97326632 9.07705016]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.78391287 8.50562387]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.88785473 6.94670149]\n",
      "  [9.00019831 8.94077463]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.27632471 8.83986231]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.00358137e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.20553967 10.18512282]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24514212e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.88785473 6.94670149]\n",
      "  [8.81062904 9.00633224]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.02037823 8.99398028]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.64474941 6.98275577]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.12702145 10.1950943 ]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.88785473 6.94670149]\n",
      "  [8.61346581 9.10075823]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.56525536e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.02037823 8.99398028]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.530526   7.08897   ]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.45557544 8.63729343]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.530526   7.08897   ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.97679254e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.88785473 6.94670149]\n",
      "  [8.75211923 9.19068241]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.21460054e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.88785473 6.94670149]\n",
      "  [8.75828979 9.05025858]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.86723409e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.0785963  8.89668444]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.530526   7.08897   ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.94536457e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.06682664 10.21765058]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07728436e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.88785473 6.94670149]\n",
      "  [8.88246081 9.14523272]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16344532e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.88785473 6.94670149]\n",
      "  [8.67266892 9.13129014]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.86602881 9.03540245]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.530526   7.08897   ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.00248089 10.26134135]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.91299494 7.1258668 ]\n",
      "  [8.67266892 9.13129014]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01787295e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.91299494 7.1258668 ]\n",
      "  [8.48274598 9.17980605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.73400676 9.12223776]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.530526   7.08897   ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.89433884 10.30259309]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.17721749e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.91299494 7.1258668 ]\n",
      "  [8.3349757  9.23879813]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.20099366 8.75663813]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.530526   7.08897   ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.7835512e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.91299494 7.1258668 ]\n",
      "  [8.50147813 9.31491832]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.91299494 7.1258668 ]\n",
      "  [8.53113653 9.16011441]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.51295144 8.54236483]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.530526   7.08897   ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.53113653 9.16011441]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.01421126 8.89221965]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.530526   7.08897   ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.85962403 10.31534231]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.70970004 6.91870146]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.47125277 9.13694507]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.75095524 9.07224675]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.530526   7.08897   ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.75982034e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.81831312 10.31244918]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.87811242e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.47125277 9.13694507]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.87811242e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.33600848 9.19737123]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.37830561e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.75095524 9.07224675]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.36564509 7.1733837 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.60280287 9.16110305]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.36564509 7.1733837 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.74355995 10.33517309]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.78426784e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.50240763 9.27763411]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.29232496 9.30325827]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.11833142 8.80185483]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.36564509 7.1733837 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.75395631e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.46309247 9.37293245]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.87245007e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.4788788  9.20720816]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.75658969 9.03499665]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.36564509 7.1733837 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.7633315  10.35046981]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.63099092 9.28648734]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.76789183 9.35783861]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.89110265 9.42205475]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23388836e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [9.00199238 9.47984927]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.2492774e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [9.10179314 9.53186434]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.3156377e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [9.19161383 9.57867791]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.69844279 9.40333762]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.58362744 9.15768625]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.36564509 7.1733837 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.69300397e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.86104286 10.43656995]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03575717e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.82859851 9.46300385]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12607084e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.44775023 9.39457643]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.53623087 9.2534711 ]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.36564509 7.1733837 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.76080485e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.80962153 10.47611554]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.60297521 9.45511878]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.31597995 9.42894783]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.09450741 8.89831469]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.36564509 7.1733837 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.77037026e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.48438196 9.48605305]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.88722262e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.86167804 6.97987933]\n",
      "  [8.63594376 9.53744774]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99238975e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.66864199 7.04926554]\n",
      "  [8.63594376 9.53744774]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.77110232 9.13960356]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.36564509 7.1733837 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.85918827 10.55303687]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99238975e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.66864199 7.04926554]\n",
      "  [8.77234939 9.58370297]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08704017e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.66864199 7.04926554]\n",
      "  [8.49461562 9.44769291]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.39228545e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.28339741 8.84887894]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.36564509 7.1733837 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.64767996 7.06418435]\n",
      "  [8.49461562 9.44769291]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.53954495 8.70351664]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.36564509 7.1733837 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.89432365e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.64767996 7.06418435]\n",
      "  [8.66312579 9.20525311]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.73502279 8.53385956]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.36564509 7.1733837 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01125107e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.64767996 7.06418435]\n",
      "  [8.79681321 9.2847278 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10401536e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.64767996 7.06418435]\n",
      "  [8.89241572 9.05590772]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.06113964e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.1111867  8.98814453]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.36564509 7.1733837 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.98656042 10.39888152]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17035292e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.64767996 7.06418435]\n",
      "  [8.69068254 9.12321167]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.53186637 8.64335693]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.36564509 7.1733837 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03037241e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.69068254 9.12321167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.82161429 9.21089051]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.82355369 9.06278803]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.06055735 8.98123108]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.36564509 7.1733837 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.02270169 10.32455597]\n",
      "  [ 6.93123757  7.71391892]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12257029e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.63599979 9.12388644]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.48467859 8.64017012]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.36564509 7.1733837 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.19848573e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.77239981 9.2114978 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.89515983 9.29034802]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17225703e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.84145135 9.10124206]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.88742846e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.48467859 8.64017012]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.77891984 8.46058188]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.74335113 7.11412876]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.93229361 8.93485378]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.96237736 8.30423245]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19802377e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.93229361 8.93485378]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.05410612 8.22605774]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19802377e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [9.08778925 8.75784999]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.33613374 8.74285126]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.02270169 10.32455597]\n",
      "  [ 7.25630551  8.1146968 ]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.84106977e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[7.12347411 8.07531166]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.30592055e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [9.17901033 8.88206499]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.36921788e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [9.2611093  8.99385849]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.42618548e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.96500814 8.99406975]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.75407013 8.46905353]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22072404e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.98413212 8.88465628]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.18611574 8.86434915]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.10500369 10.2161405 ]\n",
      "  [ 7.25630551  8.1146968 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.76651236 8.9880678 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.68025886e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.59966281 8.5274017 ]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.21659798e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.88986112 9.08926102]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16858031e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [9.00087501 9.18033492]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24561167e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.94030263 9.00112814]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.14183288 8.85015705]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.93008668e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.1286229  10.20852151]\n",
      "  [ 7.25630551  8.1146968 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [9.04627237 9.10101533]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [9.14164513 9.19091379]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.34329057e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.82755572 9.13551972]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.64953146e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.60193873 8.57928641]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12534726e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.94480015 9.22196774]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [9.05032013 9.29977097]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.96593556 9.08160005]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.15241852 8.87305181]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.61064972  8.99389437]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.15068567 10.23690077]\n",
      "  [ 7.25630551  8.1146968 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22136756e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [9.069342   9.17344004]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.25862404e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [9.1624078  9.25609604]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.35769756e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [9.24616702 9.33048644]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.88405092 9.21446394]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.93648353 9.03128621]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.15068567 10.23690077]\n",
      "  [ 7.25630551  8.1146968 ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.1289632  10.30423596]\n",
      "  [ 7.25630551  8.1146968 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23290974e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.61661887 9.21974646]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.81982705 9.13733749]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.94671193e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.01112915 10.34001656]\n",
      "  [ 7.25630551  8.1146968 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.75495698 9.29777181]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.50540931 9.3038209 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.71436518 9.20467537]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.9077283  10.39153664]\n",
      "  [ 7.25630551  8.1146968 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.90181328e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.65486838 9.37343881]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.00552134e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.78938154 9.43609493]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.0988586e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.48043684 9.39991761]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.24935733 8.86230473]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.88448515e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.53996135 9.2448807 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.88776998 9.08776702]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.79319938e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.86984869 10.3937206 ]\n",
      "  [ 7.25630551  8.1146968 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.92578858e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.800113   7.18137684]\n",
      "  [8.68596522 9.32039263]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.68596522 9.32039263]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.47323991e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.69182447 9.20137175]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.86984869 10.3937206 ]\n",
      "  [ 7.4775424   8.28747306]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.9429031e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[7.03612314 8.26581288]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.8173687  9.38835337]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.11827859e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.48541414 9.37472538]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.24007789 8.85057603]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.53873822 9.2275931 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.53553423 8.61632526]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.6848644  9.30483379]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20526705e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.81637796 9.37435041]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.93474016 9.43691537]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19972141e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.88158378 9.16498779]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.01570659 8.96565087]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.98755786 10.36285542]\n",
      "  [ 7.4775424   8.28747306]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23256735e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.64707453 9.16875424]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.46668311 8.65032713]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.71021051 9.04450797]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.0283647  8.97030573]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.84859226e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.97786313 10.2992309 ]\n",
      "  [ 7.4775424   8.28747306]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04392266e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.56645113 9.11037628]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.8053276  9.10484522]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.91551202 10.29376596]\n",
      "  [ 7.4775424   8.28747306]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.40535661 9.19712623]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.26480644 8.7312731 ]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.50860088 9.09107236]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.89860803 8.98314294]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.57669398 7.0427599 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.79860042e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.86119636 10.28331192]\n",
      "  [ 7.4775424   8.28747306]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.90402788e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.65774079 9.18196512]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.00751448e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.79196671 9.26376861]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10065242e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.55542657 9.22514148]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.89860803 8.98314294]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [0.         0.        ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.37147464 8.68162806]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.69988391 9.30262733]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03675714e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.69853181 9.12396489]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.93021586 8.9541388 ]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.91001091 10.29124192]\n",
      "  [ 7.4775424   8.28747306]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95662651 6.87875736]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.82867863 9.2115684 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12612643e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6503996  7.0210342 ]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.82867863 9.2115684 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.72911229 9.09356617]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.79478325e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.9864769  10.33024832]\n",
      "  [ 7.4775424   8.28747306]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12612643e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6503996  7.0210342 ]]\n",
      "\n",
      " [[6.55516449 7.22579523]\n",
      "  [8.94581077 9.29041156]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6503996  7.0210342 ]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [8.94581077 9.29041156]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6503996  7.0210342 ]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [8.5645503  9.28263225]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.29037627 8.75983598]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6503996  7.0210342 ]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [8.70809527 9.35436902]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6503996  7.0210342 ]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [8.67019814 9.1811189 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.61326739 8.55236555]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.0161585e-17 1.0000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [8.67019814 9.1811189 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.2032317e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [8.78040603 9.01150567]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.10122446 8.9082821 ]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.8478422e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.00540086 10.26972643]\n",
      "  [ 7.4775424   8.28747306]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09263059e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [8.90236543 9.11035511]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23545138e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [8.6916725  9.11849039]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.6213537e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.52728123 8.60153721]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20621187e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [8.82250525 9.20664135]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12184279e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [8.82216511 9.04393556]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.79250666 8.41834283]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12160677e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [8.9399486  9.13954201]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [8.98697696 8.93710813]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.99104412 8.28401467]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.23596797e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [9.08827927 9.04339732]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [9.14055728 8.83530453]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[8.99104412 8.28401467]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.15892334 10.16898503]\n",
      "  [ 7.4775424   8.28747306]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.34253572e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [9.22650155 8.95177408]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [9.3038514  9.05659667]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [9.24834334 8.8419042 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.1948594  8.17876901]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [9.30211543 8.69245971]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.46099904 8.65697852]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.30030784 10.0614764 ]\n",
      "  [ 7.4775424   8.28747306]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [9.37190389 8.82321374]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.50306468e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [9.07035156 8.87439827]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.85864014 8.37824857]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.29382071e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [9.1633164  8.98695845]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.35832803e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [9.12511426 8.84477865]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.07936577 8.22703574]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[6.85590655 7.32906224]\n",
      "  [9.19430344 8.71320362]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.21740426 8.09879932]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.37982961e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.10567465 7.14981257]\n",
      "  [9.19430344 8.71320362]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.10567465 7.14981257]\n",
      "  [9.28411342 8.59612154]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.52882527 8.57399022]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.06560616e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[6.66559913 9.09170749]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[7.36379929 9.96918681]\n",
      "  [7.4775424  8.28747306]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.10567465 7.14981257]\n",
      "  [9.05358682 8.72765686]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.88584736 8.27805785]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.10567465 7.14981257]\n",
      "  [9.08113235 8.67505157]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.3884434  8.62670365]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.66559913 9.09170749]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[7.36379929 9.96918681]\n",
      "  [7.55322045 8.45006169]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.8822912e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[7.15051451 8.10292707]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.26026028e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.10567465 7.14981257]\n",
      "  [9.17301912 8.80754641]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.36506064e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.10567465 7.14981257]\n",
      "  [8.94188692 8.85445467]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.77097647 8.35513369]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20468046e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.94188692 8.85445467]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20468046e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [9.04769823 8.9690092 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27810181e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [9.0322397  8.82655808]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.33100795 8.66524157]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.29479553 10.01521664]\n",
      "  [ 7.55322045  8.45006169]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.84852303 8.87937567]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.70491319 8.38437105]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13989625e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.90622679 8.79343625]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.91494731 8.20956003]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17993628e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [9.01560411 8.91409263]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.25116641e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [9.07378098 8.74087033]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.37539186 8.61086667]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.27691015 10.00395645]\n",
      "  [ 7.55322045  8.45006169]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.29620035e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.88704724 8.81478183]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.09845999 8.80701591]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.19327397 10.02789096]\n",
      "  [ 7.55322045  8.45006169]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16662779e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.99834251 8.93330365]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2438544e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [9.09850826 9.03997328]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31335835e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.79327906 7.18296466]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [9.18865743 9.13597595]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.0721025  7.24587271]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [9.18865743 9.13597595]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.0721025  7.24587271]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [9.26979169 9.22237836]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.43221011e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.0721025  7.24587271]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.87427984 9.13399555]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.61943547e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.59894193 8.55710618]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15776863e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.0721025  7.24587271]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.98685186 9.22059599]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.23588116e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.0721025  7.24587271]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.9330027  9.03314047]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.87267205 8.39180927]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.1985158e-17 1.0000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.9330027  9.03314047]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.1985158e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [9.01557017 8.87329394]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.04256409 8.24522221]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25580849e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [9.12481072 8.73473586]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.39859163 8.63376749]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.24656127 10.00783982]\n",
      "  [ 7.55322045  8.45006169]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.33160935e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.92184202 8.82087492]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.09792033 8.82001967]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.19201744 10.03226988]\n",
      "  [ 7.55322045  8.45006169]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.2381543e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.70008914 8.93844533]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.000000e+00 0.000000e+00]\n",
      " [1.000000e+00 5.619061e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.92576714 8.92291779]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.07604438 10.09151307]\n",
      "  [ 7.55322045  8.45006169]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03689955e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.83008022 9.0446008 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.9470722  9.14014072]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20827848e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.64384296 9.13923747]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.49960573e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.79330132 8.99806412]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.99555937 10.20145153]\n",
      "  [ 7.55322045  8.45006169]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99787092e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.43924201 9.16884439]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.27234746 8.66656982]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.85590049e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.52855999 9.05105012]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.93439748 8.91386552]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.90920368 10.22114581]\n",
      "  [ 7.55322045  8.45006169]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.43803899 9.09107127]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.34241433 8.59336127]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.85506573e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.55598523 8.98288014]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.93488864 8.88513896]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.79422313e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.87699593 10.20372496]\n",
      "  [ 7.55322045  8.45006169]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.93690737e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.45194807 9.04549565]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.34822355 8.56076774]\n",
      "  [6.77877389 6.92228377]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.17294342e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.56526345 8.94705492]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.34822355 8.56076774]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.92491015 8.86187385]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.86460335 10.18068445]\n",
      "  [ 7.55322045  8.45006169]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.18866909e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.70873711 9.05234943]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.8378634  9.14711449]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[7.12959209 7.11668815]\n",
      "  [8.95407706 9.23240304]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.21313907e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.73476011 7.10309362]\n",
      "  [8.95407706 9.23240304]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.70829641 9.00321071]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.0139325  10.28330344]\n",
      "  [ 7.55322045  8.45006169]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.73476011 7.10309362]\n",
      "  [8.56035709 9.2174858 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.27829104 8.68859967]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.73476011 7.10309362]\n",
      "  [8.59149496 9.08418277]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.57574351 8.47797295]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [3.30216035 5.10789057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.9615472e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.73476011 7.10309362]\n",
      "  [8.73234547 9.17576449]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05928187e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.73476011 7.10309362]\n",
      "  [8.79647014 8.97907143]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[8.57574351 8.47797295]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.0255543  10.23328029]\n",
      "  [ 7.55322045  8.45006169]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22075546e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.73476011 7.10309362]\n",
      "  [8.82853247 8.88072489]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.81928474 8.29127643]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12602501e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.73476011 7.10309362]\n",
      "  [8.94567922 8.9926524 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.73476011 7.10309362]\n",
      "  [9.0511113  9.09338716]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.73476011 7.10309362]\n",
      "  [9.14600017 9.18404845]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.73476011 7.10309362]\n",
      "  [9.10071398 8.90853479]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.21986409 8.73895033]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.15306274 10.18005406]\n",
      "  [ 7.55322045  8.45006169]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31488888e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.73476011 7.10309362]\n",
      "  [8.83830263 8.94984753]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.97115714 8.94149679]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.15306274 10.18005406]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.96166616e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[7.11057831 8.13140255]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13280442e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.73476011 7.10309362]\n",
      "  [8.95447237 9.05486278]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.73476011 7.10309362]\n",
      "  [8.66569904 9.1040301 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.45185819 8.61236044]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.74812333 6.99649098]\n",
      "  [8.66569904 9.1040301 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.08715419 8.87820184]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.04281099 10.23163907]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01303662e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.74812333 6.99649098]\n",
      "  [8.79912914 9.19362709]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.74812333 6.99649098]\n",
      "  [8.63442625 9.14809428]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.86070149 9.03175655]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.88693182e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.97517599 10.27505725]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.74812333 6.99649098]\n",
      "  [8.46149372 9.18674976]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.31494823 8.69057818]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.87134072e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.74812333 6.99649098]\n",
      "  [8.61534435 9.26807479]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.8201994  7.20547541]\n",
      "  [8.61534435 9.26807479]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.8201994  7.20547541]\n",
      "  [8.63365147 9.11026867]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.6109347  8.48939656]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99079915e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.8201994  7.20547541]\n",
      "  [8.76119961 8.95089296]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.97503623e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.8099472  8.32505546]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07930346e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.8201994  7.20547541]\n",
      "  [8.90457869 8.80546866]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.195044   8.77255063]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.04941947 10.15971609]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.8201994  7.20547541]\n",
      "  [9.01412082 8.9249218 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2548028e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.8201994  7.20547541]\n",
      "  [8.78507801 8.97148115]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.91728979 8.95016175]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.03874094 10.1684505 ]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09587242e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.8201994  7.20547541]\n",
      "  [8.90657021 9.07433303]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.18017457e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.8201994  7.20547541]\n",
      "  [9.01591319 9.16689973]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2560465e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.8201994  7.20547541]\n",
      "  [8.67487251 9.16351457]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.4285939  8.6404867 ]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.000000e+00 1.000000e+00]\n",
      " [6.019402e-17 1.000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.8201994  7.20547541]\n",
      "  [8.70887381 9.03795196]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.84851188e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.69784647 8.43542414]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04299514e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.8201994  7.20547541]\n",
      "  [8.8335755  8.89314564]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.03534339e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.16441961 8.78509227]\n",
      "  [6.72867637 6.88544898]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.05280067 10.14148351]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12952432e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.8201994  7.20547541]\n",
      "  [8.68255559 8.96060973]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.16441961 8.78509227]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.4477902  7.11463712]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.66520415e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.16441961 8.78509227]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.48966295 7.07135547]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.55523204 8.47679003]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.48966295 7.07135547]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20494664e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.8201994  7.20547541]\n",
      "  [8.81430003 9.06454875]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22322986e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.10925233 7.23619254]]\n",
      "\n",
      " [[6.93581971 7.2285572 ]\n",
      "  [8.81430003 9.06454875]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22322986e-16 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[6.93581971 7.2285572 ]\n",
      "  [8.81430003 9.06454875]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[6.93581971 7.2285572 ]\n",
      "  [8.82924283 8.92299039]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.80931315 8.30759117]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.48966295 7.07135547]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12651793e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[6.93581971 7.2285572 ]\n",
      "  [8.94631855 9.03069135]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20775553e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[6.93581971 7.2285572 ]\n",
      "  [9.0516867  9.12762221]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.28086936e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[6.93581971 7.2285572 ]\n",
      "  [9.04956861 8.88684757]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.11268893e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.02448402 8.20853461]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.48966295 7.07135547]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27939965e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[6.93581971 7.2285572 ]\n",
      "  [9.13457791 8.72683763]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.26199372e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.33336228 8.66086071]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.48966295 7.07135547]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.1802315  10.06147681]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[6.93581971 7.2285572 ]\n",
      "  [9.22112012 8.85415387]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.39843742e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[6.93581971 7.2285572 ]\n",
      "  [9.29900811 8.96873848]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[6.93581971 7.2285572 ]\n",
      "  [8.98284897 8.94871352]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.78243167e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.75982073 8.40991576]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.48966295 7.07135547]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.23310359e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [8.98284897 8.94871352]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.23310359e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.08456407 9.05384217]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.30368262e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.17610766 9.14845796]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.2584969  9.23361216]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.42437277e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.33264721 9.31025094]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.17025189 9.01909178]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.04801112 8.31259459]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.48966295 7.07135547]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.3631405e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.2532267  9.1171826 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.42071584e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.32790403 9.20546434]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.47253364e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.28315646 8.92777001]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.23726815 8.2274053 ]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.48966295 7.07135547]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.28829676e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.33648549 8.75484712]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[9.23726815 8.2274053 ]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.35322827 8.1156415 ]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.47848823e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.08034618 7.24391577]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.40953405 8.62368016]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.54870673 8.58241147]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[6.66559913 9.09170749]\n",
      "  [3.13289544 0.32372175]]\n",
      "\n",
      " [[7.35392937 9.98021047]\n",
      "  [7.63681603 8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.40953405 8.62368016]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.46858065 8.76131215]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.15377302 8.81362066]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.21592512 8.78328992]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.33847389 10.0155535 ]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.35170598e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.23839572 8.9322586 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [8.9055679  8.97944527]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.04335211 8.89786636]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.23146411 10.09955486]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17947908e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.01501111 9.08150074]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25542057e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [8.7248464  9.09989691]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.51161462 8.58889195]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.21081567e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [8.85236176 9.18990722]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14255991e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [8.96712559 9.2709165 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [8.88820864 9.07101503]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.90611908e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.14839295 8.83426792]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.17101551 10.17818344]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [8.99938778 9.16391353]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2445797e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.099449   9.24752217]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31401112e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.1895041  9.32276996]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.27529988e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.27055369 9.39049296]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.34349832 9.45144366]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.48335435e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [8.93110634 9.259429  ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.65408342e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.64663901 8.62090556]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23943999e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [8.92420878 9.07807672]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.19172571 8.88172615]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.15519127 10.22032241]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.0317879  9.17026905]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2670618e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.12860911 9.25324214]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.33424501e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [8.84099484 9.17931153]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.63226079 8.61258769]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13467252e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [8.95689535 9.26138038]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [8.93135199 9.07572527]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.88867119 8.43658395]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19737039e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.03821679 9.16815274]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27152274e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.07457687 8.95870995]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.3064121  8.80642094]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.20742638 10.19364518]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.29675262e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.16711919 9.06283896]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.36096674e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.25040727 9.15655506]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.41875946e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [9.32536654 9.24089955]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [8.98524811 9.14301815]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.0361766  8.98066854]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.19781244 10.25402985]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.06104944 7.19376401]\n",
      "  [8.7070947  9.16377649]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.57621768e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.89721328 9.09194621]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.0817441  10.29252552]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [8.7070947  9.16377649]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [8.51243266 9.21866673]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.47979251e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.3535797  8.7334398 ]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [8.66118939 9.29680006]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.00990743e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [8.79507045 9.36712005]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10280608e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [8.91556341 9.43040805]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23728297e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [9.02400707 9.48736724]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [8.85343541 9.23705954]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.71816402 8.56154372]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [8.96809187 9.31335359]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2228638e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [9.07128269 9.38201823]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [9.02290695 9.1156266 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.04944151e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.96824479 8.4270225 ]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [9.12061625 9.20406394]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.26573977e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [9.14760604 8.97284097]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.31682003 8.83052146]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.91394709e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.19991447 10.23539915]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [8.90053103 9.01862907]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.71862243 8.52271236]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.30398671 7.07142995]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [9.01047793 9.11676616]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25227504e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.13944233 6.94479992]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [9.01047793 9.11676616]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.239277   8.85551584]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.20414841 10.26440604]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86543196 7.01460629]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [9.01047793 9.11676616]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.72382967 8.57446438]\n",
      "  [6.63010603 6.9567614 ]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25227504e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86543196 7.01460629]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [8.99477083 8.98816883]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.72382967 8.57446438]\n",
      "  [6.80458488 6.90816645]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.95982317 8.38249973]\n",
      "  [6.80458488 6.90816645]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [8.99477083 8.98816883]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.21712624e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.07781992 8.2865174 ]\n",
      "  [6.80458488 6.90816645]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.24827521e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [9.09529375 9.08935195]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31112784e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [9.18576438 9.18041676]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [9.26718794 9.26237508]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.28608068e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.0133626  7.2623926 ]\n",
      "  [9.26472194 8.9457945 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.24479873 8.2215765 ]\n",
      "  [6.80458488 6.90816645]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.21257008 7.2095141 ]\n",
      "  [9.26472194 8.9457945 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.21257008 7.2095141 ]\n",
      "  [9.33028046 8.76152785]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.50405873 8.71655066]\n",
      "  [6.80458488 6.90816645]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.33418639 10.13681416]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.47418262e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.21257008 7.2095141 ]\n",
      "  [9.39725242 8.88537506]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.52065375e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.21257008 7.2095141 ]\n",
      "  [9.1002497  8.9293078 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.18570392 8.913001  ]\n",
      "  [6.80458488 6.90816645]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.30719307 10.1401302 ]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31456672e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.21257008 7.2095141 ]\n",
      "  [8.82440642 9.0298543 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.01572919 9.01255258]\n",
      "  [6.80458488 6.90816645]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.07038375e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.1833591  10.18200682]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12316199e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.21257008 7.2095141 ]\n",
      "  [8.61849488 9.11994818]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.45526255 8.65425556]\n",
      "  [6.80458488 6.90816645]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.21257008 7.2095141 ]\n",
      "  [8.7566454  9.20795336]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07614334e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.21257008 7.2095141 ]\n",
      "  [8.76042772 9.06567891]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.10097492 8.89993051]\n",
      "  [6.80458488 6.90816645]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.09585064 10.21727497]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.21257008 7.2095141 ]\n",
      "  [8.62060382 9.09281166]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.62118055e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.49872899 8.58708992]\n",
      "  [6.80458488 6.90816645]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.98174553e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.21257008 7.2095141 ]\n",
      "  [8.75854344 9.18353049]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.21257008 7.2095141 ]\n",
      "  [8.77876332 9.02660121]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.89717788e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.08770475 8.88045495]\n",
      "  [6.80458488 6.90816645]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.05943065 10.21927797]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09149073e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01664525 6.86030304]]\n",
      "\n",
      " [[7.21257008 7.2095141 ]\n",
      "  [8.62446356 9.06548258]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.61197252e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.4936378  8.56642051]\n",
      "  [6.80458488 6.90816645]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.21257008 7.2095141 ]\n",
      "  [8.62446356 9.06548258]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.21257008 7.2095141 ]\n",
      "  [8.7620172  9.15893433]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07987078e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.21257008 7.2095141 ]\n",
      "  [8.88581548 9.24304089]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.88581548 9.24304089]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.07059116 8.87092144]\n",
      "  [6.80458488 6.90816645]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.89846403e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.08404152 10.30685534]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.6711442  9.16988902]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.86891219 9.05820286]\n",
      "  [6.80458488 6.90816645]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.91554125e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.01047844 10.32138328]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01681497e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.48313698 9.20822565]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.73864747 9.15765474]\n",
      "  [6.80458488 6.90816645]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.89849401 10.3439819 ]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.17727175e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.63482328 9.28740309]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99161226e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.41287063 9.30676344]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.62872134 9.21642013]\n",
      "  [6.80458488 6.90816645]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.81439526 10.39469633]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.83760167e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.57158356 9.3760871 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.71442521 9.43847839]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04684719e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.40870114 9.40580725]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.62872134 9.21642013]\n",
      "  [6.45378098 7.14065128]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.62872134 9.21642013]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.17784112 8.87053296]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.83470851e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.47548702 9.25111681]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.81467866 9.09314501]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.79739244 10.39779489]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.62793832 9.32600513]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.98683486e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.43984062 9.30026057]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.62629631 9.20569046]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.77463247 10.41900167]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.59585656 9.37023451]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.96457367e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.73627091 9.43321106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.06200569e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.86264382 9.48988995]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14969451e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.97637943 9.54090096]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22861445e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.53870824 9.45272666]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.22863145 8.8839359 ]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.92491906e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.5608067  9.27993769]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.5386384  8.65394302]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.70472603 9.35194392]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.83425343 9.41674953]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12999472e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.95082808 9.47507458]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.21088464e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [8.8908694  9.1991145 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.82566696 8.50661731]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [9.00178246 9.27920305]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24624135e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [9.10160422 9.35128274]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [9.1914438  9.41615447]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.27556907e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [9.12598868 9.11072416]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.06322896 8.39759832]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [9.18828592 8.91440141]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.20692885 8.26455972]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [9.26945733 9.02296127]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.4319781e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [9.3175002  8.81730452]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.33046451 8.15920167]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.29306291e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.00374016 7.03132525]\n",
      "  [9.3909359  8.67233293]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.42160661 8.04853401]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.51627079e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [9.3909359  8.67233293]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.51627079e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [9.45184231 8.80509964]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.5585331e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [9.4945638  8.62196342]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.42065629 8.69186767]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.70084559e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.18514175 10.1582862 ]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [9.11554442 8.78772878]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.85654591 8.36102535]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.32517956e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [9.10039058 8.73827453]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.30232966 8.74382716]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.23272711 10.07445291]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31466447e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [8.87112715 8.86666813]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.69961569 8.41858083]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [8.91540985 8.80076639]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.24289869 8.73907158]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.18252749 10.05753301]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.18630831e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [8.7548644  8.89601183]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.99446034 8.892549  ]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.98387962e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.09320951 10.08717124]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07490752e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [8.87937796 9.00641065]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16130616e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [8.99144016 9.10576958]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [9.09229615 9.19519262]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.30904783e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [8.74393221 9.15461591]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.49480306 8.60812086]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.06732179e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [8.76988733 9.0205563 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.75535646 8.41228295]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08533177e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [8.89289859 9.11850067]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17068798e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [8.94859188 8.92416352]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.21496203 8.74100997]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.12604151 10.11325103]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20933297e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [9.05373269 9.03174716]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [8.81285116 9.01227757]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.000000e+00 0.000000e+00]\n",
      " [1.000000e+00 5.700275e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.63262148 8.47541601]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.11514392e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [8.93156604 9.11104981]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [8.91883161 8.94569131]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.16672734 8.78300842]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.66559913  9.09170749]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.1305534  10.13490204]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23773653e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [9.02694845 9.05112218]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.26370376e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.25824444 6.9845958 ]\n",
      "  [8.78016516 9.03876446]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.59542974 8.50700999]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09246345e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.06729411 6.8951019 ]\n",
      "  [8.78016516 9.03876446]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.80978093 8.36901078]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.06729411 6.8951019 ]\n",
      "  [8.91399495 8.86698654]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.97048845 8.23130001]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.18532653e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[7.06729411 6.8951019 ]\n",
      "  [9.04519286 8.72601327]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.33746558 8.66961082]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.1305534  10.13490204]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.94781535e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.18335384 10.05785633]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.04519286 8.72601327]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.04207433 8.85794794]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.20975406 10.01933347]\n",
      "  [ 7.63681603  8.46620167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27636336e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.14067357 8.85341194]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.22660621 8.96807075]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.40224416e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.30394559 9.07126368]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95810805 7.05634455]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.37355103 9.16413731]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.37355103 9.16413731]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.90493879 8.93670736]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.20975406 10.01933347]\n",
      "  [ 7.66263934  8.48566185]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.93395485e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[7.30470957 8.2313562 ]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.50420761e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [8.84875103 9.1567516 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.49196981 8.63105432]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14005446e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [8.96387593 9.24107644]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2199384e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.06748834 9.31696879]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.1607395  9.38527191]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.27130799e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.24466555 9.44674472]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.320199   9.50207025]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.05688742 9.20345685]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.86873987 8.4969099 ]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.28447809e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.07593966 9.00049239]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.0647458  8.3486519 ]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.29769824e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.16834569 9.10044315]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.3618178e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.21007117 8.88968234]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.41627453 8.68205934]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.2889055  10.06553967]\n",
      "  [ 7.66263934  8.48566185]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.39077067e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [8.97154539 8.9176649 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.79675542 8.40809563]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22526016e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.00447487 8.82207071]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.31393991 8.73026368]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.05769419e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.2462427  10.06159812]\n",
      "  [ 7.66263934  8.48566185]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24810957e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [8.8278134  8.90314083]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.68809531 8.42638817]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [8.94503206 9.01282674]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20686284e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [8.94775415 8.87696864]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.92314932 8.26398154]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.05297874 8.98927178]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.0957491  8.80022851]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.19167864e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.36007174 8.65663002]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.02809093e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.26142099 10.05089046]\n",
      "  [ 7.66263934  8.48566185]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.18617419 8.92020566]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.37418881e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [8.93711579 8.92275483]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.75488218 8.39741694]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20136983e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [8.97051077 8.82034419]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.9656454  8.22684615]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22454225e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.07345969 8.93830978]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.12298801 8.75989335]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.38739109 8.63377926]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.2799057  10.02940257]\n",
      "  [ 7.66263934  8.48566185]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.33034459e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.2106892  8.88390401]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.28962028 8.99551361]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [8.99976658 8.95126851]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.81992169e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.79360218 8.39739703]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.93973873 6.82663985]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24484255e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.01732416 8.83459307]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.79360218 8.39739703]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.00373075 8.23253574]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.11015438 8.71031083]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.14592713 8.1003922 ]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.19913894 8.83927975]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.38318491e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.27922505 8.95535177]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.35130254 9.0598166 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.41617229 9.15383494]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.30675641e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.366457   8.81707435]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.48492584 8.56195713]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.05144932e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.38653565 10.04153102]\n",
      "  [ 7.66263934  8.48566185]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.07719884 8.83332003]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.19707718 8.79759097]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.32414736 10.05409352]\n",
      "  [ 7.66263934  8.48566185]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.29857197e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.69588376 7.07135145]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.16947895 8.94998802]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01573346 7.11567094]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [9.16947895 8.94998802]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.36260416e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01573346 7.11567094]]\n",
      "\n",
      " [[6.86863329 6.91539527]\n",
      "  [8.86357035 8.9940304 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.68786489e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.64396673 8.49640765]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23006749e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01573346 7.11567094]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.86357035 8.9940304 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.8674115  8.34581599]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15033743e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01573346 7.11567094]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.97721331 9.09462736]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22919307e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01573346 7.11567094]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [9.03557126 8.88564007]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.36336469 8.6945454 ]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.27630218 10.08130279]\n",
      "  [ 7.66263934  8.48566185]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01573346 7.11567094]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.86313151 8.9206382 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.09220322 8.87979382]\n",
      "  [6.27837902 7.25689369]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.18340369 10.10890668]\n",
      "  [ 7.66263934  8.48566185]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15003292e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.01573346 7.11567094]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.66844704 9.01223663]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.09220322 8.87979382]\n",
      "  [6.3760708  7.18036437]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.51348043 8.54479156]\n",
      "  [6.3760708  7.18036437]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20298869e-16 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.66844704 9.01223663]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.72411903 8.37729043]\n",
      "  [6.3760708  7.18036437]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01494343e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.82387113 8.85703449]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.23542099 8.73220789]\n",
      "  [6.3760708  7.18036437]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.1212503  10.09726713]\n",
      "  [ 7.66263934  8.48566185]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.70610396 8.9214004 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.71447125e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.60015208 8.4346641 ]\n",
      "  [6.3760708  7.18036437]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.79311281 8.83456584]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.60015208 8.4346641 ]\n",
      "  [6.62809623 6.96404783]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.14857616 8.7562389 ]\n",
      "  [6.62809623 6.96404783]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.07787028 10.0824599 ]\n",
      "  [ 7.66263934  8.48566185]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10144769e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.91380153 8.95110925]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.18519231e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [9.02242138 9.05599833]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.25211249e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [9.12017924 9.1503985 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.81952009 9.07769481]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.60209611 8.50919738]\n",
      "  [6.62809623 6.96404783]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.11977142e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.85059849 8.94252635]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.96890323e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.84128745 8.33160923]\n",
      "  [6.62809623 6.96404783]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14133639e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.96181423 8.80390687]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.13487556e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.25179184 8.69878858]\n",
      "  [6.62809623 6.96404783]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.12366083 10.0627927 ]\n",
      "  [ 7.66263934  8.48566185]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.21850781e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.78162385 8.88146886]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.97536025 8.87451137]\n",
      "  [6.62809623 6.96404783]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.07447995 10.0839839 ]\n",
      "  [ 7.66263934  8.48566185]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09347562e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.90346146 8.99332198]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17801745e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.64187483 9.04646554]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.44443006 8.5558419 ]\n",
      "  [6.62809623 6.96404783]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.19930105e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.69870944 8.94556953]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.05200701 8.81151451]\n",
      "  [6.62809623 6.96404783]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.01672375 10.12021976]\n",
      "  [ 7.66263934  8.48566185]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03594219e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.82883849 9.05101257]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12623736e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.94595465 9.14591132]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [9.05135918 9.23132019]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2806421e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.74648239 9.1402659 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.52459646 8.56186361]\n",
      "  [6.62809623 6.96404783]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.21381827e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.78307978 8.99487839]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.06898773 8.82901971]\n",
      "  [6.62809623 6.96404783]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.02159379 10.15806124]\n",
      "  [ 7.66263934  8.48566185]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.21889718e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.9047718  9.09539055]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17892668e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [9.01429462 9.1858515 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2549234e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [9.11286516 9.26726635]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.32332045e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.78402767 9.16524106]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.59898498e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.84313138 8.97773435]\n",
      "  [6.62809623 6.96404783]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.02440796 10.24512704]\n",
      "  [ 7.66263934  8.48566185]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.52926639 9.17371427]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.33327225 8.65835288]\n",
      "  [6.62809623 6.96404783]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.59794209 9.05019829]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.33327225 8.65835288]\n",
      "  [6.64735701 6.94536507]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.60581296 8.44925576]\n",
      "  [6.64735701 6.94536507]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.74129623 8.90480145]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.11266967 8.82267869]\n",
      "  [6.64735701 6.94536507]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.02440796 10.24512704]\n",
      "  [ 7.7532035   8.53537341]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 1.01373209e-16]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[7.14887328 8.17759868]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.06549271e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.86716661 9.0143213 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15283283e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.98044995 9.11288917]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.73529284 9.08551606]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.55045197 8.54554577]\n",
      "  [6.64735701 6.94536507]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.06132702e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.78782721 8.96097634]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.9330679e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.55045197 8.54554577]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.08498917 8.8708237 ]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68502092  9.09981456]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.02733486 10.20695406]\n",
      "  [ 7.7532035   8.53537341]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.62790927 9.02881765]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.85342853 9.01819347]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.65344441  9.1326889 ]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.02733486 10.20695406]\n",
      "  [ 7.7532035   8.53537341]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.65344441  9.1326889 ]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.96483114 10.21500409]\n",
      "  [ 7.7532035   8.53537341]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.9868147e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.45532605 9.12168622]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.71264672 9.09509837]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.65344441  9.1326889 ]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.86454599 10.25617653]\n",
      "  [ 7.7532035   8.53537341]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.17341221e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.31272171 9.19888246]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.18141205 8.72710217]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.7681094e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.48144954 9.27899421]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.63330459 9.35109479]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99055846e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.58921711 9.16638826]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.83652442 8.9660217 ]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.65344441  9.1326889 ]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.86795984 10.29464357]\n",
      "  [ 7.7532035   8.53537341]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.42921832 9.16960281]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.66544615 9.10086828]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.65344441  9.1326889 ]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.80566725 10.31516291]\n",
      "  [ 7.7532035   8.53537341]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.28078762 9.22514872]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.31897175e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.14503812 8.74049362]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [4.95665317 7.66726666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.74595067e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.39840906 9.10877181]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[8.14503812 8.74049362]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.82756694e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.89190334 6.8562607 ]\n",
      "  [8.45721978 9.05058335]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.45540697 8.49048015]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.82811446 6.82432241]\n",
      "  [8.45721978 9.05058335]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.6105914  8.36547342]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.86837508e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.82811446 6.82432241]\n",
      "  [8.6114978  9.14552502]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.97542696e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.82811446 6.82432241]\n",
      "  [8.75034802 9.23097252]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07177365e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.82811446 6.82432241]\n",
      "  [8.81941057 8.96167563]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.83305993 8.26740696]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.11969542e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.82811446 6.82432241]\n",
      "  [8.94292925 8.7878006 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.13879686 8.75976864]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.65344441  9.1326889 ]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.98000533 10.17270169]\n",
      "  [ 7.7532035   8.53537341]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.82811446 6.82432241]\n",
      "  [9.04863633 8.90902054]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27875275e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.82811446 6.82432241]\n",
      "  [8.77983691 8.95841773]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.86140056 8.948965  ]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.84335164e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.65344441  9.1326889 ]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.00193743 10.16971794]\n",
      "  [ 7.7532035   8.53537341]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09223568e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [8.77983691 8.95841773]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09223568e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [8.90185322 9.06257595]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [9.0116679  9.15631836]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25310074e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [8.65039417 9.15774518]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.45494244e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.73147525 9.04236967]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.85857009e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.65344441  9.1326889 ]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.96112638 10.24795704]\n",
      "  [ 7.7532035   8.53537341]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [8.78535476 9.24197066]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09606446e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [8.48526748 9.2379332 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.25984462 8.71635812]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [8.63674073 9.31413988]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99294276e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [8.62230821 9.14361319]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.91437286 8.95736187]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.98731024 6.77227874]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.65344441  9.1326889 ]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.92948648 10.28142379]\n",
      "  [ 7.7532035   8.53537341]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.98292819e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [8.76007739 9.22925187]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07852476e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [8.54578784 9.19757068]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.91437286 8.95736187]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.37550157 8.65770921]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.92983151e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9132589  6.97575209]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [8.69120906 9.27781362]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03073775e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [8.69120906 9.27781362]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03073775e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [8.69580515 9.10199049]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.95954537 8.94142412]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.80829715e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.59851679  9.17891397]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.92948648 10.28142379]\n",
      "  [ 7.7532035   8.53537341]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.59851679  9.17891397]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.9430653  10.28150809]\n",
      "  [ 7.7532035   8.53537341]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20678539e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [8.82622464 9.19179144]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [8.59693047 9.17246537]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.52304409e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.41854487 8.63969821]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [8.66588318 9.04211197]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.98649856 8.93245234]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.81771935e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.59851679  9.17891397]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.93788592 10.25759883]\n",
      "  [ 7.7532035   8.53537341]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.92599199 6.9955283 ]\n",
      "  [8.52754102 9.09403692]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.54174662e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.76840365 9.06926571]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.81412543e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.59851679  9.17891397]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.87995937 10.26641419]\n",
      "  [ 7.7532035   8.53537341]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.91717024e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.57035746 7.12547043]\n",
      "  [8.52754102 9.09403692]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.63618557 9.14119853]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.59851679  9.17891397]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.85099609 10.27082186]\n",
      "  [ 7.7532035   8.53537341]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.91717024e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.57035746 7.12547043]\n",
      "  [8.67478691 9.18463323]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.0193426e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.57035746 7.12547043]\n",
      "  [8.39186769 9.24879603]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.17483986 8.77011767]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.57035746 7.12547043]\n",
      "  [8.46586979 9.13244508]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.47376784 8.53803687]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.57035746 7.12547043]\n",
      "  [8.62244203 8.98143729]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.68586073 8.36159335]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.57035746 7.12547043]\n",
      "  [8.76019783 9.08329356]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07860833e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.57035746 7.12547043]\n",
      "  [8.88417805 9.1749642 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16463689e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.57035746 7.12547043]\n",
      "  [8.91643332 8.93211944]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.90950369 8.25364445]\n",
      "  [6.74385929 6.89090084]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.57035746 7.12547043]\n",
      "  [9.02201814 8.7675175 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.90950369 8.25364445]\n",
      "  [6.93573113 6.7469082 ]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.19515028 8.73515097]\n",
      "  [6.93573113 6.7469082 ]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.59851679  9.17891397]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.85099609 10.27082186]\n",
      "  [ 7.73615106  8.53872617]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[7.18324389 8.09580634]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [9.02201814 8.7675175 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.83797358 8.97590423]\n",
      "  [6.93573113 6.7469082 ]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.59851679  9.17891397]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.0343053  10.14241793]\n",
      "  [ 7.73615106  8.53872617]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.6461985  8.97412044]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.73270891 9.04491929]\n",
      "  [6.93573113 6.7469082 ]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.59851679  9.17891397]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.97563205 10.16085714]\n",
      "  [ 7.73615106  8.53872617]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.78157865 9.0767084 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09344426e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.90342078 9.16903756]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23559784e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [9.01307871 9.2521338 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.59962292 9.24403462]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.30620362 8.72007349]\n",
      "  [6.93573113 6.7469082 ]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.62229291 9.1100467 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.60201897 8.50405543]\n",
      "  [6.93573113 6.7469082 ]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.76006362 9.19904203]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.0785152e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.8208394  9.00114319]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.09126231 8.81637057]\n",
      "  [6.93573113 6.7469082 ]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.59851679  9.17891397]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.01615178 10.18088585]\n",
      "  [ 7.73615106  8.53872617]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22413737e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.93875546 9.10102887]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20250758e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [9.04487991 9.19092598]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27614621e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.75894488 9.12201122]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.61444107e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.09126231 8.81637057]\n",
      "  [6.70437049 6.90000233]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.5492091  8.55698977]\n",
      "  [6.70437049 6.90000233]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.21554778e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.88305039 9.2098101 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16385442e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.99474535 9.28882909]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24135837e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.91705632 9.06721045]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.08106527 8.85084923]\n",
      "  [6.70437049 6.90000233]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.59851679  9.17891397]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.07489842 10.2173271 ]\n",
      "  [ 7.73615106  8.53872617]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.18745077e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [9.02535069 9.16048941]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.26259509e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [9.12281562 9.24444047]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.33022497e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.79383391 9.16255992]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.5580662  8.59044858]\n",
      "  [6.70437049 6.90000233]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10194805e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.91445052 9.24630393]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.18564264e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [9.02300547 9.32167354]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.26096777e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.93472921 9.0970162 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.85292479 8.43403077]\n",
      "  [6.70437049 6.90000233]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19971381e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [9.00853452 8.92212041]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.0298762  8.28586355]\n",
      "  [6.70437049 6.90000233]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [9.11621774 8.77540562]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.34489747 8.72986262]\n",
      "  [6.70437049 6.90000233]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.59851679  9.17891397]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.18393631 10.1188258 ]\n",
      "  [ 7.73615106  8.53872617]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.32564677e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [9.20459597 8.89786506]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.38697148e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.94025697 8.94087758]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.79043582e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.04602326 8.91246163]\n",
      "  [6.70437049 6.90000233]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.59851679  9.17891397]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.16807094 10.13576393]\n",
      "  [ 7.73615106  8.53872617]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20354946e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.68853779 9.03542344]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.89024    9.01053639]\n",
      "  [6.70437049 6.90000233]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.59851679  9.17891397]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.05945059 10.18205134]\n",
      "  [ 7.73615106  8.53872617]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.02888419e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.56323884 7.0567956 ]\n",
      "  [8.5003649  9.12192628]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.89024    9.01053639]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.34526596 8.6540387 ]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.68176538 7.17716831]\n",
      "  [8.5003649  9.12192628]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.89831302e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.93311307 7.19900149]]\n",
      "\n",
      " [[6.67898907 7.05019964]\n",
      "  [8.5003649  9.12192628]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.99641321 8.89983989]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.59851679  9.17891397]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.92987125 10.23979618]\n",
      "  [ 7.73615106  8.53872617]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.67898907 7.05019964]\n",
      "  [8.5003649  9.12192628]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.67898907 7.05019964]\n",
      "  [8.65032841 9.20973365]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.67898907 7.05019964]\n",
      "  [8.52372949 9.16480278]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.4076984  8.61584106]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.91452546e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.67898907 7.05019964]\n",
      "  [8.67135654 9.2483225 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.0169623e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.67898907 7.05019964]\n",
      "  [8.69875763 9.07049767]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.83401272e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.9757977  8.903839  ]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.80856414e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.59851679  9.17891397]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.94443868 10.24809716]\n",
      "  [ 7.73615106  8.53872617]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.67898907 7.05019964]\n",
      "  [8.5396979  9.09678444]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.53432141e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.76567432 9.05115836]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.59851679  9.17891397]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.94443868 10.24809716]\n",
      "  [ 7.74137309  8.50768562]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.98437673e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[7.0075011  8.18661694]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.92560577e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.67898907 7.05019964]\n",
      "  [8.37611868 9.16885556]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.23328463 8.69312141]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.67898907 7.05019964]\n",
      "  [8.53850681 9.25197001]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.67898907 7.05019964]\n",
      "  [8.68465613 9.32677301]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.02619075e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.67898907 7.05019964]\n",
      "  [8.81619052 9.39409571]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.11746106e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.67898907 7.05019964]\n",
      "  [8.70140911 9.17429642]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.59720596 8.51627927]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.67898907 7.05019964]\n",
      "  [8.8312682  9.25686677]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22558466e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.67898907 7.05019964]\n",
      "  [8.85451648 9.0349451 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.07637845 8.8573785 ]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.57703387  9.18869585]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.94443868 10.24809716]\n",
      "  [ 7.74137309  8.50768562]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57703387  9.18869585]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.01402593 10.23802662]\n",
      "  [ 7.74137309  8.50768562]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14405505e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.85451648 9.0349451 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.8437996  9.0238999 ]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57703387  9.18869585]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.04881956 10.23299135]\n",
      "  [ 7.74137309  8.50768562]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14405505e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.56477808 9.12703251]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.34781103 8.66276295]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.18860173e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.70830027 9.21432926]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.69327455 9.07226981]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.99343334 8.92457801]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57703387  9.18869585]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.0017196  10.2454036 ]\n",
      "  [ 7.74137309  8.50768562]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.54401061 9.10596611]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.79740451 9.06045045]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.85841894e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57703387  9.18869585]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.91846404 10.26508824]\n",
      "  [ 7.74137309  8.50768562]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.92859831e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.39096711 9.17716323]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.66608787 9.13626052]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57703387  9.18869585]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.81561887 10.30340941]\n",
      "  [ 7.74137309  8.50768562]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.82240305e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.2619187  9.24308582]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.55929148 9.18949403]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.72928562e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.57703387  9.18869585]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.81561887 10.30340941]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[6.80851803 8.2905428 ]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.71985732e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.43572683 9.31877724]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.85346135e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.59215415 9.38689952]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.73293873 9.44820957]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05969354e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.39018596 9.39990239]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.24531216e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.50589329 9.21611078]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57703387  9.18869585]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.76388382 10.41166566]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.55116736 9.45991215]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.93356431e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.69605063 9.51392094]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.35038263 9.44340478]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.0930997  8.8854173 ]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.15884838e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.51534437 9.4990643 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.90870711e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.66380993 9.54915787]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20234516e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.79742894 9.59424209]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.91768604 9.63481788]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.18788773e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.02591744 9.67133609]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.7501986  9.38983497]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.54662929 8.69864264]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07166997e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.87517874 9.45085147]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86670249 7.24827126]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.98766086 9.50576632]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85200296 7.10359268]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.98766086 9.50576632]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.86837899 8.65162785]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.02106583 7.35410287]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.98766086 9.50576632]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.23644252e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.02106583 7.35410287]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.04118203 9.2135343 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.13974302 8.99048019]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57703387  9.18869585]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.99841472 10.39124655]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.25471606e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.02106583 7.35410287]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.13706382 9.29218087]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.34011165e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.02106583 7.35410287]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.22335744 9.36296278]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.02106583 7.35410287]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.86757593 9.27767347]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.61690188 8.70630948]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15311686e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.02106583 7.35410287]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.98081834 9.34990612]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.02106583 7.35410287]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.0827365  9.41491551]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.14362751 7.44301764]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.0827365  9.41491551]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.14362751 7.44301764]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.17446285 9.47342396]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.36606244e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.14362751 7.44301764]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.25701657 9.52608156]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.42334558e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.14362751 7.44301764]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.07526904 9.24556457]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.97917679e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.10781683 9.00965336]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57703387  9.18869585]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.12931497 10.39384911]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.88916987e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.14362751 7.44301764]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.16774213 9.32100812]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.000000e+00 1.000000e+00]\n",
      " [6.361399e-17 1.000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.14362751 7.44301764]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.25096792 9.3889073 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.41914849e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.14362751 7.44301764]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.86861069 9.298315  ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.60135269 8.72415268]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.14362751 7.44301764]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.98174962 9.3684835 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.14362751 7.44301764]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.93141589 9.17390282]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.8732427  8.53163747]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19741473e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.14362751 7.44301764]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.0382743  9.25651254]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27156264e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.18712348 7.42411383]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.0382743  9.25651254]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.25431253e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.18712348 7.42411383]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.06843423 9.04091126]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.06399504 8.38218324]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2924903e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.18712348 7.42411383]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.16159081 9.13682013]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.18712348 7.42411383]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.20639342 8.92128336]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.38372351 8.84863126]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57703387  9.18869585]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.24721486 10.2654379 ]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.38821872e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.18712348 7.42411383]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.28575408 9.02915502]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.18712348 7.42411383]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [8.99636644 9.05403002]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.79040833 8.54592764]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.18712348 7.42411383]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.0967298  9.14862701]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.18712348 7.42411383]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.18705682 9.23376431]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.18712348 7.42411383]]\n",
      "\n",
      " [[6.57004592 7.06805122]\n",
      "  [9.26835114 9.31038788]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.43121052e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.18712348 7.42411383]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [9.26835114 9.31038788]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.18712348 7.42411383]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [9.1503389  9.073565  ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.05533973 8.40238982]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.34932308e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.18712348 7.42411383]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [9.19730534 8.89773842]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.28340416e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.42655581 8.80737007]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 5.0287655e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57703387  9.18869585]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.30252956 10.19181432]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.18712348 7.42411383]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [9.27757481 9.00796458]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.43761073e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.18712348 7.42411383]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [9.34981733 9.10716812]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.48773905e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [7.18712348 7.42411383]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [9.04553099 9.07653209]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.13428973 8.98041076]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57703387  9.18869585]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.26947718 10.22651999]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [9.04553099 9.07653209]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.97493573 9.08081338]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.04421309e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57703387  9.18869585]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.25295098 10.24387283]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.71273979 9.1705914 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.88864826 9.13795582]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.03274574e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.68969733  9.19189706]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.25295098 10.24387283]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68969733  9.19189706]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 7.11157141 10.29017297]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.5118292  9.24047803]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.34905581 8.76516912]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.59553692 9.12630666]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.79332125e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.01915647 8.99865375]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68969733  9.19189706]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.99400047 10.29560915]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.19287038e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.50543105 9.16261483]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.80717842 9.11757054]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68969733  9.19189706]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.89917266 10.31285051]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.90182836e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.65488794 9.24635335]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.00553492e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.78939915 9.32171801]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09887082e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.51757094 9.30788722]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.66325827 9.18392547]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68969733  9.19189706]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.8566147  10.37958014]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.91025211e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.32408878 9.3275138 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.31745361e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.57427502 9.24379479]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.68969733  9.19189706]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.75794286 10.42079559]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.1917544  9.36127482]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.06383927 8.86640732]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.68417147e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.32141291 9.22720034]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.59541251e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.73509678 9.1015219 ]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.65940426 6.96908412]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.54802581  9.26426677]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.75794286 10.42079559]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.54802581  9.26426677]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.70753659 10.40127793]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.77414013e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.48927162 9.3044803 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.64034445 9.37403227]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.41421094 9.3276249 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.73509678 9.1015219 ]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.42374084 7.12515082]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.55056303 9.21127212]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.42374084 7.12515082]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.45702754  9.29264455]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.70753659 10.40127793]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45702754  9.29264455]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.71945267 10.43168892]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.57278985 9.39486241]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.94856792e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.71551086 9.45537617]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.84395977 9.50983855]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.4422051  9.43942812]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.15216355 8.88140731]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.42374084 7.12515082]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.85795655e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.59798459 9.49548531]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.96605028e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.73818613 9.54593678]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.84727763 7.30422122]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.62995849 9.32553131]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.76386285 9.11337922]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.42374084 7.12515082]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.66255692e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45702754  9.29264455]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.81170973 10.44605699]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.62995849 9.32553131]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.99236341 7.25818076]\n",
      "  [8.42052438 9.30811735]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.25014118 8.77993655]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.42374084 7.12515082]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.84291253e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.42052438 9.30811735]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.16858251e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.51031866 9.16603329]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.72468543e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.84975448 9.06839107]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.42374084 7.12515082]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45702754  9.29264455]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.80998233 10.38944181]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.18104397e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.65928679 9.24942996]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.00858724e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.46954519 9.25207141]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.64887017 9.18997226]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.42374084 7.12515082]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45702754  9.29264455]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.79280924 10.39554947]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.62259067 9.32686427]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.98312418e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.3708434  9.33942104]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.54155878 9.25320592]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.42374084 7.12515082]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.71345826e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45702754  9.29264455]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.74474198 10.43354315]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.80843943e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.53375906 9.40547893]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.92148487e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.68038316 9.46493104]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20464516e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.81234484 9.51843794]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.42279593 9.46050134]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.13989776 8.91080349]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.42374084 7.12515082]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.46735707 9.29457207]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.45689171 8.67323057]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.42374084 7.12515082]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.87540924e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.61643522 9.11657826]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.92634265 9.01003255]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.42374084 7.12515082]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45702754  9.29264455]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.81894508 10.36340288]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.97885298e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.47875467 9.16230215]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.69074936 9.15037743]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.42374084 7.12515082]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.4560918   9.29168343]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.81894508 10.36340288]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.73159364e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.4560918   9.29168343]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.80097441 10.3466223 ]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.88331791e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.31567708 9.24130204]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.33652938e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.69074936 9.15037743]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.28817016 7.22272638]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.69074936 9.15037743]\n",
      "  [6.50828124 7.05421572]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.69074936 9.15037743]\n",
      "  [6.33044036 7.18725883]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.33769021 8.47714205]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.69074936 9.15037743]\n",
      "  [6.33044036 7.18725883]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.38923487 9.37721995]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.4560918   9.29168343]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.72675803 10.36983197]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.7701601e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [7.71353249 9.371539  ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.69074936 9.15037743]\n",
      "  [6.33044036 7.18725883]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.78003043 9.43722557]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.35233835e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [7.56877841 9.46065973]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.70459118e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.69074936 9.15037743]\n",
      "  [6.33044036 7.18725883]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.58071843 9.86654557]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.4560918   9.29168343]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.39089038 10.46917988]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [7.81190057 9.51459376]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [7.53823766 9.70391511]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [4.5662907e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.69074936 9.15037743]\n",
      "  [6.33044036 7.18725883]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.37279594 9.64994616]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.47981361e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.4560918   9.29168343]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.21074025 10.61615598]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [7.3182372  9.71193602]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.69074936 9.15037743]\n",
      "  [6.33044036 7.18725883]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.26883469 9.54164645]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.47981361e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.31048262  8.86251509]\n",
      "  [ 3.13289544  0.32372175]]\n",
      "\n",
      " [[ 6.21074025 10.61615598]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.37877694e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "QTable: [[[ 6.31048262  8.86251509]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.21074025 10.61615598]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.72435843e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[6.3315539  8.53004581]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [7.73541834 9.51611898]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.33652938e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.93954202 8.8816363 ]\n",
      "  [6.33044036 7.18725883]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.26883469 9.54164645]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.36752472e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [7.96187651 9.56450708]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.52466164e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.15675506 9.33490806]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.23247303 8.67478138]\n",
      "  [6.33044036 7.18725883]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.26883469 9.54164645]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.6598858e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.34107955 9.40141726]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.78778661e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86439146 7.35233732]\n",
      "  [8.5069716  9.46127553]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.7708692e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.83498437 7.46067887]\n",
      "  [8.5069716  9.46127553]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.83498437 7.46067887]\n",
      "  [8.54647501 9.20055032]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.53482652 8.51761081]\n",
      "  [6.33044036 7.18725883]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.26883469 9.54164645]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.93030834e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.83608219 7.41055956]\n",
      "  [8.54647501 9.20055032]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.83608219 7.41055956]\n",
      "  [8.68716811 9.00731948]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.79160631 8.30381144]\n",
      "  [6.33044036 7.18725883]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.26883469 9.54164645]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.17943436  8.47626358]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.21074025 10.61615598]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.17943436  8.47626358]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.58023737 10.41100578]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.02793379e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.83608219 7.41055956]\n",
      "  [8.46022658 8.82518432]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.27989379 8.18197945]\n",
      "  [6.33044036 7.18725883]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.26883469 9.54164645]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.87046147e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.83608219 7.41055956]\n",
      "  [8.61420392 8.94266589]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.97730471e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.83608219 7.41055956]\n",
      "  [8.61905948 8.74412472]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.77204184 8.75539204]\n",
      "  [6.33044036 7.18725883]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.26883469 9.54164645]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.5659569e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.17943436  8.47626358]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.73774248 10.20315278]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.98067393e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86566489 7.20292967]\n",
      "  [8.61905948 8.74412472]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.98067393e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86566489 7.20292967]\n",
      "  [8.41834648 8.87421918]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.25335951 8.42738369]\n",
      "  [6.33044036 7.18725883]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.26883469 9.54164645]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.87562221 7.38232314]]\n",
      "\n",
      " [[6.86566489 7.20292967]\n",
      "  [8.57651183 8.98679726]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.95115056e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86841584 7.28588047]]\n",
      "\n",
      " [[6.86566489 7.20292967]\n",
      "  [8.57651183 8.98679726]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.95115056e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86841584 7.28588047]]\n",
      "\n",
      " [[6.86566489 7.20292967]\n",
      "  [8.58959972 8.86435211]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.56251964 8.25943269]\n",
      "  [6.33044036 7.18725883]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.26883469 9.54164645]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86841584 7.28588047]]\n",
      "\n",
      " [[6.8578403  6.90523791]\n",
      "  [8.58959972 8.86435211]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.97635681 8.71097746]\n",
      "  [6.33044036 7.18725883]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.26883469 9.54164645]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.17943436  8.47626358]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.80471113 10.14731723]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.96023211e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86841584 7.28588047]]\n",
      "\n",
      " [[6.8578403  6.90523791]\n",
      "  [8.73063975 8.97791689]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05809829e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86841584 7.28588047]]\n",
      "\n",
      " [[6.8578403  6.90523791]\n",
      "  [8.5558626  8.97334943]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.53470937e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.71006286 8.91441562]\n",
      "  [6.33044036 7.18725883]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.26883469 9.54164645]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.17943436  8.47626358]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.8247006  10.16299839]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.93682228e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86841584 7.28588047]]\n",
      "\n",
      " [[6.8578403  6.90523791]\n",
      "  [8.70027634 9.07601449]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03702944e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.86841584 7.28588047]]\n",
      "\n",
      " [[6.8578403  6.90523791]\n",
      "  [8.8302487  9.16841304]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12721589e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9663074  7.31030545]]\n",
      "\n",
      " [[6.8578403  6.90523791]\n",
      "  [8.8302487  9.16841304]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12721589e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9663074  7.31030545]]\n",
      "\n",
      " [[6.8578403  6.90523791]\n",
      "  [8.94722383 9.25157173]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20838369e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9663074  7.31030545]]\n",
      "\n",
      " [[6.8578403  6.90523791]\n",
      "  [8.55763706 9.19155212]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.71006286 8.91441562]\n",
      "  [6.24924532 7.15939566]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.26883469 9.54164645]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.34987788e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.71006286 8.91441562]\n",
      "  [6.24924532 7.15939566]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.36429759 9.83602258]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.17943436  8.47626358]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.83540513 10.25812004]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9663074  7.31030545]]\n",
      "\n",
      " [[6.8578403  6.90523791]\n",
      "  [7.82453756 9.53018509]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [8.83223714e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.71006286 8.91441562]\n",
      "  [6.24924532 7.15939566]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.81196382 9.73008533]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.4293636e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.9663074  7.31030545]]\n",
      "\n",
      " [[6.8578403  6.90523791]\n",
      "  [8.04208381 9.57716658]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.20793923 7.54718686]]\n",
      "\n",
      " [[6.8578403  6.90523791]\n",
      "  [8.04208381 9.57716658]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.72674942e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.71006286 8.91441562]\n",
      "  [6.24924532 7.15939566]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [7.12281543 9.6959093 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.58031663e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.20793923 7.54718686]]\n",
      "\n",
      " [[6.8578403  6.90523791]\n",
      "  [7.87016808 9.66694701]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.94244606e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.71006286 8.91441562]\n",
      "  [6.24924532 7.15939566]]\n",
      "\n",
      " [[6.22038482 7.27151416]\n",
      "  [6.79556977 9.95120266]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.17943436  8.47626358]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.56576979 10.49583882]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.46102613e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.20793923 7.54718686]]\n",
      "\n",
      " [[6.8578403  6.90523791]\n",
      "  [7.65331194 9.81395457]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.71537376e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.71006286 8.91441562]\n",
      "  [6.24924532 7.15939566]]\n",
      "\n",
      " [[5.82842032 7.61623815]\n",
      "  [6.79556977 9.95120266]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.71537376e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.71006286 8.91441562]\n",
      "  [6.24924532 7.15939566]]\n",
      "\n",
      " [[5.82842032 7.61623815]\n",
      "  [6.95910966 9.90118316]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.31055196e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.20793923 7.54718686]]\n",
      "\n",
      " [[6.8578403  6.90523791]\n",
      "  [7.61029984 9.86745055]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.65770472e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.82842032  7.61623815]\n",
      "  [ 6.60586275 10.14892711]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.17943436  8.47626358]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.32700483 10.69489963]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.28070631e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.20793923 7.54718686]]\n",
      "\n",
      " [[6.8578403  6.90523791]\n",
      "  [7.84926985 9.88070549]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.44652507e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.20793923 7.54718686]]\n",
      "\n",
      " [[6.8578403  6.90523791]\n",
      "  [8.06434287 9.89263494]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.59576196e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 6.20793923  7.54718686]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 7.67451653 10.00588832]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.58373808e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.82842032  7.61623815]\n",
      "  [ 6.87273799 10.07681888]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.06505312e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 6.20793923  7.54718686]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 7.58635346 10.03367171]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.82842032  7.61623815]\n",
      "  [ 6.97091038 10.05187812]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.26409018e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 6.20793923  7.54718686]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 7.58154088 10.03758711]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.83704075e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.82842032  7.61623815]\n",
      "  [ 7.01807154 10.0409739 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.26075078e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 6.20793923  7.54718686]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 7.82338679 10.03382839]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.42856509e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 6.20793923  7.54718686]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 8.04104811 10.03044556]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.11591959e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 6.20793923  7.54718686]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 7.82775267 10.03161234]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.86976538e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.72143878  7.82450863]\n",
      "  [ 7.01807154 10.0409739 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.86976538e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.72143878  7.82450863]\n",
      "  [ 6.5398377  10.2984468 ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.39024153e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.17943436  8.47626358]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.29460349 10.86009475]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.43159453e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 6.20793923  7.54718686]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 8.04497741 10.02845111]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.58232447e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 8.04497741 10.02845111]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.47665447  8.03163304]\n",
      "  [ 6.5398377  10.2984468 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.07584799e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.47665447  8.03163304]\n",
      "  [ 6.28776025 10.4932613 ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.17943436  8.47626358]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.36529271 10.94142782]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 7.5375928  10.21153007]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 6.28776025 10.4932613 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [8.72602025e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 6.65891724 10.33124268]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.23025567e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 7.4323633  10.23826211]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.62055203e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 6.80240394 10.26092618]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 7.43714323 10.22350153]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.72011592e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 6.87605926 10.2198637 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.03211096e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 7.46899532 10.19969625]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.77122457e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 6.92562776 10.18981035]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 7.72209579 10.17972662]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.35828034e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 7.94988621 10.16175396]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 8.15489759 10.14557856]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.65859691e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 8.33940783 10.13102071]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 7.93995502 10.14143449]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.61123925e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 7.13879589 10.15147897]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.10189011e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 7.82549586 10.13130884]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.95353472e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 7.19959629 10.12826302]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.43002855e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 8.04294628 10.11817795]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.58091509e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.8578403   6.90523791]\n",
      "  [ 7.90131165 10.11039418]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.99572348e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 7.26032281 10.10828918]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.48263633e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 7.90131165 10.11039418]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.03786097e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 7.29068606 10.09830227]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.48263633e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 8.11118049 10.09935477]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.62826208e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 7.97186467 10.08899829]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.01178594e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 6.69146011 10.42572226]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.17943436  8.47626358]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.37139222 11.00631322]\n",
      "  [ 7.67368698  8.52848959]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 8.1746782  10.08009846]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.67232247e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 7.76392315 10.21033813]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.64313318e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 6.39428695 10.61538642]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.42104146e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.17943436  8.47626358]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.37139222 11.00631322]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[6.27134621 8.84915816]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 7.43967635 10.35132363]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.43692787e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 6.67301401 10.44822266]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 7.69570872 10.31619127]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 7.92613784 10.28457214]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.09997259e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 7.63227453 10.32157514]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 6.38506389 10.62663662]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.42104146e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.17943436  8.47626358]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.23860592 11.13178667]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 7.86904707 10.28941762]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.46024828e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 8.08214237 10.26047586]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.60811284e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 7.59509674 10.38089258]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.43052809e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 6.24924532  7.15939566]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 6.73057064 10.46567534]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.27015705e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 7.48977663 10.37671643]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 5.81685092  7.76596797]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 6.73057064 10.46567534]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.67027156e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 5.81685092  7.76596797]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 6.86119597 10.38352424]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 7.4893667  10.34176791]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.76091109e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 5.81685092  7.76596797]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 6.42604036 10.64447679]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.32890246e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.17943436  8.47626358]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.11504964 11.2026005 ]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.1967921e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 7.74043003 10.30759112]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.37100228e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 7.96638703 10.27683201]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.52779144e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 7.55360966 10.39620672]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.45896122e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.71006286 8.91441562]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.25343133 8.21312104]\n",
      "  [6.18479392 9.71274383]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 8.57568788e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.06149092  8.12863722]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.11504964 11.2026005 ]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.06149092  8.12863722]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.07896868 11.25978294]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.71990469  7.89297215]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 7.2507224  10.08320089]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [8.58312577e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.71006286 8.91441562]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.25343133 8.21312104]\n",
      "  [6.49268592 9.88965227]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.71990469 7.89297215]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [7.22243557 9.99746135]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.01041175e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 5.81685092  7.76596797]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 6.17793043 10.44873931]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.06149092  8.12863722]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 5.92845857 11.12887601]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [7.22243557 9.99746135]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.71006286  8.91441562]\n",
      "  [ 5.81685092  7.76596797]]\n",
      "\n",
      " [[ 5.25343133  8.21312104]\n",
      "  [ 6.47793944 10.2233542 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.01157141e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 3.76300095  4.04288624]\n",
      "  [ 5.33112452  8.1259818 ]]\n",
      "\n",
      " [[ 6.33304927  7.49593463]\n",
      "  [ 7.20239356 10.08807235]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.71006286 8.91441562]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.25343133 8.21312104]\n",
      "  [6.16356609 9.36313199]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.95534183  7.8157735 ]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 5.92845857 11.12887601]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.13234851e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.85980765  7.53419615]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 5.92845857 11.12887601]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.85980765  7.53419615]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 5.84518671 11.09966695]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [7.06662322 9.78928897]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.71006286 8.91441562]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.25343133 8.21312104]\n",
      "  [5.92570611 8.69524445]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.85980765  7.53419615]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 5.74924264 10.96554906]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.90345488e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [7.3599609  9.81036007]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [7.05026289 9.38327782]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.71006286 8.91441562]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.25343133 8.21312104]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.85980765  7.53419615]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 5.69472648 10.73608566]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.89210262e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [7.3452366  9.44495004]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.09678175e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [7.75664344 9.28824127]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.95768881 8.67250432]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.25343133 8.21312104]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.06139724 9.11312236]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.32276746 7.84993062]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.25343133 8.21312104]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.06605836e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.77382688  7.28077653]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 5.69472648 10.73608566]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.6964442   7.05269888]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 5.69472648 10.73608566]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 3.95270219e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.62679978  6.84742899]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 5.69472648 10.73608566]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.62679978  6.84742899]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.07192214 10.51329177]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.59371802e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.25525752 9.20181012]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.72823561e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.42973177 9.28162911]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.58675859 9.3534662 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.72808273 9.41811958]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05632401e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.29314835 8.84903204]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.08119065e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.97864307 7.96457812]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.25343133 8.21312104]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.75452765e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.3380314  8.61034727]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.97864307 7.96457812]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.53629578e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.41809039 8.68760577]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.62679978  6.84742899]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.37117363 10.20078479]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.13625186 8.78021594]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.96354594 8.35588926]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.32262667 8.90219435]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.77498235e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.490364   9.01197491]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.43060038 8.84834316]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.35401312 8.2172819 ]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.55690544 8.71108434]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.59976873 8.09307468]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.9375459e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.71836021 8.59277204]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.78722845 7.98364616]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.87407149 8.48984449]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.09736459e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.94208368 8.572137  ]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.42088979e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[5.62679978 6.84742899]\n",
      "  [5.78985493 3.47807799]]\n",
      "\n",
      " [[6.73521541 9.99633019]\n",
      "  [7.36946505 8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15762405e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.61386921 8.67377704]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.665128   8.78460057]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[5.62679978 6.84742899]\n",
      "  [5.78985493 3.47807799]]\n",
      "\n",
      " [[6.81315539 9.96767591]\n",
      "  [7.36946505 8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.75248229 8.80639934]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.87723406 8.9257594 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15981853e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.98951066 9.03318346]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [9.09055959 9.12986512]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.30784285e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [9.18150363 9.21687861]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.37094796e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [9.26335327 9.29519074]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [9.33701794 9.36567167]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.47885769e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [9.40331615 9.4291045 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.52486131e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [9.46298453 9.48619405]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.56626457e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.79754347 9.25693726]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.55782616 8.87937065]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.62679978  6.84742899]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.92559508 10.18661286]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.33304927 7.49593463]\n",
      "  [8.4219022  9.18021689]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.54915111 9.01433047]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.80559695e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.62679978  6.84742899]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.83155842 10.26539318]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.84386858e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.18618508 7.3536995 ]\n",
      "  [8.4219022  9.18021689]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.23827586e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.14333643 8.67925199]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.18618508 7.3536995 ]\n",
      "  [8.46828567 9.06180924]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.45898249 8.46434969]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.18618508 7.3536995 ]\n",
      "  [8.62145711 9.15562832]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.19646752e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.18618508 7.3536995 ]\n",
      "  [8.69432155 8.96355403]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.96211461 8.83833212]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.74034591e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.62679978  6.84742899]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.89350783 10.21811821]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03289748e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.18618508 7.3536995 ]\n",
      "  [8.82488939 9.06719863]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12349712e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.18618508 7.3536995 ]\n",
      "  [8.94240045 9.16047877]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.18618508 7.3536995 ]\n",
      "  [9.04816041 9.24443089]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27842251e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.18618508 7.3536995 ]\n",
      "  [8.70892605 9.15754829]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.46462772 8.58218538]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04303139e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.18618508 7.3536995 ]\n",
      "  [8.83803344 9.24179346]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13261764e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.18618508 7.3536995 ]\n",
      "  [8.80486781 9.05377088]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.87351537e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.98971699 8.87833997]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.78333195e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.62679978  6.84742899]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.96870104 10.23056746]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22192087e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.33112452 8.1259818 ]]\n",
      "\n",
      " [[6.61503967 7.2983581 ]\n",
      "  [8.80486781 9.05377088]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10960436e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.61503967 7.2983581 ]\n",
      "  [8.80486781 9.05377088]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.78233891 9.03139697]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.83550772e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.62679978  6.84742899]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.00629764 10.23679208]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22192087e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.61503967 7.2983581 ]\n",
      "  [8.51536947 9.13944423]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.29731724 8.67147618]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.61503967 7.2983581 ]\n",
      "  [8.66383252 9.22549981]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.66383252 9.22549981]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01174147e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.79744927 9.30294983]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10445671e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.71765153 9.12006538]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.7574204e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.95117768 8.93045492]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.62679978  6.84742899]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.99020944 10.26642219]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.53929684 9.13221466]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.39130758 8.61811332]\n",
      "  [5.81685092 7.76596797]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.62617145 9.01335266]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.39130758 8.61811332]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.99173756 8.91562554]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.62679978  6.84742899]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.9455733  10.23855216]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.7635543  9.11201739]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.88719887 9.20081565]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16673301e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.99847899 9.28073409]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2439491e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [9.09863109 9.35266068]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [9.18876798 9.41739461]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [9.26989118 9.47565515]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.28645583e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.83164062 9.30407779]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.54538191e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.52852503 8.67944389]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22563634e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.82723032 9.12381645]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.04249183 8.93514281]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.81945962e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.62679978  6.84742899]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.00367878 10.26880266]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.63061189 9.13596535]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.47349067 8.62195754]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.98869002e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.7675507  9.22236881]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.89079563 9.30013193]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16922876e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [9.00171607 9.37011874]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.24923906e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.8902543  9.13384239]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.79284706 8.46451573]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16885314e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.96226598 8.95272748]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.19789504 8.83977893]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[5.8181729  7.29239177]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.62679978  6.84742899]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.08674578 10.21549232]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.21882127e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.760291   9.01227531]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.19789504 8.83977893]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.60306392 8.52479959]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07867298e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.82137107 8.91605749]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.13623027 8.84859672]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.91741771e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.62679978  6.84742899]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.07192132 10.17416916]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [5.86144906 7.61432689]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.66517764 8.99746744]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.89688366 8.99396603]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.62679978  6.84742899]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.00203172 10.18607155]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.66517764 8.99746744]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.74925452 9.07141163]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.85863552e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.11421257  7.99814312]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.00203172 10.18607155]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.85863552e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.11421257  7.99814312]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.96708692 10.19202275]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01267483e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.77305284 7.33937897]\n",
      "  [8.43229063 9.12729837]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.66146203 9.11251492]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.11421257  7.99814312]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.85645971 10.24693072]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.75944267 7.32060884]\n",
      "  [8.43229063 9.12729837]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.000000e+00 1.000000e+00]\n",
      " [5.851077e-17 1.000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.75944267 7.32060884]\n",
      "  [8.28073012 9.20865515]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.14302306 8.73971952]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.63693056 7.15619223]\n",
      "  [8.28073012 9.20865515]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.81409542 8.96863205]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.75762465e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.11421257  7.99814312]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.7405219  10.30692742]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.74591078e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.63693056 7.15619223]\n",
      "  [8.26600323 9.1917804 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.60325647 9.10708699]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.11421257  7.99814312]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.67666224 10.33017587]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.73569194e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.63693056 7.15619223]\n",
      "  [8.43940291 9.27260236]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.85601214e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.63693056 7.15619223]\n",
      "  [8.59546261 9.34534212]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.63693056 7.15619223]\n",
      "  [8.73591635 9.41080791]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.06175967e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.63693056 7.15619223]\n",
      "  [8.86232472 9.46972712]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.63693056 7.15619223]\n",
      "  [8.47246495 9.37769836]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.19061421 8.80462284]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.87895354e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.63693056 7.15619223]\n",
      "  [8.51247816 9.21069831]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.6833803e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.765972   9.03438177]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.22777118  8.63114191]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.67666224 10.33017587]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.63286509e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.22777118  8.63114191]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.74332239 10.34936726]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.63693056 7.15619223]\n",
      "  [8.66123034 9.28962848]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.78295742 7.29394751]\n",
      "  [8.66123034 9.28962848]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.66123034 9.28962848]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.00993584e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.79510731 9.36066563]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10283165e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.91559658 9.42459907]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.56418709 9.32605224]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.30866084 8.74761178]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.60555788 9.16207083]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.85165937 9.01355279]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.67911986e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.22777118  8.63114191]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.81388434 10.33951196]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.44344269 9.18645653]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.30320676 8.68135901]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.8588153e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.54300405 9.06577187]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.76150708e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.568805   8.46698825]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.92789987e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.08947799 7.40474985]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.68870364 9.15919468]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.02899928e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.52022046 7.3660528 ]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.68870364 9.15919468]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.52022046 7.3660528 ]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.77187382 8.96639264]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.00995624 8.86929891]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.22777118  8.63114191]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.9156917  10.25631304]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08671018e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.52022046 7.3660528 ]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.89468644 9.06975338]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23438571e-16 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.46409272 7.23074597]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.89468644 9.06975338]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.55802365e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.5628527  8.56255081]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.46409272 7.23074597]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [9.0052178  9.16277804]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.46409272 7.23074597]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [9.10469602 9.24650024]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31765197e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.46409272 7.23074597]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [9.19422642 9.32185021]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.37977616e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.46409272 7.23074597]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [9.02225429 9.08594543]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.94167264e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.04770303 8.88380062]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.22777118  8.63114191]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.06674757 10.26253469]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.26044653e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.46409272 7.23074597]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.73020835 9.09649296]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.51593486 8.5804975 ]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05779895e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.46409272 7.23074597]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.85718752 9.18684367]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.85718752 9.18684367]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.90911685e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.80084244 8.46498621]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14590845e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.97146877 9.2681593 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22520699e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [9.00607136 9.02007414]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.22712024 8.83750698]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.90354116e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.22777118  8.63114191]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.13580233 10.239297  ]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24921736e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [9.10546422 9.11806672]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31818502e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [9.1949178  9.20626005]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.38025591e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [9.27542602 9.28563404]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.85597085 7.36282515]\n",
      "  [8.92856111 9.17781982]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.68498456 8.58988142]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.92856111 9.17781982]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19543382e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.035705   9.26003783]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.26977983e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.99184632 9.06597148]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.19681321 8.89065951]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.95145753e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.22777118  8.63114191]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.16463969 10.24603709]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.09266169 9.15937434]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.30930148e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.82505613 9.13595097]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.62842906 8.59971014]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.86389969 9.00785954]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.98717538e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.8597744  8.40299889]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.18824446 7.18210746]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.97750972 9.10707359]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22939875e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.03266462 8.91473635]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.8597744  8.40299889]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.63803199 6.95225328]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.29574308 8.79991428]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.63803199 6.95225328]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.22777118  8.63114191]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.1953857  10.18891309]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.12939816 9.02326272]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.88299631 9.03159707]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.70107006 8.51259597]\n",
      "  [6.26494849 7.33022931]]\n",
      "\n",
      " [[6.63803199 6.95225328]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.99469668 9.12843736]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.6384203  7.04757198]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.09522701 9.21559363]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.26221631e-16 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95730096 7.21002344]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.09522701 9.21559363]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31108153e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95730096 7.21002344]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.02804153 9.0128352 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.70107006 8.51259597]\n",
      "  [6.61290227 7.07015304]]\n",
      "\n",
      " [[6.63803199 6.95225328]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.96175165 8.36143207]\n",
      "  [6.61290227 7.07015304]]\n",
      "\n",
      " [[6.63803199 6.95225328]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95730096 7.21002344]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.09872142 8.85099043]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.21846439e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.96175165 8.36143207]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.63803199 6.95225328]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.3590301  8.75628127]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.63803199 6.95225328]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.22777118  8.63114191]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.23718142 10.13485271]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95730096 7.21002344]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.18884928 8.96589138]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.37604503e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95730096 7.21002344]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.26996435 9.06930225]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95730096 7.21002344]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.34296792 9.16237202]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95730096 7.21002344]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.015096   9.08369852]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.78555345 8.51162004]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.63803199 6.95225328]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25547947e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.95730096 7.21002344]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.1135864  9.17532867]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.99287186 7.00965974]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.1135864  9.17532867]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.78555345 8.51162004]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.83323738 6.88077466]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.03821128 8.42594149]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.83323738 6.88077466]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.99287186 7.00965974]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.17207771 8.95804093]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.41397821 8.76691183]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.83323738 6.88077466]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.22777118  8.63114191]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.28742179 10.15064273]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.36440741e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.99287186 7.00965974]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.25486994 9.06223683]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.28437121e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.99287186 7.00965974]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.32938295 9.15601315]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.47355985e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.99287186 7.00965974]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.39644465 9.24041184]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.52009325e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.99287186 7.00965974]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.45680019 9.31637065]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.56197332e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.99287186 7.00965974]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.09399138 9.16495006]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.84458566 8.54943594]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.83323738 6.88077466]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.99287186 7.00965974]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.08482995 9.0022494 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.13716415e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.33726155 8.83497506]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.83323738 6.88077466]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.22777118  8.63114191]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.27764288 10.17622113]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.99287186 7.00965974]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.87731959 9.03511473]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.78513733e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.33726155 8.83497506]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.75152331 6.97437735]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.33726155 8.83497506]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.71955861 8.53153342]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.99287186 7.00965974]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.98958763 9.13160325]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.98425937 6.91744324]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.98958763 9.13160325]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.95561436 8.41840801]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.23777948e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.98425937 6.91744324]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.07703956 8.93316483]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.108623   8.28246994]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.29846145e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.98425937 6.91744324]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.18196898 8.77957039]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.46536865 8.71172342]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.22777118  8.63114191]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.31160903 10.09993872]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.98425937 6.91744324]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.97713195 8.87447456]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.87402949e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.15732794 8.8958372 ]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.31160903 10.09993872]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.2466573  10.09975918]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.98425937 6.91744324]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.07941876 8.98702711]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.30011235e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.98425937 6.91744324]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.80264055 9.05184843]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.59972019 8.56865797]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.98425937 6.91744324]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.84120835 8.9533874 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.9672546e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.19852301 8.82423266]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.15981199 10.13123455]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22696413e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.98425937 6.91744324]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.95708752 9.05804866]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.77153889 6.98841468]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.95708752 9.05804866]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.9631863  8.96461015]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.96811758e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.162741   10.18883674]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.77153889 6.98841468]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.66381828 9.11486839]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.84668955 9.05783977]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.04689781 10.24036573]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01173158e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.66381828 9.11486839]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01173158e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.79743645 9.20338155]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.53739405 9.22482669]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.33830239 8.71885056]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.60401798 9.09995357]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.98791032 8.95557157]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.88976763e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.9650561  10.26016429]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.97023679e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.49717312 9.13220541]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.54272622e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.39282441 8.63066795]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.89609828e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.64745581 9.21898487]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.00037784e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.78271023 9.29708638]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.9044392  9.36737775]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.80934937 9.13595605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.82369181e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.72015195 8.4697164 ]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.92841443 9.22236045]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.03557299 9.3001244 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [9.00584727 9.03794876]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.14609842 8.83892391]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.08486696 10.24526165]\n",
      "  [ 7.36946505  8.67626312]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24906187e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.761363   9.05454395]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.90699599 9.01756662]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.08486696 10.24526165]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[3.93820038 2.31098967]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[6.64021831 8.54639666]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.8852267  9.14908955]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16536454e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.60541175 9.18157142]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.78744478 9.10688797]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.98459818 10.29525939]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.41768379 9.2335409 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.2607959  8.74686034]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.84094147e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.51316025 9.11551459]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.92423722 8.99153393]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.84653857e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.89756319 10.29383553]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.42627502 9.15437087]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.49854414e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.72114389 9.11330118]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.8192916  10.30866611]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.84690283e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.58364751 9.23893378]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.19122039e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.38028131 9.26478736]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.58828858 9.18011703]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.76175833 10.360248  ]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.81498829e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.22545609 9.30444049]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.08432673 8.81183471]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.70755671e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.34645874 9.17695413]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.74686669 9.05001656]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.71946266 10.35090565]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.79151916e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.85129676 7.1401547 ]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.27197605 9.20848369]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.56121841 9.16537054]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.66852175 10.3588463 ]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.14796728e-16 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.27197605 9.20848369]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.14796728e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.16047539 9.27039006]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.4480179  9.22622379]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.62721649e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.59845103 10.38757918]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.13249346e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.05944486 9.32568455]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.94778689 8.84338571]\n",
      "  [6.89115179 6.87964935]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.59236328e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.20883719 9.20019656]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.94778689 8.84338571]\n",
      "  [6.62469065 6.97717896]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.000000e+00 0.000000e+00]\n",
      " [1.000000e+00 5.514885e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.25742832 8.60177148]\n",
      "  [6.62469065 6.97717896]]\n",
      "\n",
      " [[6.71066627 7.0211787 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.69602503e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99940987 7.3525405 ]\n",
      "  [8.38795347 9.2801769 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.85488632 7.38834101]\n",
      "  [8.38795347 9.2801769 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.85488632 7.38834101]\n",
      "  [8.49694806 9.08079704]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.7297419e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.25742832 8.60177148]\n",
      "  [6.62469065 6.97717896]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.52749339 8.43320456]\n",
      "  [6.62469065 6.97717896]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.89594211e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.85488632 7.38834101]\n",
      "  [8.65947139 8.91368034]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.9031271  8.87163395]\n",
      "  [6.62469065 6.97717896]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.76301407 10.25926173]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20174306e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[3.76300095 4.04288624]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.85488632 7.38834101]\n",
      "  [8.49098653 9.00549375]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.65676918 9.03952166]\n",
      "  [6.62469065 6.97717896]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.77790165 10.23182836]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.85488632 7.38834101]\n",
      "  [8.49098653 9.00549375]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.2247792  8.62195833]\n",
      "  [6.62469065 6.97717896]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.76754164e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.85488632 7.38834101]\n",
      "  [8.53540495 8.95153021]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.70708703e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.82355026 8.90371051]\n",
      "  [6.62469065 6.97717896]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.8031128  10.19652627]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.85488632 7.38834101]\n",
      "  [8.68186445 9.05637719]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.02425363e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.85488632 7.38834101]\n",
      "  [8.47035233 9.0896728 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.42867852e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.82355026 8.90371051]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.42867852e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.63302025 9.03046576]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 6.78969733 10.23413225]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.87748762e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.85488632 7.38834101]\n",
      "  [8.6233171  9.18070552]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.85488632 7.38834101]\n",
      "  [8.36486665 9.20253906]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.29647177e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.16245679 8.69624851]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.80429222e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.85488632 7.38834101]\n",
      "  [8.52837998 9.28228516]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.85488632 7.38834101]\n",
      "  [8.52917271 9.11964198]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.49289748 8.49598105]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.85488632 7.38834101]\n",
      "  [8.67625544 9.20767778]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.85488632 7.38834101]\n",
      "  [8.80862989 9.28691001]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.85488632 7.38834101]\n",
      "  [8.9277669  9.358219  ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23897655e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [8.9277669  9.358219  ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [9.03499021 9.4223971 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.26928385e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [9.13149119 9.48015739]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.33624486e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [9.21834207 9.53214165]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [9.29650787 9.57892749]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.45074818e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [9.04541292 9.18785616]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.96232767 8.84164342]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.01301384 10.29220859]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [9.14087163 9.26907055]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.34275384e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [8.75536688 9.17119264]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.48331059 8.58929877]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07525619e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [8.8798302  9.25407338]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16161996e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [8.83323933 9.0627562 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.77495103 8.41975186]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [8.9499154  9.15648058]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.21025134e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [9.05492386 9.24083252]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2831156e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [9.14943147 9.31674927]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.34869343e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [9.23448833 9.38507434]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [9.31103949 9.44656691]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [9.16550016 9.0911842 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.19268105 8.82675937]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.17270698 10.28257798]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.35984332e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [9.24895014 9.18206578]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [8.90154749 9.12173664]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.96542332 9.02641087]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.14697249 10.28998364]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17668936e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [9.01139274 9.20956297]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25290982e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [9.11025347 9.28860668]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [9.19922812 9.35974601]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [8.78578339 9.29043735]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.84150065 9.12919889]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 5.78985493  3.47807799]]\n",
      "\n",
      " [[ 7.0877996  10.36116676]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [8.52949195 9.29689823]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.33254711 8.78335874]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.91852397e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [8.59776482 9.16179261]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.00139339 9.03614608]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.65830446 6.95129794]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 7.05101479  5.15759766]]\n",
      "\n",
      " [[ 7.0877996  10.36116676]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "QTable: [[[5.62518751 4.5740535 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[6.64021831 8.54639666]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[5.62518751 4.5740535 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[6.75921508 8.43791537]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.96589779e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [8.73798834 9.24561335]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.0631974e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [8.56955153 9.23726511]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.00139339 9.03614608]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.55208198e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.42851731 8.71297908]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [5.80677611 8.36130069]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [8.71259637 9.3135386 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.99854992 7.43745811]\n",
      "  [8.84133674 9.38218474]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[7.03580966 7.47160295]\n",
      "  [8.84133674 9.38218474]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13490976e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[7.03580966 7.47160295]\n",
      "  [8.95720306 9.44396626]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.21530817e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[7.03580966 7.47160295]\n",
      "  [8.85000845 9.20717476]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[8.42851731 8.71297908]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 7.05101479  5.15759766]]\n",
      "\n",
      " [[ 7.08390318 10.36345329]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[7.03580966 7.47160295]\n",
      "  [8.96500761 9.28645729]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[7.03580966 7.47160295]\n",
      "  [8.85391073 9.12842028]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.04781993 9.00187085]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.91544526e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 7.05101479  5.15759766]]\n",
      "\n",
      " [[ 7.08351588 10.33309475]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14363472e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[7.03580966 7.47160295]\n",
      "  [8.64608333 9.16495848]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.4823433  8.66691882]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99942549e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.97633816 7.40178487]\n",
      "  [8.64608333 9.16495848]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99942549e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.97633816 7.40178487]\n",
      "  [8.71597899 9.04924677]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.72756324 8.45315812]\n",
      "  [6.44176543 7.05007368]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.97633816 7.40178487]\n",
      "  [8.84438109 9.14432209]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.97633816 7.40178487]\n",
      "  [8.91321584 8.95342429]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.72756324 8.45315812]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.92906796 8.30794878]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23695718e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.97633816 7.40178487]\n",
      "  [9.02189426 9.05808186]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.97633816 7.40178487]\n",
      "  [9.11970483 9.15227368]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.97633816 7.40178487]\n",
      "  [9.1314796  8.89931635]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.29794033 8.78721229]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 7.05101479  5.15759766]]\n",
      "\n",
      " [[ 7.19434978 10.22627392]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.97633816 7.40178487]\n",
      "  [8.88491593 8.96454309]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.02671008 8.98411571]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.99208298e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 7.05101479  5.15759766]]\n",
      "\n",
      " [[ 7.15114126 10.19895419]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.1651489e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.97633816 7.40178487]\n",
      "  [8.653142   9.07591783]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.87381154 9.07163953]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 7.05101479  5.15759766]]\n",
      "\n",
      " [[ 7.03682743 10.22984423]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.00432343e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.97633816 7.40178487]\n",
      "  [8.47609562 9.16661473]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.32734402 8.70246566]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.88147282e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.97633816 7.40178487]\n",
      "  [8.56898542 9.06429363]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.59126618 8.47695028]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.97633816 7.40178487]\n",
      "  [8.72099918 8.92292693]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.11036406 8.83041283]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 7.05101479  5.15759766]]\n",
      "\n",
      " [[ 7.00681339 10.18409288]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.97633816 7.40178487]\n",
      "  [8.60464521 8.9936286 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.85790738 8.98884357]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.00681339 10.18409288]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.69014763e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[5.62518751 4.5740535 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[6.82146563 8.31640913]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.97633816 7.40178487]\n",
      "  [8.44548556 9.09235173]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.73167905 9.06805894]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.88160092 10.22898713]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.17204657e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.97633816 7.40178487]\n",
      "  [8.3154144  9.17339944]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.36493006e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.61847989 9.12562432]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.77506987e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.76696622 10.28385334]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.76997783e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.97633816 7.40178487]\n",
      "  [8.48387296 9.25605949]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.88686944e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.88171826 7.40331623]\n",
      "  [8.48387296 9.25605949]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.88686944e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.88171826 7.40331623]\n",
      "  [8.28932844 9.27827948]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.12497132 8.77412395]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.75187705e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.88171826 7.40331623]\n",
      "  [8.39465275 9.14878932]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.42034676 8.5465777 ]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.88171826 7.40331623]\n",
      "  [8.56546508 8.99302574]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.91695987 8.88683019]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5385292   8.85554644]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.80966914 10.23913697]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.56546508 8.99302574]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.94348534e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.70891857 9.09372317]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.52124323 9.10159366]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.36697723 8.58405256]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.91280027e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.66911891 9.19143429]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01540963e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.68135034 9.02933817]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.80575673e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.65602875 8.40376155]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.81321531 9.12640435]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.93189378 9.21376392]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19774633e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [9.0387044  9.29238753]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.9817637  9.00769838]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.92071986 8.30496013]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.23235054e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [9.05916979 8.82583324]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.08402784 8.18281336]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2860618e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [9.16319603 8.68604196]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.26588158 8.68706147]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.49313226  9.02342801]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.80966914 10.23913697]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49313226  9.02342801]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.07011298 10.09398527]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.88795065 8.81784557]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.73560753e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.68812105 8.37066896]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.7344388  7.25347082]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.99915558 8.93606101]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.99915558 8.93606101]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.94372276 8.25975889]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [9.07706689 8.77193406]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.10268814 8.13865307]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.29848041e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [9.1796087  8.64142826]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.37938926 8.60692064]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.90587639e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49313226  9.02342801]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.20689997 10.00356394]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.94156006 8.76348238]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.07245462 8.8048859 ]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49313226  9.02342801]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.18007401 10.00717492]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [9.04740405 8.88713415]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27789768e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.75268387 8.96552143]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.53730086 8.48865152]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07339448e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.87741549 9.06896929]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15994442e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.85362809 8.92994525]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.14068003 8.74719573]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49313226  9.02342801]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.13148824 10.07556556]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.1434386e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.68308606 8.96385092]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.92293531 8.90382409]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.94846403e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49313226  9.02342801]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.03897854 10.12332315]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.81477745 9.06746583]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.11648055e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.93329971 9.16071924]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19872189e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.63582398 9.14188926]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.77705907 9.0012413 ]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49313226  9.02342801]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.97381886 10.21841728]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.77224158 9.22770033]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08696536e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.49694442 9.21434669]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.67805708 9.08798756]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49313226  9.02342801]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.8856872  10.29494731]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.64724998 9.29291202]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.78252498 9.36362082]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.46248532 9.31700543]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.32772235e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.59330342 9.16197271]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49313226  9.02342801]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.82783773 10.37427583]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.26856403 9.3232918 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.10407732 8.81030307]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.44170763 9.39096262]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.85761136e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.46248474 9.21960254]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.78317375 9.05486187]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.2385079  9.32511705]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49313226  9.02342801]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.79891276 10.37497893]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.87202838e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.61623627 9.29764229]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.86704516 7.29886841]\n",
      "  [8.42138763 9.27076589]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.40066169e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.78317375 9.05486187]\n",
      "  [6.71190801 6.90630009]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.987809   9.37086488]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [8.42138763 9.27076589]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.84351153e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [8.57924887 9.3436893 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.95304977e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [8.72132398 9.40932037]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [8.84919159 9.46838833]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14036015e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [8.21971939 9.48254012]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.69753306e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.78317375 9.05486187]\n",
      "  [6.15107761 7.201496  ]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.987809   9.37086488]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.78317375 9.05486187]\n",
      "  [6.15107761 7.201496  ]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.71346961 9.83542401]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49313226  9.02342801]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.68734414 10.48050551]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.70357608e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [7.79524754 9.67543966]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.65840533e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.78317375  9.05486187]\n",
      "  [ 6.15107761  7.201496  ]]\n",
      "\n",
      " [[ 6.52970959  7.0901074 ]\n",
      "  [ 6.53167246 10.10991421]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.64027715e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49313226  9.02342801]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.46177108 10.61042862]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.40903956e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [7.51029275 9.88168552]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.53225822e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.78317375  9.05486187]\n",
      "  [ 6.15107761  7.201496  ]]\n",
      "\n",
      " [[ 6.52970959  7.0901074 ]\n",
      "  [ 6.76995333 10.00763131]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.04226249e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [7.46312771 9.94389528]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.78317375 9.05486187]\n",
      "  [6.15107761 7.201496  ]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.87022775 9.98137377]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [7.71681494 9.94950575]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.35461601e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [7.60649857 9.96730239]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.76717814e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.78317375 9.05486187]\n",
      "  [6.15107761 7.201496  ]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.53236678 9.60005809]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.50551558e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.34381903  8.62108521]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.46177108 10.61042862]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.4837544e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.34381903  8.62108521]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.27348497 10.79213527]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.05561373e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [7.84584871 9.97057215]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [7.53587107 9.82530931]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000e+00 1.00000e+00]\n",
      " [4.53274e-17 1.00000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.78317375 9.05486187]\n",
      "  [6.15107761 7.201496  ]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.303711   9.24846313]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.40190872e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.20943713  8.25897669]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.27348497 10.79213527]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.35310466e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.20943713  8.25897669]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.15109091 10.82619136]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.22906098e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [7.28941993 9.6120399 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.78317375 9.05486187]\n",
      "  [6.15107761 7.201496  ]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.56762347 9.46904753]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.05805115e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [7.27175936 9.59363896]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.55720425e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.78317375 9.05486187]\n",
      "  [6.15107761 7.201496  ]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.69251548 9.57197935]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.04579667e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [7.54458342 9.63427507]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.23510639e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [7.79012508 9.67084756]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [8.01111257 9.7037628 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.55882602e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [8.21000131 9.73338652]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.80207764 7.35774056]\n",
      "  [7.78200685 9.695485  ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.28773097e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.78317375 9.05486187]\n",
      "  [6.15107761 7.201496  ]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.33003259 9.08958035]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.30866254e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.08849342  7.93307902]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.15109091 10.82619136]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.26817672e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.08849342  7.93307902]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.1883482  10.79128968]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.39985199e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [7.78200685 9.695485  ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.00380616 9.7259365 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.55375618e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [7.53391612 9.49880039]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.39234246e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[7.78317375 9.05486187]\n",
      "  [6.15107761 7.201496  ]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.08849342  7.93307902]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.10774055 10.69516499]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [7.88022756 9.37134494]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.33468309 9.30549693]\n",
      "  [6.15107761 7.201496  ]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.08849342  7.93307902]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.2059613  10.59612047]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.4680063e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.0922048  9.43421045]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.28298432 9.4907894 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.45468589 9.54171046]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.17332337e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.84246782 6.975003  ]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.6092173  9.58753942]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.97384455e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.6092173  9.58753942]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.08945878e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.11102847 8.98776423]\n",
      "  [6.15107761 7.201496  ]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.19476891e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.54902004 9.3888754 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.47512225 8.74943228]\n",
      "  [6.15107761 7.201496  ]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.66455892 9.19421061]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.71994564 9.11316433]\n",
      "  [6.15107761 7.201496  ]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.3062507e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.08849342  7.93307902]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.56880422 10.47574448]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.42025772 9.24237104]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.22807591 8.75353058]\n",
      "  [6.15107761 7.201496  ]]\n",
      "\n",
      " [[6.52970959 7.0901074 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.84272749e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.57823195 9.31813393]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.95234413e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.58034634 9.1604792 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.22807591 8.75353058]\n",
      "  [6.15107761 7.201496  ]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.70937458e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.22807591 8.75353058]\n",
      "  [6.36676917 7.10216023]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.54617649 8.54095697]\n",
      "  [6.36676917 7.10216023]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.7223117  9.24443128]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.21046391e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.77962645 9.03859843]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.78493882 8.38591786]\n",
      "  [6.36676917 7.10216023]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.21841793e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.90378875 8.87366636]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.95398491 8.24242547]\n",
      "  [6.36676917 7.10216023]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17824455e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [9.01340988 8.98629972]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [9.11206889 9.08766975]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.32276793e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [9.13762841 8.84080506]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.13204382 8.15753476]\n",
      "  [6.36676917 7.10216023]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [9.22386557 8.95672456]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [9.30147901 9.0610521 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.4541976e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [9.30355703 8.79353995]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.1935436  8.76906517]\n",
      "  [6.36676917 7.10216023]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.08849342  7.93307902]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.00582492 10.25528822]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.92919596 8.90439605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.66845018 8.446291  ]\n",
      "  [6.36676917 7.10216023]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.93197805 8.83071442]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.13655506 8.82526079]\n",
      "  [6.36676917 7.10216023]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.08849342  7.93307902]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.07570368 10.15992988]\n",
      "  [ 7.19327101  8.87779482]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.1978048e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [9.03878024 8.94764298]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27191371e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.77401215 9.00392581]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.898559   8.97660235]\n",
      "  [6.36676917 7.10216023]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.08849342  7.93307902]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.07570368 10.15992988]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.73334262e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[5.62518751 4.5740535 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[6.92033767 8.25977489]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08819394e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.89661093 9.10353323]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17326394e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [9.00694984 9.1931799 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.66289852 9.18723089]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.898559   8.97660235]\n",
      "  [6.34280818 7.14172105]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.77956097 9.05227313]\n",
      "  [6.34280818 7.14172105]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.90975571e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.08849342  7.93307902]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.00301125 10.2548573 ]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01109337e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.44327365 9.2145247 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.69098499 9.12807948]\n",
      "  [6.34280818 7.14172105]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.08849342  7.93307902]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.87881508 10.31323853]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.29803082 9.25849414]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.16470482 8.7674374 ]\n",
      "  [6.34280818 7.14172105]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.75791555e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.41489734 9.13622203]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.66540205e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.83387844 9.00901411]\n",
      "  [6.34280818 7.14172105]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.08849342  7.93307902]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.80536648 10.31110808]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.1678016e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.35510715 7.20970027]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.5734076  9.22259983]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.94899658e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.5734076  9.22259983]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.42025518 9.21490556]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.63908581 9.12895028]\n",
      "  [6.34280818 7.14172105]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.7221716e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.08849342  7.93307902]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.77078531 10.34151626]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.84272573e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.57822966 9.293415  ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.95234255e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.34474916 9.29828761]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.3006806e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.15744257 8.78379019]\n",
      "  [6.34280818 7.14172105]]\n",
      "\n",
      " [[6.55608516 7.04646593]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.7903329e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.51027424 9.36845885]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.51811415 9.1977455 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.15744257 8.78379019]\n",
      "  [6.34280818 7.14172105]]\n",
      "\n",
      " [[6.54101961 7.03674904]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.78703541 9.0285016 ]\n",
      "  [6.34280818 7.14172105]]\n",
      "\n",
      " [[6.54101961 7.03674904]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.69817609e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.25256083  8.60314601]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.77078531 10.34151626]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.25256083  8.60314601]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.79263831 10.34985633]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.91062903e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.66630273 9.27797095]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01345552e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.51384156 7.55706428]\n",
      "  [8.79967246 9.35017386]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [8.79967246 9.35017386]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10599936e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [8.91970521 9.41515647]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.18928881e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [8.57466677 9.31897887]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.40334125e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.78703541 9.0285016 ]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.54101961 7.03674904]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.61057303 9.15419333]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.54101961 7.03674904]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.25256083  8.60314601]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.82618587 10.40251972]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [8.3315626  9.32116677]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.53576086 9.23810455]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.54101961 7.03674904]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.25256083  8.60314601]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.74571797 10.42972657]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [8.18008564 9.35582521]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.03991469 8.86138236]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.54101961 7.03674904]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [8.36207708 9.42024269]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.80235657e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [8.39700441 9.25467429]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.5788115e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.37875911 8.63256089]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.54101961 7.03674904]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.16531845e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [8.55730397 9.32920686]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.93782244e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [8.63015563 9.11762779]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.81393205e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.64144181 8.46333156]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.54101961 7.03674904]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.98837343e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [8.76714007 9.20586501]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08342548e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [8.89042606 9.28527851]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16897232e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [8.90178975 9.02797188]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.64144181 8.46333156]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.72708653 6.90370715]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.8814368  8.34285453]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.72708653 6.90370715]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [9.01161078 9.12517469]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25306111e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [9.1104497  9.21265722]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.32164439e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [9.19940473 9.2913915 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.38336934e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [9.15227709 8.98283756]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.16273477e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.10162924 8.26456229]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.72708653 6.90370715]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.35066797e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [9.21679024 8.7972437 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[9.10162924 8.26456229]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[7.00419496 6.75767849]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.23753071 8.15117862]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[7.00419496 6.75767849]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.39543296e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [9.3034074  8.6590933 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.34012832 8.03922663]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[7.00419496 6.75767849]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[6.77678976 7.51860168]\n",
      "  [9.38775503 8.5452373 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.42516617 7.93770824]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[7.00419496 6.75767849]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.51406361e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.14349689 7.17739576]\n",
      "  [9.38775503 8.5452373 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.14349689 7.17739576]\n",
      "  [9.46394398 8.44770195]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.41087027 8.64074474]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[7.00419496 6.75767849]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.68078213e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.25256083  8.60314601]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.15843658 10.09394406]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.14349689 7.17739576]\n",
      "  [9.51754959 8.60293175]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.60412668e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.14349689 7.17739576]\n",
      "  [9.56579463 8.74263858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.14349689 7.17739576]\n",
      "  [9.14724542 8.82761719]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.06880977 8.85795   ]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[7.00419496 6.75767849]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.96716319e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.25256083  8.60314601]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.23811646 10.0780189 ]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.14349689 7.17739576]\n",
      "  [9.23252088 8.94485547]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.14349689 7.17739576]\n",
      "  [8.84378435 9.01560773]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.57191862 8.53521809]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[7.00419496 6.75767849]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.14349689 7.17739576]\n",
      "  [8.95940591 9.11404696]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.14349689 7.17739576]\n",
      "  [8.90847041 8.97111072]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.57191862 8.53521809]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.84934747 8.35605333]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.1814931e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.14349689 7.17739576]\n",
      "  [9.01762337 9.07399964]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.11148744 6.93111921]\n",
      "  [9.01762337 9.07399964]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.31992032 8.70923423]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.02245222e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.25256083  8.60314601]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.22610758 10.16860931]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.11148744 6.93111921]\n",
      "  [8.83677981 9.02069351]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.69467208 8.46289452]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.11148744 6.93111921]\n",
      "  [8.89625874 8.89550456]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.90583954 8.28964909]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23460391e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.11148744 6.93111921]\n",
      "  [9.00663287 9.00595411]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24960699e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.11148744 6.93111921]\n",
      "  [9.06565225 8.81883669]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.07918067 8.17235922]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.11148744 6.93111921]\n",
      "  [9.16449839 8.67836203]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.43003336 8.65362333]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.25256083  8.60314601]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.27885314 10.05564947]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.3591482e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.11148744 6.93111921]\n",
      "  [8.95426254 8.80063035]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.12655794 8.84907145]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.25256083  8.60314601]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.22113159 10.04807687]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.21326778e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.11148744 6.93111921]\n",
      "  [8.72775445 8.93994376]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.95173161 8.94376648]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.25256083  8.60314601]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.10166757 10.10001594]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05609621e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.60691661 7.29389007]]\n",
      "\n",
      " [[7.11148744 6.93111921]\n",
      "  [8.854979   9.04594938]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14437598e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.11148744 6.93111921]\n",
      "  [8.854979   9.04594938]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.5178574  8.59026299]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.11148744 6.93111921]\n",
      "  [8.83463246 8.95907989]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.79278169 8.37876345]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.11148744 6.93111921]\n",
      "  [8.95116922 9.0631719 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.11148744 6.93111921]\n",
      "  [9.05605229 9.15685471]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.17816464 7.12830149]\n",
      "  [9.05605229 9.15685471]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.17816464 7.12830149]\n",
      "  [9.04513882 8.92993273]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.01444637 8.26135482]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27632586e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.17816464 7.12830149]\n",
      "  [9.14062494 9.03693946]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.34258267e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.17816464 7.12830149]\n",
      "  [9.17609102 8.82301166]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.17765959 8.15988207]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.3671922e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.17816464 7.12830149]\n",
      "  [9.25848192 8.94071049]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.17816464 7.12830149]\n",
      "  [9.33263373 9.04663944]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.17816464 7.12830149]\n",
      "  [9.3373807  8.78727255]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.32378208 8.09485006]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.4791094e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.17816464 7.12830149]\n",
      "  [9.39820318 8.6315763 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.42117231 8.00005555]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.17816464 7.12830149]\n",
      "  [9.46757051 8.51581037]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.55125318 8.54003415]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[6.25256083 8.60314601]\n",
      "  [7.72919343 5.95396498]]\n",
      "\n",
      " [[7.33786199 9.95633212]\n",
      "  [7.32522175 8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.37611052 6.97047489]\n",
      "  [9.46757051 8.51581037]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.56944673e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.37611052 6.97047489]\n",
      "  [9.52081346 8.66422933]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.60639145e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.37611052 6.97047489]\n",
      "  [9.18090801 8.74812833]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.94798979 8.2692684 ]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.37053466e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.37611052 6.97047489]\n",
      "  [9.16964992 8.68177152]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.40913969 8.61716705]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.09166458e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[6.25256083 8.60314601]\n",
      "  [7.72919343 5.95396498]]\n",
      "\n",
      " [[7.33679096 9.95087467]\n",
      "  [7.32522175 8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.37611052 6.97047489]\n",
      "  [9.25268493 8.81359437]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.37611052 6.97047489]\n",
      "  [8.98999834 8.85366401]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.13928623 8.78893339]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[6.5609968  8.78192287]\n",
      "  [7.72919343 5.95396498]]\n",
      "\n",
      " [[7.33679096 9.95087467]\n",
      "  [7.32522175 8.76546106]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.26439482 10.01690294]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.37611052 6.97047489]\n",
      "  [9.09099851 8.9682976 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.30814741e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.37611052 6.97047489]\n",
      "  [8.80121375 8.99972216]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.64776436e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.97540104 8.90122787]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.04068649e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.15268291 10.10834033]\n",
      "  [ 7.32522175  8.76546106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10706884e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.48415095 7.22445162]]\n",
      "\n",
      " [[7.37611052 6.97047489]\n",
      "  [8.59076729 9.06035223]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.42400744 8.57475483]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.37611052 6.97047489]\n",
      "  [8.59076729 9.06035223]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.96104228e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.37611052 6.97047489]\n",
      "  [8.66498662 8.96007804]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.84532939e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.07307688 8.83071355]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.15268291 10.10834033]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[5.62518751 4.5740535 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[6.92616348 8.21391866]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01254228e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.37611052 6.97047489]\n",
      "  [8.56172406 9.01232444]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.6018224e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.46122807 8.52028655]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.94088949e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.37611052 6.97047489]\n",
      "  [8.70555166 9.111092  ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.37611052 6.97047489]\n",
      "  [8.83499649 9.1999828 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13051033e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [8.83499649 9.1999828 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22610207e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [8.95149684 9.27998452]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.21134869e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [8.86023965 9.04810688]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.77470989 8.37938603]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14802629e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [8.97421568 9.14329619]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [8.9969918  8.92340251]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.0886781e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.98615167 8.25905402]\n",
      "  [6.28621826 7.18226117]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24291715e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [9.09729262 9.03106225]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [9.14310698 8.81915273]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.98615167 8.25905402]\n",
      "  [6.73756979 6.89475219]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.98615167 8.25905402]\n",
      "  [6.96324556 6.7509977 ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.15031862 8.1571881 ]\n",
      "  [6.96324556 6.7509977 ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.34430493e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [9.22879628 8.93723746]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.28075276e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [9.30591665 9.04351371]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.45727683e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [9.31308577 8.7846321 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.30039362 8.09244689]\n",
      "  [6.96324556 6.7509977 ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.46225141e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [9.3817772  8.90616889]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [9.44359948 9.015552  ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [9.49923953 9.1139968 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [9.46977721 8.79397716]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.4381077  8.06381431]\n",
      "  [6.96324556 6.7509977 ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [9.51013168 8.6225143 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.58012701 8.57524329]\n",
      "  [6.96324556 6.7509977 ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.38039413 10.00317589]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [9.18711665 8.74135446]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.24222116 8.788892  ]\n",
      "  [6.96324556 6.7509977 ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[6.5609968  8.78192287]\n",
      "  [7.72919343 5.95396498]]\n",
      "\n",
      " [[7.36504372 9.99812973]\n",
      "  [7.43074595 8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [8.89044679 8.88623403]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.06712807 8.89369789]\n",
      "  [6.96324556 6.7509977 ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.23870058 10.05355848]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [9.00140211 8.99761063]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [9.1012619  9.09784957]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [8.77748218 9.10640394]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.5445569  8.58941052]\n",
      "  [6.96324556 6.7509977 ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09060176e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.22205386 7.16523056]\n",
      "  [8.80656385 8.98896618]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.79490399 8.39029173]\n",
      "  [6.96324556 6.7509977 ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.13365247 7.17820175]\n",
      "  [8.80656385 8.98896618]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.11078122e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.13365247 7.17820175]\n",
      "  [8.92124352 8.85059978]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.29293223 8.71656926]\n",
      "  [6.96324556 6.7509977 ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.1878477  10.06701915]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.13365247 7.17820175]\n",
      "  [8.77779465 8.91192759]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.02160519 8.88509229]\n",
      "  [6.96324556 6.7509977 ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.10504171 10.09828061]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09081858e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.13365247 7.17820175]\n",
      "  [8.90001519 9.02073483]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.13365247 7.17820175]\n",
      "  [8.65864967 9.06440433]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.47426246 8.56830788]\n",
      "  [6.96324556 6.7509977 ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20162903e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.13365247 7.17820175]\n",
      "  [8.71902982 8.95952532]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.47426246 8.56830788]\n",
      "  [6.87132777 6.802822  ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.72474316 8.36796407]\n",
      "  [6.87132777 6.802822  ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05004229e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.13365247 7.17820175]\n",
      "  [8.84941217 8.82694828]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.20438826 8.72329428]\n",
      "  [6.87132777 6.802822  ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.09228572 10.07991962]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14051322e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.13365247 7.17820175]\n",
      "  [8.96447096 8.94425346]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22035129e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.96447096 8.94425346]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22035129e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.76399078 8.96144444]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.93910842 8.89361499]\n",
      "  [6.87132777 6.802822  ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.05173918 10.12453759]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.55763876 9.03816821]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.39260971 8.56207478]\n",
      "  [6.87132777 6.802822  ]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.93805474e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.67838239 7.2363667 ]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.63586327 8.94391402]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.39260971 8.56207478]\n",
      "  [6.79270777 6.82624091]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.39260971 8.56207478]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.65065016 8.358603  ]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.19846678e-16 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.63586327 8.94391402]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.14602075 8.72911653]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.98021489 10.1398344 ]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.57633993 8.96360362]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.86509633 8.92049203]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.92064342 10.15535865]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.95103129e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.71870594 9.06724326]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20996351e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.5053915  9.10181844]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.70080554 9.02238947]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.86247831 10.2184067 ]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.65485235 9.1916366 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.40774839 9.20477409]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.21350212 8.69310437]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.48927504 9.07962879]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.50246108 8.4784037 ]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.64562195 8.93117588]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.99622186 8.82656453]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.76180089e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.88948794 10.1816737 ]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.52129972 8.99621375]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.40663082 8.51176777]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.91283947e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.66916975 9.09659238]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01544491e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.6972372  8.95300329]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.68221029 8.3370852 ]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93086493 6.79292648]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03492062e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.82150272 8.81133573]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.68221029 8.3370852 ]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.09690032 8.74121208]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.97334506 10.11537114]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12114714e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.64951149 8.9021527 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.61835323e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.50825476 8.43146712]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20036085e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.72805765 8.8236632 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.74535044 8.24519884]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.85525188 8.94129688]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22891307e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.96972669 9.04716719]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22399819e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.98300352 8.82166313]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.06830588e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.16201324 8.66874788]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.07987394 10.08635082]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.23321084e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.75630706 8.87833072]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.66353439e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.9129562  8.86891427]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.04245979 10.0945077 ]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.88067635 8.99049764]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.99260872 9.09144788]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.79945126 6.96162455]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.66148684 9.09328965]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.42107283 8.57177299]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.66148684 9.09328965]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.69917255 8.97535402]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.69020544 8.3760281 ]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03626354e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[7.15261462 7.16680226]\n",
      "  [8.8292553  9.07781862]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[7.05238948 6.93381237]\n",
      "  [8.8292553  9.07781862]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.16208663 8.72581713]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.5609968   8.78192287]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.05293201 10.1783813 ]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[7.05238948 6.93381237]\n",
      "  [8.6794623  9.02923616]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.55282824 8.47460303]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20451736e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[7.05238948 6.93381237]\n",
      "  [8.76086245 8.90445929]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.09758692 8.80865403]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.60167121  8.96231396]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.05293201 10.1783813 ]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.60167121  8.96231396]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.03081099 10.15097437]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.2158139e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[7.05238948 6.93381237]\n",
      "  [8.61946599 8.97569126]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.49657986 8.49460352]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.000000e+00 1.000000e+00]\n",
      " [5.980956e-17 1.000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[7.05238948 6.93381237]\n",
      "  [8.70836494 8.88568704]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.06061432 8.80769151]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.60167121  8.96231396]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.99875147 10.129762  ]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20852841e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.75044047 6.98998279]\n",
      "  [8.70836494 8.88568704]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.82980775 8.95575055]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.60167121  8.96231396]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.98272171 10.11915581]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.75044047 6.98998279]\n",
      "  [8.48610557 9.02514374]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.3093461  8.58793277]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.88841862e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.75044047 6.98998279]\n",
      "  [8.63749501 9.12262937]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99346615e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.75044047 6.98998279]\n",
      "  [8.77374551 9.21036643]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08800892e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.75044047 6.98998279]\n",
      "  [8.7106112  9.04035632]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.94776174 8.84162871]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.84523651e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.60167121  8.96231396]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.97560533 10.17572044]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04420069e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.75044047 6.98998279]\n",
      "  [8.53441029 9.05682965]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.764123   8.99110253]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.60167121  8.96231396]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.90156678 10.21059208]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.92193676e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.75044047 6.98998279]\n",
      "  [8.37285435 9.12485584]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.64268821 9.0797881 ]\n",
      "  [6.75339777 6.83795037]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.60167121  8.96231396]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.79992513 10.25523837]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.75044047 6.98998279]\n",
      "  [8.53556891 9.21237025]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.75044047 6.98998279]\n",
      "  [8.32485974 9.23810036]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.64268821 9.0797881 ]\n",
      "  [6.43377417 7.05089042]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.64268821 9.0797881 ]\n",
      "  [6.27396237 7.15736045]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.54131416 9.1419894 ]\n",
      "  [6.27396237 7.15736045]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.60167121  8.96231396]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.72990646 10.32285933]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.15530637e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.75044047 6.98998279]\n",
      "  [8.49237377 9.31429033]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.89276806e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.75044047 6.98998279]\n",
      "  [8.64313639 9.3828613 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.75044047 6.98998279]\n",
      "  [8.33809386 9.34822641]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.54131416 9.1419894 ]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.10589462 8.81028526]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.75044047 6.98998279]\n",
      "  [8.50428447 9.41340377]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.90103277e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.75044047 6.98998279]\n",
      "  [8.65385603 9.47206339]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.00481888e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.75044047 6.98998279]\n",
      "  [8.78847042 9.52485705]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09822638e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.75044047 6.98998279]\n",
      "  [8.63659306 9.28654263]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.62459428e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.7449099  9.03428636]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.49279819  9.11030071]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.72990646 10.32285933]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49279819  9.11030071]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.81959046 10.37604672]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99284029e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.63659306 9.28654263]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99284029e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.41626049 9.25698586]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.60029113 9.16756187]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49279819  9.11030071]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.77629942 10.3908177 ]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.83995386e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.2482467  9.29551768]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.27376138e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.09944424 8.80198801]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.72337087e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.36390105 9.16855404]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.39528254 8.56841562]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.8036222e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.54006354 9.01164327]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.90816104 8.94053489]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49279819  9.11030071]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.80417513 10.30006616]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.92585948e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.68605719 9.11047894]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.02716293e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.81745147 9.19943105]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.93570632 9.27948794]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20039181e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.63111758 9.21595793]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.40652755 8.65665062]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.76800582 9.29436213]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08402621e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.74661393 9.10984131]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.70190935 8.47226183]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.06918261e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.87195254 9.19885718]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.98475728 9.27897146]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.97314238 9.02839047]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.07262472 8.85615738]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49279819  9.11030071]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.99134452 10.26138927]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.71562108 9.05665818]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.60150865e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.83285017 9.0326344 ]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49279819  9.11030071]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.98192069 10.25335791]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.000000e+00 1.000000e+00]\n",
      " [6.047677e-17 1.000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.84405897 9.15099237]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13679869e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.95965307 9.23589313]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [9.06368777 9.31230382]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.28919678e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [9.15731899 9.38107344]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.71179956 9.30359048]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.40114491 8.73775339]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04502529e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.84061961 9.37323143]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.95655765 9.43590829]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [9.06090188 9.49231746]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [9.15481169 9.54308571]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [9.23933052 9.58877714]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [9.31539747 9.62989943]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [9.0181567  9.31005107]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.82946532e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.99334073 8.97021986]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.84468069e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49279819  9.11030071]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.09822302 10.35069938]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25760325e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [9.11634103 9.37904596]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.32573232e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [9.20470693 9.44114137]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.38704848e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [9.28423623 9.49702723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.44223302e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.83945441 9.33660156]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.53245213 8.71975055]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13360363e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.95550897 9.4029414 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [8.89073534 9.18937092]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.92057801e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.10551527 9.00015503]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49279819  9.11030071]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.10540565 10.35109806]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16918692e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [9.0016618  9.27043383]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [9.10149562 9.34339045]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31543125e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.82985746 7.20960845]\n",
      "  [9.19134606 9.4090514 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.2755555e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.19134606 9.4090514 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.72929606 8.76369807]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.27221145 9.46814626]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.34499031 9.52133164]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.16421358 9.26614505]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.03033346 8.58830706]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.24779222 9.33953054]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.41694491e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.323013   9.40557749]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.46913981e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.3907117  9.46501974]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.51611522e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.30748923 9.16783269]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.23816242 8.46128661]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.34900959 8.96843099]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.35868505 8.3180157 ]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.48717856e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.41410863 9.07158789]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.45052833 8.86300022]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.45955386 8.20420794]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.55762134e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.50908571 8.71318329]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.53341121 8.08737728]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.56790734 8.59154256]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.61513289e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.60886786 8.68412787]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.93831658 6.73129732]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49279819  9.11030071]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.37986576 10.11216605]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.61111661 8.7323883 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.65000494 8.85914947]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.26854962 8.90322588]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.60886786 8.68412787]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.91270544 6.83929981]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.97360207e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.01185378 8.40335429]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.91270544 6.83929981]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.43134824e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.23901632 8.81295466]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.45787319 8.74654356]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.91270544 6.83929981]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.12081055e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49279819  9.11030071]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.38553941 10.08126489]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.4108554e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.31511469 8.93165919]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.38360322 9.03849327]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.07495089 9.01786406]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.85891695 8.48041741]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.91270544 6.83929981]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.29701214e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.08104222 8.90109899]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.38367424 8.77271466]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.91270544 6.83929981]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49279819  9.11030071]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.32518659 10.10107204]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.26024777e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.172938   9.01098909]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.9399387  9.01458041]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.12191176 8.92678615]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.91270544 6.83929981]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49279819  9.11030071]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.23856878 10.15636818]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.71873405 9.07800466]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.5484495  8.59459494]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.91270544 6.83929981]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04983706e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.84686065 9.1702042 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.84281012 9.02294007]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.16965226 8.85984474]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.91270544 6.83929981]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49279819  9.11030071]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.15640844 10.18736012]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.95852911 9.12064607]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.74712546 9.10426093]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.9473895  9.00486642]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.91270544 6.83929981]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.49279819  9.11030071]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.0770544  10.23538443]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86432037 7.11812813]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.87241291 9.19383484]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.98112535 7.236598  ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.87241291 9.19383484]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15647319e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.98112535 7.236598  ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.61516226 9.19886399]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.41975966 8.6819788 ]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.91270544 6.83929981]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.97796969e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.98112535 7.236598  ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.67548499 9.07222352]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.68007382 8.46987881]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.91270544 6.83929981]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01982699e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.98112535 7.236598  ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.80977203 8.92406328]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.68007382 8.46987881]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.86394572 8.30456472]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.11300734e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.98112535 7.236598  ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.9504643  8.78385753]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.26279462 8.74643613]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.57722085  9.14930413]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.0770544  10.23538443]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57722085  9.14930413]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.11871292 10.13123523]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.98112535 7.236598  ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.05541787 8.90547177]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.98112535 7.236598  ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.83282678 8.95131034]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.97888248 8.92571216]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57722085  9.14930413]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.09248717 10.14614175]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12900479e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.98112535 7.236598  ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.60796638 9.04594003]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.82643611 9.02131278]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.9214016e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57722085  9.14930413]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.98943014 10.19144689]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.98112535 7.236598  ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.43455764 9.13149513]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.70899011 9.08723514]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57722085  9.14930413]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.86853812 10.2483215 ]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.85265006e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86438573 7.27089705]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.43455764 9.13149513]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.85265006e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86438573 7.27089705]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.30087486 9.20064162]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.60191031 9.14294617]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.76600573e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57722085  9.14930413]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.75461901 10.3044174 ]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.1519778e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86438573 7.27089705]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.47078738 9.28057746]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86438573 7.27089705]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.27615781 9.2974672 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.11141828 8.79045996]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.14854762e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.86438573 7.27089705]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.38264622 9.16491758]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.75755674 9.01699694]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.68695847e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57722085  9.14930413]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.73036799 10.31817573]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.81662927e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.38264622 9.16491758]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.23183686 8.6744655 ]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.81662927e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[5.44420815 6.13725179]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.48405785 9.05224499]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.50954157 8.45813075]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.88699773e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.48405785 9.05224499]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.90468061e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.64839392 8.34996337]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.88699773e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.7013865  8.86610785]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.80475156 8.22142482]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03779977e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.87259387 8.72162385]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.09452298 8.73798271]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57722085  9.14930413]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.91422154 10.14773741]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15659875e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.67410613 8.85600501]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.81295011 8.92808632]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.57722085  9.14930413]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.92675322 10.11627071]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20377404e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.46223311 8.99923703]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.2913683  8.56373797]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.54766387 8.9251137 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.5647497  8.35191447]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.93113327e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.69289748 9.03260233]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03190934e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.82360774 9.1293421 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12260779e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.94124696 9.21640789]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.89652336 8.94896973]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.05307614 8.72246552]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.80640057e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.55931172  9.12116035]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.92675322 10.11627071]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.55931172  9.12116035]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.02198595 10.13772325]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.00687102 9.05407276]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.10618392 9.14866548]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31868441e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.19556553 9.23379893]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.27600898 9.31041904]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.43652421e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.34840808 9.37937714]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.89543449 9.17867477]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.58471187 8.53270267]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17244762e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.88160199 9.00241845]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.84499673 8.36731872]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [8.99344179 9.10217661]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24045384e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.09409761 9.19195895]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.0850475  8.94290696]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.23129275 8.73874866]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.87248155e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.55931172  9.12116035]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.14501198 10.14602441]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.65713484 7.20486623]\n",
      "  [9.17654275 9.04861626]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.36750565e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.99918452 7.22187962]\n",
      "  [9.17654275 9.04861626]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.99918452 7.22187962]\n",
      "  [9.25888847 9.14375464]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.99918452 7.22187962]\n",
      "  [9.33299963 9.22937917]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.99918452 7.22187962]\n",
      "  [9.39969966 9.30644126]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.52235187e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.99918452 7.22187962]\n",
      "  [8.99236693 9.14872009]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.71160671e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.97365116 8.92778409]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.55931172  9.12116035]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.16945276 10.23250024]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.23970801e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.99918452 7.22187962]\n",
      "  [9.09313024 9.23384808]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.99918452 7.22187962]\n",
      "  [8.73602558 9.18803768]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.85460669 9.05689214]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.97480721e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.55931172  9.12116035]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.07913661 10.29146519]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.99918452 7.22187962]\n",
      "  [8.86242303 9.26923391]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14954131e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.99918452 7.22187962]\n",
      "  [8.97618072 9.34231052]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22847657e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.99918452 7.22187962]\n",
      "  [8.62993304 9.29391212]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.45022825e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.37927656 8.74601092]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.99918452 7.22187962]\n",
      "  [8.76693973 9.3645209 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.99918452 7.22187962]\n",
      "  [8.73518049 9.18066482]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.68371047 8.54527139]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.06124906e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.99918452 7.22187962]\n",
      "  [8.86166244 9.26259834]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.99918452 7.22187962]\n",
      "  [8.9754962  9.3363385 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.24560032e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.99918452 7.22187962]\n",
      "  [9.07794658 9.40270465]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.29909082e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.99918452 7.22187962]\n",
      "  [9.01245748 9.11946088]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.02553457e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.94683823 8.42042005]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25364863e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.07832755 6.97910783]\n",
      "  [9.01245748 9.11946088]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.30507376 8.8267961 ]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.91213779e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.07913661 10.29146519]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.1445513  10.29351695]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25364863e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.07832755 6.97910783]\n",
      "  [9.11121173 9.20751479]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.32217315e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.07832755 6.97910783]\n",
      "  [8.87763537 9.13447584]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.70359103 8.56718838]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [8.87763537 9.13447584]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16009699e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [8.98987183 9.22102825]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [9.09088465 9.29892543]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.30806841e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [9.18179618 9.36903288]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.37115096e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [9.0723345  9.1113918 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.03932947e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.20961603 8.90100097]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.92838225 6.80760143]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.20120945 10.29131519]\n",
      "  [ 7.43074595  8.68664048]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.29519666e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [8.82001366 9.11609629]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.20961603 8.90100097]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.63281348 8.596939  ]\n",
      "  [6.15350685 7.23547598]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [8.86313223 8.99682374]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.63281348 8.596939  ]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.19689052 8.91499558]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.20120945 10.29131519]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.80599136e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[5.62518751 4.5740535 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[7.00833463 8.20568883]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15003342e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [8.976819   9.09714137]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22891947e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [9.0791371  9.18742723]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [9.17122339 9.26868451]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.27276292e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [8.8643679  9.20034049]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.64419242 8.63763398]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15089084e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [8.88986092 9.05522384]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.20257999 8.93534307]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.15654909 10.26774713]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16858018e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [8.72596246 9.10174915]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.96390963 9.07477039]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.06865953 10.27457322]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [8.85336621 9.19157423]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14325688e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [8.96802959 9.27241681]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22282059e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [8.66957865 9.26611656]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.80941863 9.14721448]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.90486785e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.00216122 10.34373323]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [8.45855678 9.29194407]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.41887273e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.28813202 8.79038487]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [8.5445312  9.16212598]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.75104688e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.56187849 8.56004283]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [8.697017   9.00508012]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.75974604 8.38205346]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20695356e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.09021792 7.14334425]\n",
      "  [8.85240692 8.85536145]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.18073751 8.82852003]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.85872538e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.04204338 10.2140112 ]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[7.08607173 7.1138167 ]\n",
      "  [8.85240692 8.85536145]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14259124e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.81533087 7.08831636]\n",
      "  [8.85240692 8.85536145]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.90718611 8.99986449]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.06198446 10.14915018]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14259124e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.9486282  7.08630276]\n",
      "  [8.85240692 8.85536145]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.9486282  7.08630276]\n",
      "  [8.5890779  9.02762652]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.38922421 8.61098285]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.95987003e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.9486282  7.08630276]\n",
      "  [8.73017011 9.12486387]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05777242e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.9486282  7.08630276]\n",
      "  [8.8571531  9.21237748]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.9486282  7.08630276]\n",
      "  [8.78426624 9.05058188]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.82119368e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.01940589 8.8651515 ]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.04469872 10.19480784]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.9486282  7.08630276]\n",
      "  [8.90583961 9.14552369]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.9486282  7.08630276]\n",
      "  [9.01525565 9.23097132]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25559025e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.9486282  7.08630276]\n",
      "  [8.71539018 9.16154626]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.82758243 9.01049889]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.00850543 10.26202243]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04751678e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.9486282  7.08630276]\n",
      "  [8.48872806 9.18497268]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.71719339 9.11005841]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.74803754 6.9642011 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.89974394 10.30500029]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.9486282  7.08630276]\n",
      "  [8.63985526 9.26647542]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.9951039e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.9486282  7.08630276]\n",
      "  [8.77586973 9.33982787]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.9486282  7.08630276]\n",
      "  [8.47481222 9.3139373 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.35487862e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.71719339 9.11005841]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.24852158 8.78060413]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.88058229e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.47481222 9.3139373 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.72356161e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.51418568 8.61587698]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.88058229e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.53521556 7.2422473 ]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.64308038 9.10331945]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.71432499 8.44926627]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99734178e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.64308038 9.10331945]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.11706007 8.84663325]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.90710412 10.29382792]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99734178e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.56836422 9.09031302]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.48587573 8.55944183]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.7115278  9.18128172]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04483671e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.84037502 9.26315355]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13424243e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.8145378  9.05535351]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.76875298 8.40186232]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22326285e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.91477009 8.88842168]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.08454466e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.95028453 8.25629983]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.02329308 8.99957951]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.12096378 9.09962156]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.32893999e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.1405957  8.85233071]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.23798391 8.74568108]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.79276627e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.10979034 10.18784625]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.34256238e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.86549141 8.92443779]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.71624964e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.66518852 8.44261566]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.89882112 8.83926516]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.89212271 8.25701389]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23495951e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.008939   8.95533864]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25120719e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.06131859 8.78047488]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.07058879 8.1406969 ]\n",
      "  [6.52987882 7.05651359]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.15889481 8.6465162 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[9.07058879 8.1406969 ]\n",
      "  [6.89317492 6.78453556]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.37921053 8.64548695]\n",
      "  [6.89317492 6.78453556]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.93340809e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.21845309 10.0525296 ]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.24300533 8.78186458]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.31870479 8.90367812]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.46615039e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75333778 7.00083016]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.01103661 8.91003384]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.79401991 8.38675701]\n",
      "  [6.89317492 6.78453556]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.98108353 7.06442862]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.01103661 8.91003384]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2526627e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.98108353 7.06442862]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.10993295 9.01903046]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.32128582e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.98108353 7.06442862]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.07257444 8.86421803]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.02603973 8.23906572]\n",
      "  [6.89317492 6.78453556]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11957154 7.07790152]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.07257444 8.86421803]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11957154 7.07790152]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.14670311 8.7277353 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.4004011  8.6405447 ]\n",
      "  [6.89317492 6.78453556]]\n",
      "\n",
      " [[6.46089612 7.12612392]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.26790779 10.01735892]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11957154 7.07790152]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.2320328  8.85496177]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.28120192e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11957154 7.07790152]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.97617684 8.88369877]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.4004011  8.6405447 ]\n",
      "  [6.89317492 6.78453556]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.79067129 8.37375186]\n",
      "  [6.89317492 6.78453556]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11957154 7.07790152]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.00435694 8.79135013]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.09975354e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.30249876 8.6938195 ]\n",
      "  [6.89317492 6.78453556]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.6113105   9.17716625]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.23569667 10.02521951]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24802774e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11957154 7.07790152]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.82317797 8.87320286]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.04552805 8.85699755]\n",
      "  [6.89317492 6.78453556]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.23569667 10.02521951]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.02077315e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.14711952 10.0618909 ]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11957154 7.07790152]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.62980021 8.97940045]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.58270655e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.47468411 8.52025896]\n",
      "  [6.89317492 6.78453556]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.19762536e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11957154 7.07790152]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.70477375 8.89780381]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.88049339e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.71925155 8.319251  ]\n",
      "  [6.89317492 6.78453556]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04015015e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11957154 7.07790152]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.83429637 9.00802343]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11957154 7.07790152]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.95086673 9.10722109]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11957154 7.07790152]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.05578006 9.19649898]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.28370971e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11957154 7.07790152]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.15020205 9.27684908]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.34922813e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11957154 7.07790152]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.06280165 8.96612494]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.05019614e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.98474643 8.24607548]\n",
      "  [6.89317492 6.78453556]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.25771638e-16 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.06280165 8.96612494]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.11749388 8.20948771]\n",
      "  [6.89317492 6.78453556]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.15652148 9.06951245]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.24086933 9.1625612 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.3167824  9.24630508]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.46481646e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.30538875 8.90694763]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.32653227e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.41759475 8.62950022]\n",
      "  [6.89317492 6.78453556]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.29571526 10.0937245 ]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.29138211e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.37484988 9.01625286]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.50510887e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.43736489 9.11462758]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.54848737e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [9.08572034 9.00911388]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.12708348 8.85223991]\n",
      "  [6.89317492 6.78453556]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.28214577 10.1505078 ]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.30448495e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.77372273 7.05539303]\n",
      "  [8.79369356 9.0454529 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.12708348 8.85223991]\n",
      "  [6.69742085 6.93316374]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.58101916 8.54430112]\n",
      "  [6.69742085 6.93316374]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10185067e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.79369356 9.0454529 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10185067e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.82925445 8.9404469 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.95427816e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.20336789 8.83235368]\n",
      "  [6.69742085 6.93316374]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.17277466 10.15143266]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.69597438 9.00316492]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.5800737  8.51744281]\n",
      "  [6.69742085 6.93316374]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.78001667 8.90855958]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.5800737  8.51744281]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.15914671 8.81929447]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.97711224e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.098394   10.13914016]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.65366702 8.98199758]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.91893096 8.9653033 ]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.92550028e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.01066381 10.16236911]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.00468773e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.49440589 9.07712011]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.763731   9.04759929]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.90309426 10.2120326 ]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.35269535 9.15759977]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.22294364 8.68683956]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.51742581 9.24183979]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15368434 6.83738095]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.66568323 9.31765582]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01302565e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.04311546 7.1457528 ]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.66568323 9.31765582]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20260513e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.04311546 7.1457528 ]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.79911491 9.38589023]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10561248e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.04311546 7.1457528 ]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.68873491 9.16768094]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.70581335e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.58696578 8.51049215]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.04311546 7.1457528 ]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.77915377 8.98803733]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.0547206  8.84005912]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.78998387e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.96320864 10.20123123]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.21835233e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.04311546 7.1457528 ]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.90123839 9.0892336 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.04311546 7.1457528 ]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [9.01111455 9.18031024]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.04311546 7.1457528 ]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.72744551 9.12617877]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.58908516e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.5183385  8.57050106]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05588185e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.04311546 7.1457528 ]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.85470096 9.21356089]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14418305e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.06343812 7.25830076]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.85470096 9.21356089]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.06343812 7.25830076]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.96923087 9.2922048 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.06343812 7.25830076]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [9.07230778 9.36298432]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.06343812 7.25830076]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [9.165077   9.42668589]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.06343812 7.25830076]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.9898739  9.14154337]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.85511881 8.44186788]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.5906085  7.01927984]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.06343812 7.25830076]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [9.03698448 8.94751884]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.85511881 8.44186788]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.21284286 8.80142643]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.09639811 10.17962315]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27066765e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.06343812 7.25830076]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.80362938 8.99432999]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.69880453e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.62787318 8.49844521]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10874503e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.06343812 7.25830076]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.92326644 9.09489699]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19175991e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.98286833 7.02852846]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [8.92326644 9.09489699]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.88324317 8.3871814 ]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19175991e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.98286833 7.02852846]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [9.01493049 8.90232106]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.04759378 8.25451912]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.98286833 7.02852846]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [9.11343744 9.01208895]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.32371755e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[6.90433879 7.14587768]\n",
      "  [9.11343744 9.01208895]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.32371755e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.07120691 6.87474649]\n",
      "  [9.11343744 9.01208895]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.16917187 8.23209514]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.32371755e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.07120691 6.87474649]\n",
      "  [9.22438747 8.79888253]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.27434092 8.13560058]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.4007046e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.07120691 6.87474649]\n",
      "  [9.30194872 8.91899428]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.07120691 6.87474649]\n",
      "  [9.37175385 9.02709485]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.07120691 6.87474649]\n",
      "  [9.39561329 8.76778766]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.43536677e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.4757297  8.63964955]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.30644437 10.09692664]\n",
      "  [ 7.48583837  8.62888771]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.51951638e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.07120691 6.87474649]\n",
      "  [9.45605196 8.89100889]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.07120691 6.87474649]\n",
      "  [9.51044677 9.001908  ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.59919811e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.07120691 6.87474649]\n",
      "  [9.55940209 9.1017172 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.07120691 6.87474649]\n",
      "  [9.60346188 9.19154548]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.66374031e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.07120691 6.87474649]\n",
      "  [9.64311569 9.27239094]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.07120691 6.87474649]\n",
      "  [9.21184973 9.09205529]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.92260474 8.45664689]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.07120691 6.87474649]\n",
      "  [9.17496676 8.9286864 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.13128908 8.29979801]\n",
      "  [6.78073991 6.87355899]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.07120691 6.87474649]\n",
      "  [9.23999901 8.7842624 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[9.13128908 8.29979801]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.26164414 8.16360396]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.28230746e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.23999901 8.7842624 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.41153728e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.31599911 8.90583616]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.46427294e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.36265721 8.71835967]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.37588496 8.06914585]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.49664851e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.42639149 8.8465237 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.54087305e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.48375234 8.96187133]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.49223015 8.708594  ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.48483454 8.01801053]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.58655779e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.54300714 8.8377346 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.56543738 8.62607151]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.66499502 8.54777592]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.30644437 10.09692664]\n",
      "  [ 7.54625304  8.59671938]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 9.72601809e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[5.62518751 4.5740535 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[7.33034227 8.05327302]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.2487167  8.73214612]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.25507526 8.81265862]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.35270887 10.04132177]\n",
      "  [ 7.54625304  8.59671938]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.41758639e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.32384503 8.85893151]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.46971714e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.39146053 8.97303836]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.51663482e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.45231447 9.07573452]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.50708303 9.16816107]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.59686405e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.55637472 9.25134496]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.63106703e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.60073725 9.32621047]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.66184972e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.64066353 9.39358942]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [9.12236187 9.22185816]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.06862118 8.92285802]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.32529918 10.20940415]\n",
      "  [ 7.54625304  8.59671938]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [8.7886294  9.18007228]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.96443026 9.04519067]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.17810135 10.27673099]\n",
      "  [ 7.54625304  8.59671938]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.21966734e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [8.58008681 9.20811241]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.41424985 8.7058403 ]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.9536312e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [8.65574334 9.08639232]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.66942226 8.48747708]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [8.79564058 8.93818699]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.20595167 8.85443093]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.10730691 10.21364029]\n",
      "  [ 7.54625304  8.59671938]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22064034e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [8.68020096 9.01086587]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.6940228e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.9458986  9.01267158]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.02573384 10.21116649]\n",
      "  [ 7.54625304  8.59671938]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.23160306 6.95107821]\n",
      "  [8.81218086 9.10977928]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.81218086 9.10977928]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.11467881e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.93096278 9.19880135]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19710032e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.64384083 9.20446931]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.78324283 9.09080239]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.02573384 10.21116649]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.08644673e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[5.62518751 4.5740535 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[7.12270747 8.20842423]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.19957389e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.13680914 7.11909981]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.43521755 9.23855561]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.26570844 8.74082344]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.94249159 7.25497215]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.43521755 9.23855561]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.94249159 7.25497215]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.52389215 9.11560718]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.73548739e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.94314775 8.95487832]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.92242378 10.25182612]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.94249159 7.25497215]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.67150293 9.20404646]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01706388e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.94249159 7.25497215]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.51301057 9.18397456]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.74054339 9.07816961]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.86641612 10.29950288]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.90708771e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.94249159 7.25497215]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.66170951 9.2655771 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.66170951 9.2655771 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.79553856 9.33901939]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10313089e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.9159847  9.40511745]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.18670719e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.55420971 9.33382657]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.37108093e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.29195558 8.77261543]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.18713507e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.59388708 9.17595946]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000e+00 0.0000e+00]\n",
      " [1.0000e+00 5.7537e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.58353262 8.5566915 ]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.73449838 9.25836351]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.21215515e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.80066224 9.05185835]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.81203121 8.39908909]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22133723e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.92059601 9.14667252]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23798139e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.98511049 8.9329719 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.0000598  8.2727333 ]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.23467284e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [9.09257916 8.77557927]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.24504601e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.13706156 8.14659836]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.30924421e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [9.20111421 8.64642898]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.31509723 8.69310033]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.11365374 10.10832303]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [9.28100279 8.78178608]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.43998937e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [9.35290251 8.90360747]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [9.00249015 8.92904387]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.00301011 8.88987938]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.15782293 10.12577906]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2467324e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.70244912 9.02047369]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.4824847  8.55312916]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.83735178 6.88638707]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.74421844 8.93148851]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.4824847  8.55312916]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.81166977 6.8644452 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.10437152 8.82687621]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.81166977 6.8644452 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.96673739e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.07659884 10.13548494]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.0675204e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.8697966  9.03833966]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.67664691 9.04992031]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.52284452 8.53340623]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.81166977 6.8644452 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.80898222 9.14492828]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.1124593e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.81362892 8.98582663]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.0920618  8.82089709]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.81166977 6.8644452 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.06375099 10.16207312]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22313672e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.64363918 9.02127215]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.50348657 8.5189574 ]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.81166977 6.8644452 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99772952e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.77927526 9.11914494]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09184596e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.79103226 8.96715543]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.76815619 8.34634087]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.81166977 6.8644452 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10000401e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.9027786  8.82211406]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.94518954 8.20201606]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.81166977 6.8644452 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [9.02946512 8.69186346]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.29809516 8.66583728]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.81166977 6.8644452 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.90146187e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.14366154 10.05778194]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [9.1265186  8.82267711]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.88249737 8.87767347]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.75796019e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.0065122  8.85603142]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.81166977 6.8644452 ]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.12482972 10.07996036]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.14067387 7.11945082]\n",
      "  [8.99424763 8.98990612]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24101301e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.99424763 8.98990612]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.69972869 9.03736563]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.0065122  8.85603142]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.60843976 6.97463517]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.85318799 8.95999985]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.60843976 6.97463517]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.04230634 10.15492643]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03664944e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.49113954 9.10268275]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.32304981 8.62107303]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.60843976 6.97463517]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.89191164e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.64202559 9.19241448]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.77782303 9.27317303]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09083827e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.90004073 9.34585573]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17564383e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.77924029 9.12135708]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.67322102 8.45907934]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.60843976 6.97463517]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.90131626 9.20922137]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17652891e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [9.01118463 9.28829923]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.97488072 9.02778135]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.67322102 8.45907934]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.15353304 8.79151024]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.11110546 10.18857576]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.22757451e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [9.07739265 9.12500322]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [9.16965339 9.2125029 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.3627252e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.84623991 9.12285555]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.92120871 8.97118542]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.09404869 10.2434301 ]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13831202e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.96161592 9.21056999]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.21837021e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.64929144 9.19375917]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.79822383 9.08296475]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.00674092 10.29921871]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.00165157e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.7843623  9.27438325]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.0953758e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.51147068 9.27037752]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.30370019 8.74963339]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.18120384e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.57721542 9.13504212]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.58273626 8.52883354]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.95163878e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.71949387 9.2215379 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.84754449 9.29938411]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13921725e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.96279004 9.3694457 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [9.06651103 9.43250113]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [9.15985993 9.48925102]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.35592962e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [9.01302447 9.15615893]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.89657792 8.42688034]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25404205e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [9.11172202 9.24054303]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [9.20054982 9.31648873]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [9.15890608 9.0289965 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.11185139 8.32503877]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.35526775e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.9359296  7.33371692]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [9.22419359 8.84451376]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.35862206 8.78220687]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.86190319e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.1930479  10.18741486]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [9.22419359 8.84451376]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [9.30177423 8.96006238]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.45440245e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.99433594 8.99291394]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.05653019 8.96606938]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.19425833 10.19087301]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.71978005 9.08288472]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.51617712 8.61618858]\n",
      "  [7.04288558 6.7566987 ]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05056286e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.84780204 9.17459625]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13939597e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.83037187 9.03377356]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.51617712 8.61618858]\n",
      "  [6.92791364 6.82482478]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.13579189 8.88444349]\n",
      "  [6.92791364 6.82482478]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.12927791 10.20894593]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22546027e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.66950269 9.07066417]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.53569702 8.57048742]\n",
      "  [6.92791364 6.82482478]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01567594e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.80255242 9.16359776]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.81555502 9.00999384]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.79407052 8.38924125]\n",
      "  [6.92791364 6.82482478]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.16803599 7.15568786]\n",
      "  [8.93399952 9.10899446]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.93399952 9.10899446]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.24874642 8.77819899]\n",
      "  [6.92791364 6.82482478]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.13823876 10.24807075]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19920748e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [9.04059956 9.19809501]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.81979835 9.1103271 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.65229255 8.53323034]\n",
      "  [6.92791364 6.82482478]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.1199645e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.93781852 9.19929439]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.92982628 9.01293933]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.18144178 8.86584347]\n",
      "  [6.92791364 6.82482478]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.14104989 10.22921111]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [9.03684365 9.1116454 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27056993e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [9.13315929 9.20048086]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.33740233e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.83915636 9.14657782]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.18144178 8.86584347]\n",
      "  [6.73653353 6.95874978]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.94714085 9.02460618]\n",
      "  [6.73653353 6.95874978]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.10618749 10.27323668]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.59843452 9.18313138]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.81604542 9.12159776]\n",
      "  [6.73653353 6.95874978]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.99246755 10.30987089]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.96636249e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.42563543 9.24020479]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.27827688 8.7568808 ]\n",
      "  [6.73653353 6.95874978]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.84645903e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.58307188 9.31618431]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.95570252e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.60284669 9.16084448]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.93612546 9.00238876]\n",
      "  [6.73653353 6.95874978]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.93737245 10.31927324]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.96942405e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.74256202 9.24476003]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.5457312  9.22333552]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.74301171 9.12890367]\n",
      "  [6.73653353 6.95874978]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.8869787  10.34897082]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.92979221e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.69115808 9.30100196]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.03070238e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.44278372 9.30206245]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.74301171 9.12890367]\n",
      "  [6.46547145 7.13093636]]\n",
      "\n",
      " [[6.77350829 6.87094932]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.74301171 9.12890367]\n",
      "  [6.46547145 7.13093636]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.62629734 9.20404017]\n",
      "  [6.46547145 7.13093636]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.82060284 10.39531039]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.59850535 9.37185621]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.96641164e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.34977161 9.36754417]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.29180681e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.15305731 8.84903775]\n",
      "  [6.46547145 7.13093636]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.79381793e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.51479445 9.43078975]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.51862015 9.25500998]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.48397672 8.62652287]\n",
      "  [6.46547145 7.13093636]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.91098014e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.66675813 9.32950898]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.01377152e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.80008232 9.39655808]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.79363185 9.14888819]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.7594411  8.47281671]\n",
      "  [6.46547145 7.13093636]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.10180784e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.90059236 8.96357078]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.10796169 8.89453251]\n",
      "  [6.46547145 7.13093636]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.97053837 10.28308351]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17602661e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [9.01053313 9.0672137 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.74845124 9.09141985]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.62602859e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.55336134 8.5838342 ]\n",
      "  [6.46547145 7.13093636]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.0704575e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.87360611 9.18227787]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.9862455  9.26405008]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.24709208e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[7.1016462  6.93354043]\n",
      "  [8.91446729 9.06555872]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.93508668e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.06489602 8.9051505 ]\n",
      "  [6.46547145 7.13093636]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.83678262e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.0510561  10.26776524]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.18565427e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.77678151 7.02883041]\n",
      "  [8.91446729 9.06555872]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.59823492 8.57879874]\n",
      "  [6.46547145 7.13093636]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.77678151 7.02883041]\n",
      "  [9.02302056 9.15900285]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.77678151 7.02883041]\n",
      "  [9.1207185  9.24310256]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.1207185  9.24310256]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.1195399  8.89650547]\n",
      "  [6.46547145 7.13093636]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.17381545 10.33112365]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.3287698e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [8.80817521 9.18015347]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.58304003 8.62031412]\n",
      "  [6.46547145 7.13093636]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [8.83730362 9.03820238]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.95568042e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.82644146 8.42543801]\n",
      "  [6.46547145 7.13093636]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [8.9492284  8.8892764 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.99291209 8.26842956]\n",
      "  [6.46547145 7.13093636]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20977464e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.05430556 9.00034876]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.25653731e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.12431761 8.8075462 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.14618309 8.15723326]\n",
      "  [6.46547145 7.13093636]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.21188585 8.92679158]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.39202986e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.26441616 8.7262891 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.27885801 8.06913227]\n",
      "  [6.46547145 7.13093636]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.34375129 8.59079746]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[9.27885801 8.06913227]\n",
      "  [6.94427893 6.79312109]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.37692952 7.97088512]\n",
      "  [6.94427893 6.79312109]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.48352988e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.42264745 8.48375278]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.45752374 7.87894367]\n",
      "  [6.94427893 6.79312109]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.48038271 8.6353775 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.53234444 8.77183975]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.61439267e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.54918171 8.53749734]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.59828805 8.57192129]\n",
      "  [6.94427893 6.79312109]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.40658041 10.08056076]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.59426354 8.68374761]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.15764224 7.20466396]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.23644699 8.77064232]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.59828805 8.57192129]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.99372282 8.29421758]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.40907257e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.23644699 8.77064232]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.45949357 8.67933309]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.13934757e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.69993392  9.09867093]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.397869   10.04853731]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.28181451e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.00202093 8.8570544 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.18889439 8.85908147]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.397869   10.04853731]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.13330281e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.29974287 10.06709041]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24640681e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [8.77656822 8.97215979]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.60507448 8.51840465]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [8.8303139  8.89344175]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.8346628  8.31657903]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12726113e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [8.94902207 8.77335249]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.13027879e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.99694023 8.16763051]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20963147e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.07328713 8.65372845]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.12778497 8.04530663]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.16595841 8.7883556 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.3601613e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.23409319 8.61230045]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.25752976 7.9675735 ]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.4074393e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.3200585  8.49317963]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.35678828 7.8810586 ]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.38805265 8.64386166]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.51427013e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.44924739 8.7794755 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.50432265 8.90152795]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.49487664 8.60318741]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.59829129 8.46736546]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[6.80911456 9.06875039]\n",
      "  [7.72919343 5.95396498]]\n",
      "\n",
      " [[7.44782209 9.97482017]\n",
      "  [7.70526343 8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.31767883e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.18675483 8.68853989]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.27827448 8.7236108 ]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[6.80911456 9.06875039]\n",
      "  [7.72919343 5.95396498]]\n",
      "\n",
      " [[7.39861298 9.96282604]\n",
      "  [7.70526343 8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.37459171e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.26807935 8.8196859 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [8.94534947 8.89928727]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.09858243 8.84693582]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.27744628 10.04112793]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20708309e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [9.05081452 9.00935854]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [8.76484023 9.0434536 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.55522731 8.54084935]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [8.88835621 9.13910824]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16753607e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.82768472 6.9459347 ]\n",
      "  [8.86626903 8.98589386]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.18859216 8.78687585]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.18523075 10.11492151]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.000000e+00 1.000000e+00]\n",
      " [1.230442e-16 1.000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.68927923 6.98771769]\n",
      "  [8.86626903 8.98589386]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.96838838 8.93940653]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.98575538e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.13912299 10.1518183 ]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15221001e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.68927923 6.98771769]\n",
      "  [8.62048987 9.06870954]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.52918016e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.83984339 9.03043058]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.01775744 10.20339297]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.98166646e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.68927923 6.98771769]\n",
      "  [8.75844088 9.16183859]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.84801597 7.15859428]\n",
      "  [8.75844088 9.16183859]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.75844088 9.16183859]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.88259679 9.24565473]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16353967e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.57723575 9.2349996 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.35081599 8.70921513]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.95165289e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.71951218 9.31149964]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05037699e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.70008248 9.13943587]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.98251097 8.93596475]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.98891171 10.25747083]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.54304563 9.14410384]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.40847374 8.62562391]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.92792873e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.68874107 9.22969345]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.70776003 9.06509629]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.68734088 8.43885047]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.0422223e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.82881637 8.90808833]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.87519699 8.28266057]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12622201e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.96448698 8.76710839]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.02339329 8.14817364]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.24407248e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [9.0916008  8.64282365]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.30726133 8.67707515]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.13109618 10.08586488]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.30856534e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.86870493 8.79224189]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.70111264 8.35543433]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15390026e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.98183444 8.9130177 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.97136227 8.79868258]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.20299479 8.71206312]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.154093   10.06240547]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.2251331e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.76687905 8.88416654]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.69197105e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.60824902 8.40969817]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.48395883 7.08703613]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08324436e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.82673913 8.80596254]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.60824902 8.40969817]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.68527902 6.90739733]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.16576171 8.72981128]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.68527902 6.90739733]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.10774215 10.05358775]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12478064e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.94406522 8.92536628]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.20619196e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.73833729 8.95460765]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.92597771 8.88634074]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.68527902 6.90739733]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.04920599 10.10863694]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.86450356 9.05914689]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15098497e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.60264287 9.08410974]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.49975184e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.78267125 8.98662514]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.68527902 6.90739733]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.96566014 10.18796236]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.41438994 9.13670493]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.2570916  8.64799454]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.68527902 6.90739733]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.8386559e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.57295094 9.22303443]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.18973594e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.71565585 9.30073099]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20954022e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.84409026 9.37065789]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.72488177 9.14452676]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.72950826e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.61849851 8.48180798]\n",
      "  [6.91145468 6.82532906]]\n",
      "\n",
      " [[6.68527902 6.90739733]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05410289e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.80984029 8.96498657]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.61849851 8.48180798]\n",
      "  [6.90312675 6.80538772]]\n",
      "\n",
      " [[6.68527902 6.90739733]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.98028468e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.83318537 8.32689862]\n",
      "  [6.90312675 6.80538772]]\n",
      "\n",
      " [[6.68527902 6.90739733]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.93819429 8.81325273]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.20285674 8.73863425]\n",
      "  [6.90312675 6.80538772]]\n",
      "\n",
      " [[6.68527902 6.90739733]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.05810779 10.11928228]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.75023984 8.90208007]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.92467149 8.91703004]\n",
      "  [6.90312675 6.80538772]]\n",
      "\n",
      " [[6.68527902 6.90739733]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.02914983 10.12047316]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07169859e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.87521586 9.01187206]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.15841812e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.60747652 9.07274805]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.40532635 8.58761424]\n",
      "  [6.90312675 6.80538772]]\n",
      "\n",
      " [[6.68527902 6.90739733]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.97263664e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.74672887 9.16547324]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.73549498 9.01778232]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.69686117 8.40092004]\n",
      "  [6.90312675 6.80538772]]\n",
      "\n",
      " [[6.68527902 6.90739733]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.92738433 7.24403257]\n",
      "  [8.84649196 8.86925918]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.69686117 8.40092004]\n",
      "  [6.90312675 6.80538772]]\n",
      "\n",
      " [[6.82138398 6.81406668]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.16009052 8.74864929]\n",
      "  [6.90312675 6.80538772]]\n",
      "\n",
      " [[6.82138398 6.81406668]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.0531717  10.10794025]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13848691e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.72772837 7.121476  ]\n",
      "  [8.84649196 8.86925918]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.16009052 8.74864929]\n",
      "  [6.90312675 6.80538772]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.90131394 8.91750075]\n",
      "  [6.90312675 6.80538772]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.06518263 10.1016738 ]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.72772837 7.121476  ]\n",
      "  [8.58377155 9.00162989]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.48263791e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.38416559 8.55940233]\n",
      "  [6.90312675 6.80538772]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.95618801e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.72772837 7.121476  ]\n",
      "  [8.64555201 8.92457587]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.01815585 8.82037068]\n",
      "  [6.90312675 6.80538772]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.90245527e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.99081212 10.12066725]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.72772837 7.121476  ]\n",
      "  [8.78099681 9.03211829]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09304052e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.17631025 6.92001901]]\n",
      "\n",
      " [[6.72772837 7.121476  ]\n",
      "  [8.59776074 9.04420742]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.44818222 8.52786831]\n",
      "  [6.90312675 6.80538772]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.96589496e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02725942 7.07769247]]\n",
      "\n",
      " [[6.72772837 7.121476  ]\n",
      "  [8.59776074 9.04420742]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02725942 7.07769247]]\n",
      "\n",
      " [[6.72772837 7.121476  ]\n",
      "  [8.73798467 9.13978667]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.06319486e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02725942 7.07769247]]\n",
      "\n",
      " [[6.72772837 7.121476  ]\n",
      "  [8.8641862  9.22580801]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02725942 7.07769247]]\n",
      "\n",
      " [[6.72772837 7.121476  ]\n",
      "  [8.81136599 9.02405133]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.02041596 8.81220105]\n",
      "  [6.90312675 6.80538772]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.85085036e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.01995246 10.16995415]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02725942 7.07769247]]\n",
      "\n",
      " [[6.72772837 7.121476  ]\n",
      "  [8.93022939 9.12164619]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.72179609 7.06372666]]\n",
      "\n",
      " [[6.72772837 7.121476  ]\n",
      "  [8.93022939 9.12164619]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.02041596 8.81220105]\n",
      "  [6.65972976 6.92757428]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.56528154e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.81818896 8.97408219]\n",
      "  [6.65972976 6.92757428]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.08206798 10.23363555]\n",
      "  [ 7.70526343  8.5196689 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19659143e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.72179609 7.06372666]]\n",
      "\n",
      " [[6.72772837 7.121476  ]\n",
      "  [9.03720645 9.20948157]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.72179609 7.06372666]]\n",
      "\n",
      " [[6.72772837 7.121476  ]\n",
      "  [9.13348581 9.28853342]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.72179609 7.06372666]]\n",
      "\n",
      " [[6.72772837 7.121476  ]\n",
      "  [9.22013723 9.35968008]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.3977554e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.72179609 7.06372666]]\n",
      "\n",
      " [[6.72772837 7.121476  ]\n",
      "  [9.2981235  9.42371207]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.45186925e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.48817363 7.1214962 ]]\n",
      "\n",
      " [[6.72772837 7.121476  ]\n",
      "  [9.2981235  9.42371207]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.74192168 9.08049532]\n",
      "  [6.65972976 6.92757428]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.91417184e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.08206798 10.23363555]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[5.62518751 4.5740535 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[7.28060313 8.37369694]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.48817363 7.1214962 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.2981235  9.42371207]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.59021024 8.80973249]\n",
      "  [6.65972976 6.92757428]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.45186925e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.48817363 7.1214962 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.36831115 9.48134086]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.50057172e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.48817363 7.1214962 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.12023967 9.26456342]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.94320099 8.61069161]\n",
      "  [6.65972976 6.92757428]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.48817363 7.1214962 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.13740023 9.07655836]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.12656059 8.43596915]\n",
      "  [6.65972976 6.92757428]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.34034508e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.48817363 7.1214962 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.21932435 8.91266684]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.39610749 8.8114388 ]\n",
      "  [6.65972976 6.92757428]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.80911456  9.06875039]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.22876373 10.18188451]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.48817363 7.1214962 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [8.96810517 8.98090894]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.78529581 8.49808297]\n",
      "  [6.65972976 6.92757428]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.48817363 7.1214962 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [8.99817091 8.88968766]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.2841534  8.82179529]\n",
      "  [6.65972976 6.92757428]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.01596246e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.79606277  9.107129  ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.22876373 10.18188451]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.79606277  9.107129  ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.21365023 10.14681732]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24373533e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.48817363 7.1214962 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [8.81274681 8.97356195]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.74828615e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.2841534  8.82179529]\n",
      "  [6.64352624 6.99250526]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.2841534  8.82179529]\n",
      "  [6.63542448 7.02497075]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.74828615e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.02753679 8.96962457]\n",
      "  [6.63542448 7.02497075]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.79606277  9.107129  ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.13192384 10.16283344]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.48817363 7.1214962 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [8.93147213 9.07620575]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19745375e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.48817363 7.1214962 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.03832492 9.16858518]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.45510153 7.14859793]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.03832492 9.16858518]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.86653793 9.04994566]\n",
      "  [6.63542448 7.02497075]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.79606277  9.107129  ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.18129189 10.24885079]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.45510153 7.14859793]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.13449243 9.25172666]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.33832738e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.45510153 7.14859793]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [8.71386139 9.24584159]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.41881352 8.72330947]\n",
      "  [6.63542448 7.02497075]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.04645597e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.45510153 7.14859793]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [8.7244561  9.11224458]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.6991892  8.50655257]\n",
      "  [6.63542448 7.02497075]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.05380753e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [8.7244561  9.11224458]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [8.85201049 9.20102013]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.14231616e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [8.90568093 9.00313109]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.91186697 8.35452872]\n",
      "  [6.63542448 7.02497075]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.01758725 8.84337703]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.91186697 8.35452872]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.06296839 8.21461517]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.11582853 8.95903933]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.3253767e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.18310162 8.76536573]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.40400095 8.7068479 ]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.98302225e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.79606277  9.107129  ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.26388659 10.13057169]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.37205678e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.26479146 8.88882916]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.33831231 8.99994624]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.47975584e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.03075653 8.98271228]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.81430309 8.44650886]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.26634615e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.12768088 9.08444106]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.26672018e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.21491279 9.17599695]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.46063286 7.19293613]\n",
      "  [9.13317763 8.96660202]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.0604226  8.30989524]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.26748301e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [9.13317763 8.96660202]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.33741506e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [9.19075785 8.80725911]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.43576593 8.7071763 ]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.79606277  9.107129  ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.30824644 10.08818949]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.37736936e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.9696853  8.88650007]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.14118154 8.88886394]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.07111467e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.79606277  9.107129  ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.24199734 10.09869477]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.74131527 8.99879561]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.96738971 8.98390988]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.79606277  9.107129  ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.11752478 10.14886563]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.06550592e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.86718374 9.09891605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.62054775 9.14302198]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.43191395 8.64916373]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.98170663e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.75849298 9.22871978]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07742535e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.88264368 9.3058478 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.99437931 9.37526302]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.24822088e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [9.09494138 9.43773672]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31088333e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.92023627 9.17853385]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.06296689 8.88412812]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.79606277  9.107129  ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.1268569  10.24584636]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.18965731e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.68530489 9.14291817]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.8822262  9.0404026 ]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.79606277  9.107129  ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.03755041 10.28009045]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.02664092e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.49554293 9.18762013]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.46939313e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.75613326 9.13223748]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.88328156e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.79606277  9.107129  ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.91699237 10.31509327]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.8949671e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.71733321 7.2191968 ]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.35022477 9.24670506]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.64486358 9.19215605]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.79962762e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.79606277  9.107129  ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.79858609 10.35622866]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.79413237e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.69875651 7.30828042]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.35022477 9.24670506]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.69875651 7.30828042]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.23305782 9.30021495]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.30468973e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.54186623 9.23856949]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.79606277  9.107129  ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.69251617 10.39820031]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.69875651 7.30828042]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.1332754  9.34553527]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.48935822 8.76213634]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.6164565   8.6964161 ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.69251617 10.39820031]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.6164565   8.6964161 ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.59956825 10.43731426]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.64359351e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.69875651 7.30828042]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.31994786 9.41098174]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.77312355e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.69875651 7.30828042]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.48795307 9.46988357]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.69875651 7.30828042]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.63915777 9.52289521]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.19892398e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.69875651 7.30828042]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.77524199 9.57060569]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.69875651 7.30828042]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.89771779 9.61354512]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17403197e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.34512154 7.15899475]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.89771779 9.61354512]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.30376623 8.72648622]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17403197e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.34512154 7.15899475]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [9.00794601 9.65219061]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.25051817e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.34512154 7.15899475]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.8254795  9.31668979]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.79846571 8.34180955]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.45481085  8.32677449]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.59956825 10.43731426]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45481085  8.32677449]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.82997592 10.44533305]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.34512154 7.15899475]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.53212603 8.99506872]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.31208327 8.26893226]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.92035173e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.34512154 7.15899475]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.67891343 9.09556184]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.02220595e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.34512154 7.15899475]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.66429002 8.85535383]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.62175764 8.17660766]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.34512154 7.15899475]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.79786102 8.96981844]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22094848e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.34512154 7.15899475]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.84763357 8.75555229]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.04286919 8.76643705]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45481085  8.32677449]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.95404139 10.22488744]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.13927906e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.34512154 7.15899475]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.64096446 8.88435096]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.47782038 8.43695891]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.19917471e-16 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.56368892 6.95428094]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.64096446 8.88435096]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.69529597 8.27221984]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99587356e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.56368892 6.95428094]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.77686801 8.99591587]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.77686801 8.99591587]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.12926454 8.7260649 ]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45481085  8.32677449]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.9877679  10.21081007]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.0901756e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.89918121 9.09632428]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.70129642 9.0385881 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.85973943 8.94735647]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45481085  8.32677449]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.97440252 10.22084027]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.81132118e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.49454398 9.09823664]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.71963072 9.06201435]\n",
      "  [6.88245903 6.85429686]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45481085  8.32677449]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.88501885 10.24971479]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.33512428 9.17392406]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.71963072 9.06201435]\n",
      "  [6.5290818  7.05195417]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.6138229  9.13089309]\n",
      "  [6.5290818  7.05195417]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45481085  8.32677449]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.77655914 10.29442702]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.78365431e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.2130913  9.23931926]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.28315093e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.51753511 9.18321735]\n",
      "  [6.5290818  7.05195417]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45481085  8.32677449]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.67351609 10.34294122]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.11355969 9.29294657]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.42817399 9.22878516]\n",
      "  [6.5290818  7.05195417]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.63068201e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.39681186  8.80056373]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.67351609 10.34294122]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.39681186  8.80056373]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.58218192 10.38864924]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.62991299e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.02804944 9.33798735]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.34695976 9.26985228]\n",
      "  [6.5290818  7.05195417]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.39681186  8.80056373]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.50231074 10.42951956]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.2252445  9.40418862]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.70740989e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.05140615 9.41003522]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.27440418 9.30673396]\n",
      "  [6.5290818  7.05195417]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.51188443e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.39681186  8.80056373]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.47171783 10.47877387]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.58678531e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [7.93546475 9.42771119]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.81138799 8.92445146]\n",
      "  [6.5290818  7.05195417]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.5063348e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.09228757 9.28363618]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.14260902 8.6756802 ]\n",
      "  [6.5290818  7.05195417]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.61515249e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.30318739 9.11209017]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.39257947 8.48267617]\n",
      "  [6.5290818  7.05195417]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.50862548 8.94911555]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.82352185e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.78497687 8.93284763]\n",
      "  [6.5290818  7.05195417]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.39681186  8.80056373]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.63930911 10.31903315]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.90404495e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.36830349 9.04769683]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.78497687 8.93284763]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.40191285e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.23980983 8.58550255]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.53147314 9.14292715]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.18397974e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.67832583 9.22863443]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.81049324 9.30577099]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.70117055 9.08708651]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.60037314 8.42758588]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.79073453 8.91457761]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.81648038 8.27962398]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09979742e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.91166108 9.02311985]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.23674141e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.98242269 8.82340952]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.06396383 8.76742525]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.39681186  8.80056373]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.91262363 10.18888038]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.71679688 8.91867486]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.51870067 8.45118257]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.84511719 9.02680737]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.83003886 8.89387672]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.79136588 8.28314197]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12707028e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.93156578 8.76019515]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.10023551e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.96830925 8.14564904]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.19751874e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [9.05310659 8.63835719]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.24920408 8.64837668]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.39681186  8.80056373]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.07755445 10.04978307]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.28185461e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [9.14779593 8.77452147]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [9.23301634 8.89706932]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.40669208e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.9161898  8.90788533]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.72403519e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.69107796 8.38734247]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.18684951e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [9.02457082 9.0170968 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [6.75996285 6.78602841]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [9.12211374 9.11538712]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [9.12211374 9.11538712]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.32973794e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [9.03748805 8.91263055]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.17656076 8.71358446]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.91103994e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.39681186  8.80056373]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.15377245 10.08994375]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.27101708e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [9.13373925 9.02136749]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.83749393 8.99611753]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.62327795 8.45523924]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.22644865e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.95374454 9.09650578]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.21290834e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [9.05837008 9.1868552 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [8.97849622 8.9755233 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.90303746 8.31782894]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.23008327e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [9.0504631  8.81489323]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.31302771 8.69489197]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.39681186  8.80056373]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.19707146 10.07092917]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.88358748 7.18310887]\n",
      "  [9.14541679 8.9334039 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.34590768e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [9.14541679 8.9334039 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.34590768e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [8.89791948 8.94465874]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.03534244 8.87581765]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.39681186  8.80056373]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.15770352 10.11332808]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [8.66309672 9.02265643]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.88075263 8.98324006]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.56148734  8.9456131 ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.15770352 10.11332808]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.56148734  8.9456131 ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 7.04409045 10.16572661]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [6.0112309e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [8.48384941 9.10462424]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.75801249 9.05791067]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.56148734  8.9456131 ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.91558499 10.224713  ]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [8.63546447 9.19416181]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.19841144e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [8.42093723 9.22024518]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.64524024 9.11884054]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.79865105e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.56148734  8.9456131 ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.82616739 10.30045457]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.000000e+00 1.000000e+00]\n",
      " [5.843199e-17 1.000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [8.26856471 9.2576588 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.30495109e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.13004601 8.76248379]\n",
      "  [6.37853165 7.09911614]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [8.38630076 9.13382292]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.13004601 8.76248379]\n",
      "  [6.44128423 7.05455158]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.79548996 9.00142372]\n",
      "  [6.44128423 7.05455158]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.56148734  8.9456131 ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.767604   10.30375645]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [8.31134636 9.16748095]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.60478658 9.12221444]\n",
      "  [6.44128423 7.05455158]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.69596861e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.56148734  8.9456131 ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.70834054 10.31887061]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [8.19758781 9.23262625]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.27688072e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[7.60478658 9.12221444]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.08142841 8.75415772]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.68821921e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [8.33136527 9.11797621]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.72405042 9.0046271 ]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.56148734  8.9456131 ]\n",
      "  [ 7.72919343  5.95396498]]\n",
      "\n",
      " [[ 6.68671638 10.30662579]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.78104597e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [8.49822874 9.20617859]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.89683076e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [8.64840587 9.28556073]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [8.78356528 9.35700466]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.09482276e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [8.48140281 9.28035317]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.53671176 9.12496387]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "QTable: [[[ 6.56148734  8.9456131 ]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.68671638 10.30662579]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "QTable: [[[5.62518751 4.5740535 ]\n",
      "  [3.39256112 4.71214127]]\n",
      "\n",
      " [[7.28060313 8.37369694]\n",
      "  [2.1740912  1.3901312 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.88515543e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [8.63326253 9.35231785]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.99052927e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[7.09996046 7.164916  ]\n",
      "  [8.76993628 9.41708607]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.56466493 7.23244355]\n",
      "  [8.76993628 9.41708607]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.44304243 9.18513225]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.45543022  9.09545686]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.68671638 10.30662579]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45543022  9.09545686]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.8513327  10.42014732]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08536574e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.56466493 7.23244355]\n",
      "  [8.36218511 9.38259593]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.16464818e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.06639526 8.8456045 ]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.56466493 7.23244355]\n",
      "  [8.5259666  9.44433634]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.91607777e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.56466493 7.23244355]\n",
      "  [8.48954141 9.26040997]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.42901419 8.62696624]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.89080271e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.56466493 7.23244355]\n",
      "  [8.61637638 9.08099148]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.66105765 8.44587971]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.56466493 7.23244355]\n",
      "  [8.77261125 8.91884762]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.83957332 8.2904789 ]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.6747282  6.90649306]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.08722187e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.56466493 7.23244355]\n",
      "  [8.89535012 9.02696286]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.17238908e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.02882692 7.03916905]]\n",
      "\n",
      " [[6.56466493 7.23244355]\n",
      "  [9.00581511 9.12426658]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.56466493 7.23244355]\n",
      "  [9.00581511 9.12426658]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.24903956e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.56466493 7.23244355]\n",
      "  [9.1052336  9.21183992]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.56466493 7.23244355]\n",
      "  [9.19471024 9.29065593]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.38011188e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.56466493 7.23244355]\n",
      "  [9.27523922 9.36159033]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.43599009e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.56466493 7.23244355]\n",
      "  [9.17344894 8.99698673]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[8.83957332 8.2904789 ]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.08916624 8.24403414]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.95171204 7.21501646]\n",
      "  [9.17344894 8.99698673]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.1452356  7.20630292]\n",
      "  [9.17344894 8.99698673]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.36535889e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.1452356  7.20630292]\n",
      "  [9.22239096 8.79610702]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.2851162  8.790076  ]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45543022  9.09545686]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 7.11462274 10.22851647]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.1452356  7.20630292]\n",
      "  [9.30015187 8.91649632]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.45327671e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.1452356  7.20630292]\n",
      "  [9.37013668 9.02484669]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.1452356  7.20630292]\n",
      "  [9.43312301 9.12236202]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.1452356  7.20630292]\n",
      "  [9.48981071 9.21012582]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.58487897e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.1452356  7.20630292]\n",
      "  [9.54082964 9.28911324]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.62028046e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.1452356  7.20630292]\n",
      "  [9.0844613  9.16058702]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[8.77634262 8.55927281]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.1452356  7.20630292]\n",
      "  [9.17601517 9.24452832]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.36713957e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.24302387 7.30096279]\n",
      "  [9.17601517 9.24452832]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.36713957e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.24302387 7.30096279]\n",
      "  [9.09854463 9.04597328]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.02758916 8.39802572]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.31338359e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.24302387 7.30096279]\n",
      "  [9.16030798 8.88219693]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [6.14035557 9.86130605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.24302387 7.30096279]\n",
      "  [9.2513211  8.74185512]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [7.27070623 9.42739507]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.41939356e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.24302387 7.30096279]\n",
      "  [9.32618899 8.8676696 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.24302387 7.30096279]\n",
      "  [9.39357009 8.98090264]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.51809862e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.24302387 7.30096279]\n",
      "  [8.60506754 9.26140935]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.04506591e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [6.98120221 9.80510412]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45543022  9.09545686]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.99933838 10.31882197]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[7.24302387 7.30096279]\n",
      "  [8.09501465 9.55274632]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 6.26255674  7.17616157]]\n",
      "\n",
      " [[ 6.87319343  6.76943809]\n",
      "  [ 6.79033646 10.03008085]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45543022  9.09545686]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.73767505 10.48050952]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.12340896e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [8.09501465 9.55274632]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.42348485e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [7.13317409 9.83613895]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.61704478e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [8.28551319 9.59747169]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.74922969e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [7.99602623 9.73319143]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [7.26499754 9.81134605]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [8.19642361 9.75987228]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.68741138e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [8.37678125 9.78388506]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.81255963e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [8.09438964 9.81648095]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.04110471e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [7.37025462 9.8322654 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [8.28495067 9.83483285]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.74883937e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [8.45645561 9.85134957]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.86784483e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [8.17632965 9.85858095]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.11414149e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 6.26255674  7.17616157]]\n",
      "\n",
      " [[ 6.87319343  6.76943809]\n",
      "  [ 6.88019733 10.10833651]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45543022  9.09545686]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.63936939 10.68368714]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.6734684e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [8.35869669 9.87272285]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.80001095e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [7.93142728 9.97969603]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.77409593e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 6.26255674  7.17616157]]\n",
      "\n",
      " [[ 6.87319343  6.76943809]\n",
      "  [ 6.59584642 10.32764311]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45543022  9.09545686]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.4922556  10.83372198]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.65105997e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 6.33764652  7.66251373]\n",
      "  [ 7.60405221 10.12090526]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 6.26255674  7.17616157]]\n",
      "\n",
      " [[ 6.87319343  6.76943809]\n",
      "  [ 6.39482545 10.49731035]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.50490728e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.45543022  9.09545686]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.28774868 10.96522309]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.27637115e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 6.33764652  7.66251373]\n",
      "  [ 7.35995628 10.25937677]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.43730153e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 6.26255674  7.17616157]]\n",
      "\n",
      " [[ 6.87319343  6.76943809]\n",
      "  [ 6.64139524 10.35240588]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.10699558e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 6.33764652  7.66251373]\n",
      "  [ 7.33653624 10.27065074]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.60839369e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 6.26255674  7.17616157]]\n",
      "\n",
      " [[ 6.87319343  6.76943809]\n",
      "  [ 6.75531211 10.28446323]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.09074466e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 6.33764652  7.66251373]\n",
      "  [ 7.60288261 10.24358566]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.27555958e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 6.33764652  7.66251373]\n",
      "  [ 7.50356615 10.23557812]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.68743941e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [6.45982815 9.78041436]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.3098872   8.68591118]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.28774868 10.96522309]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.17889848  8.31732006]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.28774868 10.96522309]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.3630021e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.17889848  8.31732006]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.1453008  11.0768428 ]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.20664494e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 6.33764652  7.66251373]\n",
      "  [ 7.75320954 10.21202031]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 6.33764652  7.66251373]\n",
      "  [ 7.46053603 10.0181759 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [6.71412848 9.89747754]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 6.33764652  7.66251373]\n",
      "  [ 7.71448242 10.01635831]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.35299751e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [7.54289261 9.96717017]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.39765876e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [6.87422128 9.93560684]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [7.52113482 9.95782782]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [6.94556457 9.95093455]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.04376713e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [7.53879324 9.95928773]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [6.98829958 9.95918237]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.04621773e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [7.78491391 9.96335896]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.40186917e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [8.00642252 9.96702306]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.11111433e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [7.79853109 9.96718448]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [6.26255674 7.17616157]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [7.11356223 9.96646497]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0822636e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [7.74469044 9.97017823]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [5.97670326 7.57466677]]\n",
      "\n",
      " [[6.87319343 6.76943809]\n",
      "  [7.11356223 9.96646497]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.93602536e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [5.97670326 7.57466677]]\n",
      "\n",
      " [[6.2820216  7.37130504]\n",
      "  [7.11356223 9.96646497]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.93602536e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [5.97670326 7.57466677]]\n",
      "\n",
      " [[6.2820216  7.37130504]\n",
      "  [7.15465729 9.97130378]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [7.97022139 9.97316041]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [8.17319925 9.97584437]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.67129625e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [7.94846254 9.97644369]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.96454078e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [5.97670326 7.57466677]]\n",
      "\n",
      " [[6.2820216  7.37130504]\n",
      "  [6.54888804 9.31257991]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.06100863  7.98558805]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.1453008  11.0768428 ]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.26415903e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.06100863  7.98558805]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.25203542 11.02899888]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [7.59378649 9.71325381]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [5.97670326 7.57466677]]\n",
      "\n",
      " [[6.2820216  7.37130504]\n",
      "  [6.81195861 9.54159148]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.26924787e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [7.83440784 9.74192843]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0872425e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [8.05096705 9.76773559]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.11729612e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [8.24587035 9.79096203]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [8.42128331 9.81186583]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.16868783e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [7.9354251  9.72256951]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.45349162e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [5.97670326 7.57466677]]\n",
      "\n",
      " [[6.2820216  7.37130504]\n",
      "  [7.08014935 9.65982354]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [8.14188259 9.75031256]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[6.33764652 7.66251373]\n",
      "  [7.90300103 9.73908569]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.54088884 10.24151132]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.33822105e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.03131848  8.90439358]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.25203542 11.02899888]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.03131848  8.90439358]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.28721812 10.91013372]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.48380857e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[5.78517879 7.9278614 ]\n",
      "  [7.90300103 9.73908569]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.53865337e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.93164483 10.01638994]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[5.78517879 7.9278614 ]\n",
      "  [8.11270093 9.76517713]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.12586342e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[5.78517879 7.9278614 ]\n",
      "  [7.8290084  9.88914454]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.80979481e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [5.97670326 7.57466677]]\n",
      "\n",
      " [[6.2820216  7.37130504]\n",
      "  [7.09742578 9.96385278]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.08649317e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[5.78517879 7.9278614 ]\n",
      "  [7.75347451 9.93011338]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.56360014 10.34597988]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.03131848  8.90439358]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.24499887 10.92711221]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[5.78517879 7.9278614 ]\n",
      "  [7.97812706 9.93710204]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.10718754e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[5.78517879 7.9278614 ]\n",
      "  [8.18031435 9.94339184]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [7.11673951 7.16929116]]\n",
      "\n",
      " [[5.51802945 8.10232265]\n",
      "  [8.18031435 9.94339184]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [4.5544125e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 7.05392581 10.15034668]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.67623334e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.9117275  10.03183459]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.52496245 10.44601822]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.33333846e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.03131848  8.90439358]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.28719043 10.97628994]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.48986377e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.56584873 10.19432458]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.52760222e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.78882072 10.30073894]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.80926386 10.17489213]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.6256296e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.62016022 10.20774164]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.71069067e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.40928653 10.54088545]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.03131848  8.90439358]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.1916593  11.07124163]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.85814419 10.18696748]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.45268288e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 8.07232977 10.16827073]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.60130399e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 8.2650968  10.15144366]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.1470126e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.69626301 10.29207601]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.44733592e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.78314847 10.38727313]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.06807105e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.56139089 10.30094725]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.70675476e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.36823796 10.62213321]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.2963267e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.03131848  8.90439358]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.12038601 11.15599972]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.8052518  10.27085253]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 8.02472662 10.24376728]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.56827267e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 8.22225396 10.21939055]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 8.40002857 10.19745149]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 8.56002571 10.17770634]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.93971102e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 8.70402314 10.15993571]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.20792586e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 8.83362082 10.14394214]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12955577e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.96410559 10.32082436]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.41885275e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.13227338 10.77346649]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.03131848  8.90439358]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.24583524 11.2063296 ]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.43496215 10.46979878]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.25511944e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.54012155 10.57465276]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.15904135e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.69146594 10.4228189 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.06740532e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 7.11673951  7.16929116]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.92231934 10.38053701]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.49721334e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 6.17441837  7.81450668]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.92231934 10.38053701]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.93898851 10.43954118]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.49721334e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 6.17441837  7.81450668]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.73675508 10.36608498]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.81489051e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.46782835 10.70230243]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.03131848  8.90439358]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.21761965 11.24959879]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 6.17441837  7.81450668]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.96307957 10.32947648]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.52549643e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 6.17441837  7.81450668]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 8.16677161 10.29652883]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 6.17441837  7.81450668]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.67051715 10.42918539]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.22096204 10.85099073]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.31434031e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.03131848  8.90439358]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.17701668 11.29647355]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.32249047e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 6.17441837  7.81450668]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 7.90346543 10.38626685]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 6.17441837  7.81450668]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 8.11311889 10.34764016]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.62960712e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 6.17441837  7.81450668]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 8.301807   10.31287615]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 6.17441837  7.81450668]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 8.4716263  10.28158853]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 6.17441837  7.81450668]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 8.62446367 10.25342968]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.98442384e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 6.17441837  7.81450668]]\n",
      "\n",
      " [[ 5.51802945  8.10232265]\n",
      "  [ 8.7620173  10.22808671]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07987085e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 6.17441837  7.81450668]]\n",
      "\n",
      " [[ 6.26382165  8.14239601]\n",
      "  [ 8.7620173  10.22808671]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.07987085e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 6.17441837  7.81450668]]\n",
      "\n",
      " [[ 6.26382165  8.14239601]\n",
      "  [ 8.88581557 10.20527804]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.26382165  8.14239601]\n",
      "  [ 8.88581557 10.20527804]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.31665956e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 7.16480725 10.50760658]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.16577315e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.26382165  8.14239601]\n",
      "  [ 8.30883069 10.30568165]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.97158373e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 7.4059359  10.37607595]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.26382165  8.14239601]\n",
      "  [ 8.47794762 10.27511349]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.26382165  8.14239601]\n",
      "  [ 8.20134817 10.28798712]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.13890035e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 7.48350722 10.30323283]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.69082848e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.26382165  8.14239601]\n",
      "  [ 8.38121335 10.25918841]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 8.38121335 10.25918841]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.81563502e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 8.54309202 10.23326957]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 8.68878281 10.20994261]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 8.81990453 10.18894835]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [6.12003818e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 8.40335515 10.21576731]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.03854525e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.71256028 10.67020583]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.28616634e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.03131848  8.90439358]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.4498504  11.2345437 ]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 8.56301964 10.19419058]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.96653393 10.36517762]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.65777436e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.4362203  10.8289204 ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.03131848  8.90439358]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.41153877 11.2633429 ]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.10557867e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.55775509 10.51415697]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.74121219 10.62012299]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.47536242 10.50512768]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.35531123e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.86075106 10.51211256]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.72782618 10.45461491]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.95504356 10.40915342]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.575594    8.24764963]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 8.1595392  10.36823808]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.53209742  8.32866984]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 8.1595392  10.36823808]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.76060237e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.49499104 10.76139344]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 6.08027475  9.45753395]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.41153877 11.2633429 ]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.08027475  9.45753395]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.46958507 11.27896668]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.53209742  8.32866984]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.67776602 10.48867642]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.81860193 10.57616729]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.53209742  8.32866984]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.56632378 10.47480512]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.46271107e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.49713499 10.79967032]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.48917644e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.08027475  9.45753395]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.26132205 11.32940539]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.53209742  8.32866984]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.38201589 10.55727069]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.01658608e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.70137385 10.62274343]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0244605e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.53209742  8.32866984]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.6438143  10.50154362]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.53209742  8.32866984]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.50245669 10.49986918]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.35521574 10.84313387]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.08027475  9.45753395]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.1316437  11.36465037]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.53209742  8.32866984]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.29331464 10.58718814]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.40981678e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.97670326  7.57466677]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.13026535 10.96742708]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.25468251e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 6.08027475  9.45753395]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.98314771 11.41720044]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.01215073e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.53209742  8.32866984]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.56398318 10.52846933]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.53209742  8.32866984]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.80758486 10.47562239]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.4176003e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.53209742  8.32866984]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 8.02682637 10.42806015]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.56972966e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.53209742  8.32866984]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 8.22414374 10.38525414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.53209742  8.32866984]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.56417801 10.5795979 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.25372609e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.44045777  8.17430422]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.13026535 10.96742708]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.25372609e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.44045777  8.17430422]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.59080388 10.7155527 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.53209742  8.32866984]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.41841056 10.57602003]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.44045777  8.17430422]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.22751184 10.14078993]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.21903814e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.97224728  9.01178055]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.98314771 11.41720044]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.15164271e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.97224728  9.01178055]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.95893808 11.43900823]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.14755638e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.25705345  8.22065089]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.41841056 10.57602003]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.32120439e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.44045777  8.17430422]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.58112014 10.30080298]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.14755638e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.41841056 10.57602003]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.34165333 10.40833121]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.13313889e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.44045777  8.17430422]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.72722141 10.31373397]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.09429536e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.36171523 10.32965919]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.44045777  8.17430422]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 6.80829679 10.28873066]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.62554371 10.29669327]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.29128387e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.86298934 10.26702395]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 8.0766904  10.24032155]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.60432978e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.48439616  8.17487337]\n",
      "  [ 7.76166392 10.23565304]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.72420491e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.44045777  8.17430422]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 7.00881396 10.23862655]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.07714725e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.34686365  8.1816979 ]\n",
      "  [ 7.76166392 10.23565304]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.38573625e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.34686365  8.1816979 ]\n",
      "  [ 7.68435755 10.21327714]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.44045777  8.17430422]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 7.07815    10.20462413]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.06641883e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.34686365  8.1816979 ]\n",
      "  [ 7.91592179 10.19194943]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.09855483e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.34686365  8.1816979 ]\n",
      "  [ 8.12432961 10.17275448]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.34686365  8.1816979 ]\n",
      "  [ 8.31189665 10.15547903]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.34686365  8.1816979 ]\n",
      "  [ 8.48070699 10.13993113]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.8846726e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.34686365  8.1816979 ]\n",
      "  [ 8.07161349 10.15181522]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.91145319e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.44045777  8.17430422]]\n",
      "\n",
      " [[ 6.2820216   7.37130504]\n",
      "  [ 7.2677204  10.16303815]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.60080697e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.34686365  8.1816979 ]\n",
      "  [ 8.26445214 10.1366337 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.14692313e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.34686365  8.1816979 ]\n",
      "  [ 8.43800693 10.12297033]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.34686365  8.1816979 ]\n",
      "  [ 8.12609162 10.12670042]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [5.44045777 8.17430422]]\n",
      "\n",
      " [[6.2820216  7.37130504]\n",
      "  [6.52275911 9.6862313 ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.87502255  8.6106025 ]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.95893808 11.43900823]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.13484391e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.87502255  8.6106025 ]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.22990569 11.27018429]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.63860876e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [5.59589095 8.34073346]]\n",
      "\n",
      " [[6.34686365 8.1816979 ]\n",
      "  [7.67214946 9.93784273]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.05214668e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [5.44045777 8.17430422]]\n",
      "\n",
      " [[6.2820216  7.37130504]\n",
      "  [6.83023934 9.81825274]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [5.59589095 8.34073346]]\n",
      "\n",
      " [[6.34686365 8.1816979 ]\n",
      "  [7.90493451 9.94405846]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.48515019e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [5.59589095 8.34073346]]\n",
      "\n",
      " [[6.34686365 8.1816979 ]\n",
      "  [8.11444106 9.94965261]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [5.59589095 8.34073346]]\n",
      "\n",
      " [[6.34686365 8.1816979 ]\n",
      "  [8.30299695 9.95468735]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.76136149e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [5.59589095 8.34073346]]\n",
      "\n",
      " [[6.34686365 8.1816979 ]\n",
      "  [7.88359421 9.90464477]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [5.44045777 8.17430422]]\n",
      "\n",
      " [[6.2820216  7.37130504]\n",
      "  [7.06855735 9.87098428]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.47034238e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [5.59589095 8.34073346]]\n",
      "\n",
      " [[6.34686365 8.1816979 ]\n",
      "  [8.09523479 9.91418029]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.61719753e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [5.59589095 8.34073346]]\n",
      "\n",
      " [[6.34686365 8.1816979 ]\n",
      "  [8.28571131 9.92276227]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.74936717e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [5.59589095 8.34073346]]\n",
      "\n",
      " [[6.34686365 8.1816979 ]\n",
      "  [8.45714018 9.93048604]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [5.59589095 8.34073346]]\n",
      "\n",
      " [[6.34686365 8.1816979 ]\n",
      "  [8.05599303 9.91363673]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.90479695e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [5.44045777 8.17430422]]\n",
      "\n",
      " [[6.2820216  7.37130504]\n",
      "  [7.25667589 9.90094683]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.58996809e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [5.59589095 8.34073346]]\n",
      "\n",
      " [[6.34686365 8.1816979 ]\n",
      "  [7.93066687 9.9171971 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.03533041e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [5.44045777 8.17430422]]\n",
      "\n",
      " [[6.04368116 7.64603125]\n",
      "  [7.25667589 9.90094683]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.03533041e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[9.17791777 8.25189163]\n",
      "  [5.44045777 8.17430422]]\n",
      "\n",
      " [[6.04368116 7.64603125]\n",
      "  [7.30060469 9.91735226]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.5030056e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [5.59589095 8.34073346]]\n",
      "\n",
      " [[6.34686365 8.1816979 ]\n",
      "  [8.13760018 9.92547739]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.64659443e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[6.6259207  6.95187819]\n",
      "  [5.59589095 8.34073346]]\n",
      "\n",
      " [[6.0936737  8.05778985]\n",
      "  [8.13760018 9.92547739]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.06581214e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.44045777  8.17430422]]\n",
      "\n",
      " [[ 6.04368116  7.64603125]\n",
      "  [ 6.64226462 10.46674984]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.87502255  8.6106025 ]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.36999292 11.1052831 ]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.64659443e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.59589095  8.34073346]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.72570594 10.14943863]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.44045777  8.17430422]]\n",
      "\n",
      " [[ 6.04368116  7.64603125]\n",
      "  [ 6.36912948 10.67548816]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.87502255  8.6106025 ]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.27527883 11.112417  ]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.36078539e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.72570594 10.14943863]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.41947137e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.44045777  8.17430422]]\n",
      "\n",
      " [[ 6.04368116  7.64603125]\n",
      "  [ 6.77484711 10.39751953]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.36078539e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.95313535 10.13449477]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.68650652 10.2262552 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.70099453e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.44045777  8.17430422]]\n",
      "\n",
      " [[ 6.04368116  7.64603125]\n",
      "  [ 6.39753509 10.64372657]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.87502255  8.6106025 ]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.21224203 11.14671058]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.33358532e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.4022673  10.37061823]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.44045777  8.17430422]]\n",
      "\n",
      " [[ 6.04368116  7.64603125]\n",
      "  [ 6.65967446 10.47011057]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.36500343 10.37335334]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.38409867  8.27519634]]\n",
      "\n",
      " [[ 6.04368116  7.64603125]\n",
      "  [ 6.65967446 10.47011057]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.62107745e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.38409867  8.27519634]]\n",
      "\n",
      " [[ 5.68571036  8.01105985]\n",
      "  [ 6.65967446 10.47011057]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.62107745e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.38409867  8.27519634]]\n",
      "\n",
      " [[ 5.68571036  8.01105985]\n",
      "  [ 6.77583861 10.38439662]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.11049774e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.39283716 10.34043532]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.70168252e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.68571036  8.01105985]\n",
      "  [ 6.77583861 10.38439662]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.70168252e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.68571036  8.01105985]\n",
      "  [ 6.84505417 10.32837244]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.65355344 10.30639179]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.8881981  10.27575261]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.09470739e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.68212072 10.26922528]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.68571036  8.01105985]\n",
      "  [ 6.99537537 10.27187633]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.33054206e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.63921051 10.24336317]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.85401675e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.68571036  8.01105985]\n",
      "  [ 6.48258449 10.5946224 ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.87502255  8.6106025 ]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.16180521 11.17070056]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.87528946 10.21902686]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.09291596e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.53067853 10.34736239]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.68571036  8.01105985]\n",
      "  [ 6.75356366 10.43625615]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.04509159e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.77761067 10.31262615]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.07936031e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.99984961 10.28136353]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 8.19986465 10.25322718]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 8.37987818 10.22790446]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.89136455 10.28845469]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.68571036  8.01105985]\n",
      "  [ 7.03332765 10.33350995]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.75901334 10.27763133]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.88035144e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.68571036  8.01105985]\n",
      "  [ 6.48138591 10.6350352 ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.87502255  8.6106025 ]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.18450794 11.19640281]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.38389703e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.47206103 10.39282974]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.49736492e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.68571036  8.01105985]\n",
      "  [ 6.21449613 10.79607872]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.87502255  8.6106025 ]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.08107838 11.2553333 ]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.18478388e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.72485493 10.35354677]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.36019488e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.95236944 10.31819209]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.46198317 10.47752754]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.68571036  8.01105985]\n",
      "  [ 6.59204133 10.58905038]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.34559726  8.44056199]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.36780812 10.47438392]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.57414754e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.68571036  8.01105985]\n",
      "  [ 6.74314392 10.48427876]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.36780812 10.47438392]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.67899602e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.74314392 10.48427876]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.67899602e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.30400331 10.7442727 ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.87502255  8.6106025 ]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.98766244 11.31742022]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.11244388e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.20550538 10.53490104]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.53420381 10.58609677]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.99982374e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.21643422 10.50188923]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [9.0680294e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.16216688 10.82001647]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 8.30955088e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.83257625  9.33226934]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.98766244 11.31742022]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.15477544e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.8113531   9.69310276]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.98766244 11.31742022]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.15477544e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.80074153  9.87351947]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.98766244 11.31742022]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.80074153  9.87351947]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.88040491 11.3594658 ]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.00740714e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.49479079 10.4517003 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.20055582e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.74531171 10.40653027]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.37438962e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.33752261 10.53127172]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.27586222e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.51609248 10.62251692]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.2751983  10.51464263]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.1102082  10.85504478]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.08035058e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.75253273  9.98054605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.88040491 11.3594658 ]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.75253273  9.98054605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.85028177 11.38558995]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.04818291e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.08168243 10.59933923]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.23980865e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 5.89521681 10.98175837]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.05944845e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.75253273  9.98054605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.75781386 11.43253067]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.82780861e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 6.89892794 10.69237296]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.20717958 10.76782837]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.57418581e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.20903515 10.62313567]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0004546e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.48813163 10.5608221 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.19593509e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.73931847 10.50473989]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.37023097e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.96538662 10.4542659 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.52709727e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 6.0936737   8.05778985]\n",
      "  [ 7.46556514 10.5342643 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.58981585 10.59761991]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 5.68276319  8.26794289]\n",
      "  [ 7.46556514 10.5342643 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [9.1452066e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.78113398 10.51251567]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 5.68276319  8.26794289]\n",
      "  [ 7.44523616 10.47213842]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.70535692e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.19369253 10.8292701 ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.75253273  9.98054605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.8570014  11.4051207 ]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.16617038e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 5.68276319  8.26794289]\n",
      "  [ 7.70071255 10.42492458]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.34344274e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 5.68276319  8.26794289]\n",
      "  [ 7.32783329 10.54417033]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.29773754e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 5.93964683 10.97668333]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.75253273  9.98054605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.85963401 11.42022848]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.08470577e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.3700562   8.4139925 ]]\n",
      "\n",
      " [[ 5.68276319  8.26794289]\n",
      "  [ 7.59504996 10.4897533 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.27012459e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.72304808  8.40289757]]\n",
      "\n",
      " [[ 5.68276319  8.26794289]\n",
      "  [ 7.59504996 10.4897533 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.27012459e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.72304808  8.40289757]]\n",
      "\n",
      " [[ 5.87940158  8.32987276]\n",
      "  [ 7.59504996 10.4897533 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.05402492e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.72304808  8.40289757]]\n",
      "\n",
      " [[ 5.87940158  8.32987276]\n",
      "  [ 7.17338371 10.63554998]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.12145791e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 5.81367702 11.05643306]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.75253273  9.98054605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.79917049 11.46433423]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.97753485e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.72304808  8.40289757]]\n",
      "\n",
      " [[ 5.87940158  8.32987276]\n",
      "  [ 7.45604534 10.57199498]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.55210123e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.72304808  8.40289757]]\n",
      "\n",
      " [[ 5.87940158  8.32987276]\n",
      "  [ 7.05349348 10.70857072]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [4.0340488e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 5.7265067  11.11395022]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.02398288e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.69593456 10.07600672]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.79917049 11.46433423]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.02398288e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.69593456 10.07600672]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.72098264 11.5155954 ]\n",
      "  [ 7.7017147   8.54320414]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.72304808  8.40289757]]\n",
      "\n",
      " [[ 5.87940158  8.32987276]\n",
      "  [ 6.81734942 10.79986545]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 5.65164641 11.16321327]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 3.96972915e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 5.69593456 10.07600672]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.72098264 11.5155954 ]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[1.00000000e+00 1.11022302e-16]\n",
      " [2.35406217e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "QTable: [[[5.62518751 4.5740535 ]\n",
      "  [3.39256112 4.71214127]]\n",
      "\n",
      " [[7.28060313 8.37369694]\n",
      "  [4.31398537 5.01501178]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.73048643e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.58846381  8.52139496]]\n",
      "\n",
      " [[ 5.87940158  8.32987276]\n",
      "  [ 6.81734942 10.79986545]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.58846381  8.52139496]]\n",
      "\n",
      " [[ 5.87940158  8.32987276]\n",
      "  [ 6.66933327 10.86521803]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [7.84323496e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 9.17791777  8.25189163]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 5.61421626 11.1878448 ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.69593456 10.07600672]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.52822463 11.60388491]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [4.6277796e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.58846381  8.52139496]]\n",
      "\n",
      " [[ 5.87940158  8.32987276]\n",
      "  [ 6.58035314 10.90774694]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[ 8.22110014  8.98904459]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 5.61421626 11.1878448 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.58846381  8.52139496]]\n",
      "\n",
      " [[ 5.87940158  8.32987276]\n",
      "  [ 6.92231783 10.81697224]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.58846381  8.52139496]]\n",
      "\n",
      " [[ 5.87940158  8.32987276]\n",
      "  [ 7.23008604 10.73527502]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000e+00 1.00000e+00]\n",
      " [5.01688e-17 1.00000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.58846381  8.52139496]]\n",
      "\n",
      " [[ 5.87940158  8.32987276]\n",
      "  [ 7.50707744 10.66174752]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.04181628e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.58846381  8.52139496]]\n",
      "\n",
      " [[ 5.87940158  8.32987276]\n",
      "  [ 7.75636969 10.59557276]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.38206264e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.58846381  8.52139496]]\n",
      "\n",
      " [[ 5.87940158  8.32987276]\n",
      "  [ 7.12387135 10.7729243 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [3.8956451e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 8.22110014  8.98904459]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.15665667 10.90309212]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.94317875e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.58846381  8.52139496]]\n",
      "\n",
      " [[ 5.87940158  8.32987276]\n",
      "  [ 7.02459834 10.747699  ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.27203874e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 8.22110014  8.98904459]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.38816767 10.75062566]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.74858852e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.58846381  8.52139496]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.02459834 10.747699  ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.58846381  8.52139496]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.06756624 10.67409976]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.43268177e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 8.22110014  8.98904459]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.52111033 10.64495273]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.58846381  8.52139496]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.36080962 10.60668979]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.58846381  8.52139496]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.28884894 10.56132599]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.04985855e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 8.22110014  8.98904459]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.03892899 10.35287906]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.69593456 10.07600672]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.67965189 11.52647285]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.58846381  8.52139496]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.55996405 10.50519339]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.24577884e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.58846381  8.52139496]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.80396764 10.45467405]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.41509035e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.80396764 10.45467405]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.41509035e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 8.02357088 10.40920664]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.11349414e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 8.22121379 10.36828598]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.70461303e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.52617849 10.32529461]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.19034876e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 8.22110014  8.98904459]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.52993589 10.30655737]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.04446708e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.77356064 10.29276515]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.07879825e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.99620458 10.26348864]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.1096963e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 8.19658412 10.23713977]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.71026642 10.24119284]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 8.22110014  8.98904459]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.84907451 10.24975582]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.93923977 10.21707355]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.50895425e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 8.1453158  10.1953662 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.13038964e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.8122877  10.19758543]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.75250014e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 8.22110014  8.98904459]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 6.20291108 10.1552806 ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 3.95234856e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.67965189 11.52647285]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 7.88210037e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.96474103 11.3422706 ]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.42086355e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 8.03105893 10.17782688]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.57266659e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 8.22795304 10.1600442 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 8.40515774 10.14403978]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.83224978e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.6837433  10.13413213]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.30413419e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 8.22110014  8.98904459]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.54011275  8.19924143]\n",
      "  [ 5.98735195 10.61454854]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.13887051e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.05586783 11.22478815]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.91536897 10.12071891]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.09847811e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 8.12383207 10.10864702]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.63704088e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 8.31144887 10.09778232]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.15344524e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 8.48030398 10.08800409]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.88439296e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 8.63227358 10.07920368]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.71107757 10.28542125]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.15455999e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 8.22110014  8.98904459]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 5.98735195 10.61454854]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 5.98735195 10.61454854]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.11236494 11.22656258]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.35063491e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.25047957 10.38853004]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.15455999e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 5.93862195 10.7978993 ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.24130519e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.9563743  11.26869331]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.52543161 10.34967704]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.13816459 10.49399824]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.12074677e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.32457681 10.59654895]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.95309667e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.09891302 10.4856187 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.50185361 10.49252195]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.92586043e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.38902172 10.43705683]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.2952523  10.41553719]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.51156724e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.13347653 10.7537383 ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 8.26612986e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.89628807 11.30056153]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.06209817e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.56572707 10.37398348]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.04995555e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.23625415 10.48848706]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 5.92525349 10.89709376]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.09137173e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.84264569 11.34567559]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.74954013  8.46401598]\n",
      "  [ 7.51262873 10.43963835]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.24487146  8.59084549]\n",
      "  [ 7.51262873 10.43963835]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [8.22294107e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.46767824 10.62440222]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.21293337e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.24487146  8.59084549]\n",
      "  [ 7.34338566 10.46958006]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.48785331e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.0708974  10.85047135]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.05414986e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.85867711 11.36066982]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.0954974e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.24487146  8.59084549]\n",
      "  [ 7.10005179 10.57497857]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.37546941 10.6552271 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.85330122e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.24487146  8.59084549]\n",
      "  [ 7.39004661 10.51748071]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.24487146  8.59084549]\n",
      "  [ 7.65104195 10.46573264]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.06179537e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.24487146  8.59084549]\n",
      "  [ 7.88593775 10.41915938]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.47196854e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.24487146  8.59084549]\n",
      "  [ 8.09734398 10.37724344]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.24487146  8.59084549]\n",
      "  [ 8.28760958 10.3395191 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.24487146  8.59084549]\n",
      "  [ 8.45884862 10.30556719]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.86950531e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.24487146  8.59084549]\n",
      "  [ 8.61296376 10.27501047]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.97644417e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.24487146  8.59084549]\n",
      "  [ 8.75166738 10.24750942]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.24487146  8.59084549]\n",
      "  [ 7.92602146 10.38584555]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.42387059e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.85814329 10.48195177]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.4997822e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.36569305  8.48820346]\n",
      "  [ 7.92602146 10.38584555]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.75879287e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 7.09948023 10.39531411]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.36569305  8.48820346]\n",
      "  [ 8.13341931 10.347261  ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91581896  8.4425671 ]]\n",
      "\n",
      " [[ 5.36569305  8.48820346]\n",
      "  [ 7.90650175 10.33175614]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.92625401e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 7.21234081 10.33035951]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.09724754e-16 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.84284581  8.35342735]]\n",
      "\n",
      " [[ 5.36569305  8.48820346]\n",
      "  [ 7.90650175 10.33175614]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.44964125 10.70944768]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.09193925 11.31303737]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.48623768e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.84284581  8.35342735]]\n",
      "\n",
      " [[ 5.36569305  8.48820346]\n",
      "  [ 8.11585157 10.29858053]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.6315033e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.84284581  8.35342735]]\n",
      "\n",
      " [[ 5.36569305  8.48820346]\n",
      "  [ 8.30426642 10.26872247]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.84284581  8.35342735]]\n",
      "\n",
      " [[ 5.36569305  8.48820346]\n",
      "  [ 7.73198971 10.41814031]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.47533764e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.16159633 10.87993879]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.13876551 11.32377481]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.36514563e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.84284581  8.35342735]]\n",
      "\n",
      " [[ 5.36569305  8.48820346]\n",
      "  [ 7.33063338 10.56104567]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.51305152 10.66438766]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.84284581  8.35342735]]\n",
      "\n",
      " [[ 5.36569305  8.48820346]\n",
      "  [ 7.2705373  10.5462779 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.51933735e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.21203196 10.86170375]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.97759768 11.38039856]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.04494869e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.84284581  8.35342735]]\n",
      "\n",
      " [[ 5.36569305  8.48820346]\n",
      "  [ 7.12008143 10.61782045]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.45404856 10.67798006]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.94054897e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.84284581  8.35342735]]\n",
      "\n",
      " [[ 5.36569305  8.48820346]\n",
      "  [ 7.40807329 10.55603841]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.50304233  8.4479057 ]]\n",
      "\n",
      " [[ 5.36569305  8.48820346]\n",
      "  [ 7.40807329 10.55603841]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.11806335 10.89114945]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.95202815 11.41261464]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.50304233  8.4479057 ]]\n",
      "\n",
      " [[ 5.36569305  8.48820346]\n",
      "  [ 7.66726596 10.50043457]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.50304233  8.4479057 ]]\n",
      "\n",
      " [[ 5.74975291  8.44427555]\n",
      "  [ 7.66726596 10.50043457]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.3202345e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.50304233  8.4479057 ]]\n",
      "\n",
      " [[ 5.74975291  8.44427555]\n",
      "  [ 7.90053937 10.45039111]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91173691  8.40410929]]\n",
      "\n",
      " [[ 5.74975291  8.44427555]\n",
      "  [ 7.90053937 10.45039111]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.48210044e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91173691  8.40410929]]\n",
      "\n",
      " [[ 5.74975291  8.44427555]\n",
      "  [ 7.39749502 10.58165534]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.24525925e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 5.93984294 11.01062058]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.13004919e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.93501209 11.43896946]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.13304331e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91173691  8.40410929]]\n",
      "\n",
      " [[ 5.74975291  8.44427555]\n",
      "  [ 7.07468469 10.6950759 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.12159399e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 5.8439263  11.08089807]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.79737992 11.49751509]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.90904864e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91173691  8.40410929]]\n",
      "\n",
      " [[ 5.74975291  8.44427555]\n",
      "  [ 7.36721622 10.62556831]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91173691  8.40410929]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.36721622 10.62556831]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.11203317e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91173691  8.40410929]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.02117863 10.74514339]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 5.74091512 11.13945507]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 8.04548083e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.70716141 11.5468149 ]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.74384272e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91173691  8.40410929]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.31906077 10.67062905]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.07861861e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91173691  8.40410929]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.58715469 10.60356614]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.26464614e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.91173691  8.40410929]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.08994339 10.7575651 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [7.96712018e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.20643492 10.87275358]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.43844242  8.55115608]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.08994339 10.7575651 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.30657934e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.43919481 10.73940283]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.43844242  8.55115608]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.38094905 10.68180859]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.53646867e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.43844242  8.55115608]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.64285415 10.61362773]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.30329541e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.43844242  8.55115608]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.397105   10.602575  ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [8.93617793e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.67843941 10.61073141]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.13277268e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.67806321  8.51660804]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.397105   10.602575  ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.13277268e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.67806321  8.51660804]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.6573945  10.5423175 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.06267696e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.67806321  8.51660804]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.50007301 10.51545131]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.63409825e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.40238478  8.29135682]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.12208427 10.92409167]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.85360991 11.47958797]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.04084422e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.67806321  8.51660804]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.75006571 10.46390618]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.37768837e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.67806321  8.51660804]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.32386656 10.60158976]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.24804932e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.12208427 10.92409167]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.49058876 10.70268174]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.76857823  8.49893992]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.32386656 10.60158976]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.32386656 10.60158976]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.0819533e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.59147991 10.54143078]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.05352947e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.39197546 10.55178809]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.50375068e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 6.08673834 10.94317606]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.06175781e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.88359514 11.46050922]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.12921334e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.13068307 10.65316447]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 5.89680723 11.05579172]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.08256424e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.7940708  11.4915204 ]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.41761476 10.58784802]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.67585328 10.52906322]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.32619316e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.90826796 10.4761569 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.09749265e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.31285687 10.66039513]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 5.16499715  8.34544013]\n",
      "  [ 5.76603193 11.12450402]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.02044425e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.6263411   9.56840605]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.82217814 11.50991825]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 6.96284121 10.77999917]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.00098838e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 4.88891135  8.62252167]\n",
      "  [ 5.76603193 11.12450402]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [8.00197676e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 5.76603193 11.12450402]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.16815245 10.87425168]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.83144164e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 6.94868158 10.73970026]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.28001554e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 5.91294748 11.04109314]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.03994764e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.64204181  9.88817032]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.82217814 11.50991825]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.64204181  9.88817032]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.69056171 11.55083923]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.82161643e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.25381342 10.66573023]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.03334418e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 6.99208571 10.74930237]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 5.73269842 11.14088226]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 3.94862039e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.64204181  9.88817032]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.64211513 11.57514056]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.85173409e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.29287713 10.67437214]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.01209001e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.56358942 10.60693492]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.24829445e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 7.80723048 10.54624143]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.4173544e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 5.82176294  8.4723651 ]\n",
      "  [ 8.02650743 10.49161729]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.56950835e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 6.12148444  8.43282947]\n",
      "  [ 8.02650743 10.49161729]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.56950835e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 6.12148444  8.43282947]\n",
      "  [ 7.30633308 10.70216155]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [3.97785861e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 5.62319527 11.20049736]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 3.91500383e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.64204181  9.88817032]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.7435908  11.5684349 ]\n",
      "  [ 6.2078818   7.15645858]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.06978701e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 6.12148444  8.43282947]\n",
      "  [ 7.57569978 10.63194539]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 6.12148444  8.43282947]\n",
      "  [ 7.03712799 10.79617164]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [3.90187553e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 5.60903395 11.22762264]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 5.64204181  9.88817032]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.7435908  11.5684349 ]\n",
      "  [ 7.01618215  7.92770807]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[5.62518751 4.5740535 ]\n",
      "  [3.39256112 4.71214127]]\n",
      "\n",
      " [[6.45515276 9.00531713]\n",
      "  [4.31398537 5.01501178]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 6.12148444  8.43282947]\n",
      "  [ 7.3334152  10.71655448]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.81383574  8.49010586]]\n",
      "\n",
      " [[ 6.12148444  8.43282947]\n",
      "  [ 7.60007368 10.64489903]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.15053145  8.73610199]]\n",
      "\n",
      " [[ 6.12148444  8.43282947]\n",
      "  [ 7.60007368 10.64489903]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 5.6019533  11.24118528]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.64204181  9.88817032]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.91182487 11.54217706]\n",
      "  [ 7.01618215  7.92770807]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 6.12148444  8.43282947]\n",
      "  [ 7.60007368 10.64489903]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [7.77427192e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.34100612 10.87855225]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.27361049e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 6.12148444  8.43282947]\n",
      "  [ 7.33643929 10.67387041]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.03523301 11.05614695]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 8.20430511e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.64204181  9.88817032]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.89048815 11.5406367 ]\n",
      "  [ 7.01618215  7.92770807]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.09067738e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 6.12148444  8.43282947]\n",
      "  [ 7.08231285 10.75939399]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.35054164 10.83183107]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.91434174e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 6.12148444  8.43282947]\n",
      "  [ 7.08137308 10.71242942]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.50782005 10.7008873 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.91368965e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 6.12148444  8.43282947]\n",
      "  [ 7.37323577 10.64118648]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 6.12148444  8.43282947]\n",
      "  [ 7.28974591 10.60094816]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.66980839 10.59082292]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.01165547e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.97664058  8.456794  ]\n",
      "  [ 7.28974591 10.60094816]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.05827734e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.28974591 10.60094816]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.05827734e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.31279631 10.53680325]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.62810928e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.76002272 10.51013276]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.07427177e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.58151668 10.48312292]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0521468e-16 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.49476743 10.44561456]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.69070804e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.1500261   8.51531508]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.23620662 10.87132106]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.08734723e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 5.64204181  9.88817032]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.89048815 11.5406367 ]\n",
      "  [ 7.09015218  8.56598088]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[5.62518751 4.5740535 ]\n",
      "  [3.39256112 4.71214127]]\n",
      "\n",
      " [[6.22548335 9.18090439]\n",
      "  [4.31398537 5.01501178]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.2005396e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.74529068 10.40105311]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.37437503e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.36712799 10.54905498]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.32723761e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.0694957   8.60618596]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.23620662 10.87132106]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.32723761e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.0694957   8.60618596]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 5.97429857 11.05191521]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.08734723e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.64204181  9.88817032]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.89209527 11.48994034]\n",
      "  [ 7.09015218  8.56598088]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.11197195e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.63041519 10.49414948]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.20492702 10.66784082]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [8.29100478e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.0694957   8.60618596]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.36912009 10.79309393]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [9.99884484e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.48443432 10.60105674]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.19336957e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.2898652  10.61776594]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.0694957   8.60618596]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.04139816 10.9925231 ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.0884624e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.64204181  9.88817032]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.86199371 11.49207655]\n",
      "  [ 7.09015218  8.56598088]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.05836012e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.56087868 10.55598935]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.80479081 10.50039041]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 8.02431173 10.45035137]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.56798477e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 8.22188056 10.40531624]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.70507569e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 8.3996925  10.36478461]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.82845751e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 8.55972325 10.32830615]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 4.81604704  8.86452511]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.69642089 10.56116232]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.19206208e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.0694957   8.60618596]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 5.86549656 11.09309217]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.06757525e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.64204181  9.88817032]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.00956521 11.4705032 ]\n",
      "  [ 7.09015218  8.56598088]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [5.3404648e-17 1.0000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.48659188  8.65672748]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.69642089 10.56116232]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.06809296e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.48659188  8.65672748]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.9267788  10.50504608]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.48659188  8.65672748]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 8.13410092 10.45454148]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 8.13410092 10.45454148]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.64416633e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.41324908 10.66450761]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.0694957   8.60618596]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.39804792 10.81234913]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.14397489e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.26584371 10.65719345]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.43953757e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.0694957   8.60618596]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.60536144 10.66905195]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.27506643 10.5962175 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.58339022e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.0694957   8.60618596]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.71270729 10.57301297]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.04809141e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.54755979 10.53659575]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.23717166e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 7.79280381 10.48293618]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.40734388e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.90421865  8.46877626]\n",
      "  [ 8.01352343 10.43464256]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.56049889e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.63719224  8.46359332]\n",
      "  [ 8.01352343 10.43464256]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.0694957   8.60618596]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.26017973 10.87470777]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.64204181  9.88817032]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.21019198 11.40910862]\n",
      "  [ 7.09015218  8.56598088]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.56049889e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.63719224  8.46359332]\n",
      "  [ 7.51083361 10.56720439]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.0694957   8.60618596]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.11416666 11.00099733]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.64204181  9.88817032]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 6.10942943 11.43143607]\n",
      "  [ 7.09015218  8.56598088]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.21168775e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.63719224  8.46359332]\n",
      "  [ 7.75975025 10.51048395]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.63719224  8.46359332]\n",
      "  [ 7.32554179 10.65564091]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.0694957   8.60618596]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 6.0008551  11.07307309]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.64204181  9.88817032]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.98493143 11.4779744 ]\n",
      "  [ 7.09015218  8.56598088]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [5.08311572e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.63719224  8.46359332]\n",
      "  [ 7.06311293 10.75704969]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.0694957   8.60618596]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 5.89440012 11.12772631]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.15288042e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.64204181  9.88817032]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.81771089 11.54180707]\n",
      "  [ 7.09015218  8.56598088]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.90101913e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.63719224  8.46359332]\n",
      "  [ 6.88931652 10.82961537]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 5.0694957   8.60618596]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 5.77428442 11.18058598]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.03684786e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.64810526 10.06080799]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.81771089 11.54180707]\n",
      "  [ 7.09015218  8.56598088]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 8.07369572e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.64810526 10.06080799]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.66458205 11.60274968]\n",
      "  [ 7.09015218  8.56598088]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.78042364e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.63719224  8.46359332]\n",
      "  [ 7.20038486 10.74665383]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.99627066e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.63719224  8.46359332]\n",
      "  [ 6.9099062  10.84556131]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.00671469e-17 1.00000000e+00]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 4.84446161  8.77532737]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 5.77428442 11.18058598]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.00671469e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 4.84446161  8.77532737]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 5.65297503 11.23139287]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 3.93059339e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.64810526 10.06080799]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.5962535  11.63959937]\n",
      "  [ 7.09015218  8.56598088]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [4.7947106e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.63719224  8.46359332]\n",
      "  [ 6.71614311 10.9153378 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0.0000000e+00 1.0000000e+00]\n",
      " [3.9225394e-17 1.0000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 4.84446161  8.77532737]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 5.58572962 10.64001963]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.58329473  9.55472719]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.5962535  11.63959937]\n",
      "  [ 7.09015218  8.56598088]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 3.88318093e-17]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "QTable: [[[ 5.58329473  9.55472719]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.484584   11.6859348 ]\n",
      "  [ 7.09015218  8.56598088]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [4.66026045e-17 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[ 6.6259207   6.95187819]\n",
      "  [ 5.99693631  8.51018033]]\n",
      "\n",
      " [[ 5.63719224  8.46359332]\n",
      "  [ 6.5923634  10.71367675]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "QTable: [[[ 7.5328972   9.48443755]\n",
      "  [ 4.84446161  8.77532737]]\n",
      "\n",
      " [[ 4.75086845  8.76106244]\n",
      "  [ 5.5261827  10.14190069]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.52496526  9.09925447]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.484584   11.6859348 ]\n",
      "  [ 7.09015218  8.56598088]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[ 5.47246873  8.68932903]\n",
      "  [ 8.27683797  6.32646127]]\n",
      "\n",
      " [[ 5.484584   11.6859348 ]\n",
      "  [ 7.09015218  8.56598088]]]\n",
      "Expected reward: [1.5166 1.7052]\n",
      "QTable: [[[[ 7.5328972   9.48443755]\n",
      "   [ 4.84446161  8.77532737]]\n",
      "\n",
      "  [[ 4.75086845  8.76106244]\n",
      "   [ 5.5261827  10.14190069]]]\n",
      "\n",
      "\n",
      " [[[ 5.47246873  8.68932903]\n",
      "   [ 8.27683797  6.32646127]]\n",
      "\n",
      "  [[ 5.484584   11.6859348 ]\n",
      "   [ 7.09015218  8.56598088]]]\n",
      "\n",
      "\n",
      " [[[ 5.62518751  4.5740535 ]\n",
      "   [ 3.39256112  4.71214127]]\n",
      "\n",
      "  [[ 6.22548335  9.18090439]\n",
      "   [ 4.31398537  5.01501178]]]\n",
      "\n",
      "\n",
      " [[[ 6.6259207   6.95187819]\n",
      "   [ 5.99693631  8.51018033]]\n",
      "\n",
      "  [[ 5.63719224  8.46359332]\n",
      "   [ 6.5923634  10.71367675]]]]\n"
     ]
    }
   ],
   "source": [
    "#Simulate plays with nash policy\n",
    "ALPHA = 0.5\n",
    "GAMMA = 0.8\n",
    "EPSILON = 0.1\n",
    "n_games = 5000\n",
    "\n",
    "qTable = np.zeros((Q, A, A, N))\n",
    "\n",
    "state = 0\n",
    "totalReward = np.array([0, 0])\n",
    "diffs = []\n",
    "expectedRewards = []\n",
    "\n",
    "for _ in range(n_games):\n",
    "    print(\"State:\", state)\n",
    "    nashEq = np.abs(computeNashEq(state, qTable))\n",
    "    print(\"Nash equilibrium:\", nashEq)\n",
    "    player1_action = np.random.choice(A, p=nashEq[0]) if np.random.rand() > EPSILON else np.random.choice(A)\n",
    "    player2_action = np.random.choice(A, p=nashEq[1]) if np.random.rand() > EPSILON else np.random.choice(A)\n",
    "    print(\"Player 1 action:\", player1_action)\n",
    "    print(\"Player 2 action:\", player2_action)\n",
    "    next_state = np.random.choice(range(Q), p=TRANSITION_MATRIX[player1_action, player2_action, state])\n",
    "    print(\"Next state:\", next_state)\n",
    "    r = reward(state, player1_action, player2_action)\n",
    "    print(\"Reward:\", r)\n",
    "\n",
    "    next_NashEq = computeNashEq(next_state, qTable)\n",
    "    next_qVal_0 = expectedPayoff(qTable[next_state, :, :, 0], next_NashEq[0], next_NashEq[1])\n",
    "    next_qVal_1 = expectedPayoff(qTable[next_state, :, :, 1], next_NashEq[0], next_NashEq[1])\n",
    "\n",
    "    oldQ = qTable[state, player1_action, player2_action].copy()\n",
    "\n",
    "    qTable[state, player1_action, player2_action, 0] = (1 - ALPHA) * qTable[state, player1_action, player2_action, 0] + ALPHA * (r[0] + GAMMA * next_qVal_0)\n",
    "    qTable[state, player1_action, player2_action, 1] = (1 - ALPHA) * qTable[state, player1_action, player2_action, 1] + ALPHA * (r[1] + GAMMA * next_qVal_1)\n",
    "    \n",
    "    diffs.append(qTable[state, player1_action, player2_action] - oldQ)\n",
    "\n",
    "    print(\"QTable:\", qTable[state])\n",
    "    state = next_state\n",
    "    totalReward += r\n",
    "    expectedRewards.append(totalReward / (_ + 1))\n",
    "print(\"Expected reward:\", totalReward/n_games)\n",
    "print(\"QTable:\", qTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "diffs = np.array(diffs)\n",
    "print(diffs.shape)\n",
    "diffs\n",
    "\n",
    "expectedRewards = np.array(expectedRewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzkAAAHECAYAAAAageT3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAACJo0lEQVR4nO3dd3gUVdsG8Ht30xMSQoDQWwKhk9B7E7EhKvbeUUF5FRt2ff1QX0VEpAh2xYINRFFULKDSu/QWQk2BNNKT3fn+CLvZMrs7szu7M7O5f9flZdgyc3b27Mx55pzzHIMgCAKIiIiIiIhChFHtAhARERERESmJQQ4REREREYUUBjlERERERBRSGOQQEREREVFIYZBDREREREQhhUEOERERERGFFAY5REREREQUUhjkEBERERFRSGGQQ0RE9RLXwiYiCl0McoioXtq8eTMefPBBjBgxAj179sR5552HZ555BocOHXJ43bRp05CWlubxv5tvvtnr/r799lukpaXh+PHjbl+zfv16pKWlYf369X5/PmfHjx9HWloavv32W7f7eu2119C/f3+kp6dj6dKlWLduHS644AJ0794dd911l+JlUkt2djYmTpyIEydO2B4bPXo0pk2bpmKpPHP+/vTgk08+wejRo9UuBhHVU2FqF4CIKNgWLFiAN954A0OHDsVjjz2GJk2aICsrC59//jmuuOIKvPzyy7jkkksAAJMmTcJ1111ne++8efOwe/duzJkzx/ZYXFxc0D+Dv7p164bFixcjNTUVALB//368++67uOaaa3DZZZehQ4cOuOuuu2CxWLBw4UIkJSWpXGLlrFmzBqtWrXJ4bM6cObr8HrVq+fLleOWVV5CcnKx2UYionmKQQ0T1yqpVqzBz5kxMmjQJ//nPf2yP9+/fH5dffjkefvhhTJs2DZ06dULHjh3Rpk0btGnTxva6Ro0aISIiAunp6SqUXjlxcXEOn6GwsBAAcMkll6Bv3762x/r164fBgwerUMLg6tq1q9pFCAlnzpzBm2++icWLF6Nhw4ZqF4eI6jEOVyOiemX+/Pno0KEDpkyZ4vJceHg4/vvf/8JkMuGdd96Rtd2vvvoKEyZMQHp6Onr27InLLrsMP/30k8vrtmzZgssvvxzdu3fHuHHj8OOPP3rc7v79+3HPPfegd+/e6N27NyZPnoxjx455Lc8vv/yC8ePHo2fPnrjiiiuwd+9eh+fth6u99dZbtiF3t956K0aPHo20tDScOHECS5cutb2uoqICzz//PIYPH47u3bvjwgsvxHvvvee1LP/88w9uuOEG9OnTBwMGDMDDDz+MU6dOAagdOtalSxcsWrTI4T35+fno1q0bPvzwQwCw9Sidf/756N69Oy644AJ88sknDu+5+eab8cgjj2DKlClIT0/H7bff7lKWb7/9Fk888QQA4LzzzrMNUbMfrmYdGrZixQpMmjQJ6enpGDx4MObNm4eSkhI8+eST6NOnDwYPHozXXnvNYW5PZWUlXn31VYwYMQLdu3fHpZde6vU7tn4Xf//9N2688Ub07NkTY8eOxWeffebxfRs3bsSdd96Jfv36oXv37hg9ejTeeustWCwWAMCVV17p0Atpddtttzkcm5UrV2LChAno0aMHhgwZgv/7v/9DWVmZ7fm33noL559/PubMmYP+/ftj6NChKCoqEi3T22+/jb///htvvfUWRo0a5bH8RESBxCCHiOqNgoICbN26Feeddx4MBoPoaxo2bIjBgwfjt99+k7zdTz/9FM8++yzGjBmDBQsWYMaMGYiIiMAjjzyC7Oxsh9c+++yzuOiiizBv3jx07NgRDz30EFauXCm63czMTFx33XU4c+YM/ve//2H69Ok4duwYrr/+epw5c8ZteX7//XdMmTIFaWlpmDt3Li666CI8+uijbl9/9dVX49lnn7WV74033sDixYvRpEkTjBgxAosXL0a3bt3w0ksvYfXq1Xj88cfx3nvv4bzzzsOrr76Kb775xu22ly5dijvuuAPNmzfHzJkz8cQTT2Dr1q249tprcebMGTRr1gz9+/fH8uXLHd63YsUKCIJgGzb4/PPPY/bs2Rg/fjzefvttXHjhhXjppZcwd+5ch/f99NNPiI2Nxfz580XnEY0cORL33XcfgNohapMmTXJb9qeffhqdOnXC/PnzMWjQILz55pu46qqrEBUVhTlz5mDs2LF49913sWLFCgC1iQwmT56ML774Arfffjvmz5+PjIwMPPTQQ1i6dKnb/Vg99NBD6Nq1K+bOnYvBgwfjhRdecBvo7N27F7fddhsaNmyIN954A/Pnz0ffvn0xZ84cW3B91VVXYevWrcjKyrK979SpU1i/fj0mTJgAAPj+++8xefJkdOjQAXPnzsX999+PZcuWYdKkSQ7B28mTJ7Fq1Sq88cYbeOKJJ5CQkCBaruuuuw4///wzxo4d6/XzEhEFEoerEVG9cfLkSQBAy5YtPb6ubdu2+O2331BYWChpyM2xY8dw5513OjSYW7ZsiQkTJmDz5s22hjoAPPDAA7jzzjsBAMOHD8eRI0cwb948jBkzxmW7c+bMQXR0ND788EPbfJFBgwZhzJgxePfdd/H444+Llmfu3Lno2bMnXnvtNQDAsGHDAACvv/666OubNWtmm5uTmpqKXr16AQAiIiLQqFEj27C2DRs2YMiQIbbPM2DAAMTExLidr2OxWDBjxgwMHTrUYd+9e/fGxRdfjPfeew+PPfYYLrvsMjz55JM4efIkWrRoAaB2TsfgwYPRpEkTZGZm4ssvv8TUqVMxceJEAMDQoUNhMBiwYMEC3HDDDUhMTARQ2xv3wgsvICIiQrRMjRo1sg0/7NKlC1q1aiX6Outxe/DBBwEAHTt2xA8//ICkpCRbQDhw4EB8//332LJlCy666CKsWbMGf/31F9544w1cfPHFtm2Ul5djxowZGDduHMLC3F92zz//fDz11FO29+Xm5mLevHm4/vrrXV67d+9eW0+S0Vh7v3LIkCH4/fffsX79elxyySUYN24cXnnlFXz33Xe2nsvvvvsOsbGxOP/88yEIAmbMmIFhw4ZhxowZtm23a9cOt912G1atWoWRI0cCAGpqavD444/bhjK6k5KS4vF5IqJgYU8OEZETay+PddiPN9OmTcMjjzyC4uJibNu2Dd999x0+/fRTAEBVVZXDa62NX6sxY8Zg9+7dKC0tddnuunXr0L9/f0RFRaGmpgY1NTWIi4tD3759sWbNGtGyVFRUYNeuXS5DhS666CJJn8WTAQMG4Msvv8Tdd9+NRYsW4dixY5g8ebKtIewsMzMTeXl5GDdunMPjbdq0QUZGBjZs2AAAGDt2LCIjI23Duk6dOoXNmzfjsssuA1B7HARBwOjRo23HoaamBqNHj0ZlZSU2b95s23aHDh3cBjhyZWRk2P5u3LgxAKBnz562xwwGAxISEnD27FkAwNq1a2EwGDBixAiXcubl5eHAgQMe93fFFVc4/Hvs2LHIy8tDZmamy2svv/xyvPPOO6iursbevXvx888/Y/bs2TCbzaiurgYANGjQAGPHjsWyZcts71uyZAkuvvhiREVF4fDhw8jOznY5rv369UNcXBz++ecfh3126dJFymEjItIE9uQQUb3RvHlzAPCYxtn6fExMjOSJ00ePHsWzzz6LtWvXIjw8HB06dEDnzp0BuK7FYm0sWyUlJUEQBJSUlLhst7CwED/++KPonI5GjRqJlqWoqAiCINh6NqyaNm0q6bN48tRTT6FZs2ZYtmwZXnzxRbz44ovIyMjA888/b/u8zuUHXD+z9bHdu3cDqE2CMGbMGCxfvhx33XUXfvzxR0RHR9t6t+yTIojJycmx/R0bG+vPR3Qglm0tJibG7esLCwshCAJ69+4t+nxubq7HQME5E5m1h6yoqAhNmjRxeK6iogIvvvgivvvuO9TU1KBVq1bIyMhAWFiYQ5276qqrsGzZMmzatAkmkwlHjhzB//73P1t5AeCFF17ACy+8IFpee0oeWyKiQGOQQ0T1RqNGjZCRkYGVK1fi4Ycftg3zKSoqQnFxMVq3bo2zZ89izZo1GDp0qO15TywWCyZOnIjw8HB8/fXX6NKlC8LCwnDw4EF89913Lq8vKipyaPSfPn0aJpNJdI5DgwYNMHjwYNEJ9O6GPTVs2BBGoxGnT592eNzaoPVHREQE7rvvPtx33304efIk/vjjD8ybNw8PP/ywy5waa1kAuJQFAPLy8hwCsfHjx2PixInIysrC8uXLccEFFyA6OhoAEB8fDwD46KOPRBva1iFuamvQoAFiYmLw8ccfiz7ftm1bj+8vKChwyORnnXclNhxw+vTp+PnnnzFr1iwMHjzYFnwNGjTI4XX9+/dHmzZtsGLFChiNRnTo0ME2/NB6XB977DH079/fZR/u5t0QEekBh6sRUb1y//33IysrC2+++abtsb///htjx47FtGnT8Oyzz6K8vBz33nuvpO0VFBQgMzMTV111FXr06GELPlavXg3Adcjbn3/+afvbYrFgxYoV6NWrF6Kioly23b9/fxw8eBBdunRBjx490KNHD3Tv3h0ffvghfv31V9HyREZGIiMjA7/88ovDHf3ff/9d0udxp6KiAhdccAHef/99ALWBxY033ohLLrnENtfJWfv27dGkSRP88MMPDo8fO3YM27Ztc+jxGDp0KBo3boyPP/4Yu3btsg1VA2CbB1JQUGA7Dj169EB+fj7efPNN2QGclODVF/3790dZWRkEQXAo5/79+zF37lzU1NR4fL9zAooVK1agZcuWDoGP1ebNmzFgwACMGTPGFuDs3LkT+fn5DnXOYDBgwoQJWLlyJX7//XeHIXEdOnRAUlISjh8/7lDe5ORkvP7667aeNiIiPWJPDhHVK0OHDsXjjz+OV199Fbt378YVV1yB5ORk3HLLLbZ0xRMmTEC3bt0kbS8pKQktW7bEp59+imbNmiE+Ph5//fWX7W5+eXm5w+tnzZoFs9mM5s2b4/PPP0dmZiY++OAD0W1bFyK95557cP311yMyMhKLFy/GypUrMXv2bLdlmjp1Km699Vbcf//9uPbaa5GZmYm3335b0udxJyoqCt26dcOcOXMQHh6OtLQ0ZGZmYsmSJbjgggtE32M0GjF16lQ88cQTePjhhzF+/HgUFBRgzpw5SEhIcOihMplMuOSSS7Bo0SIkJydjwIABtufS0tIwfvx4PPPMMzhx4gS6d++OzMxMvPHGG2jVqhXatWsn67NYezB+/fVXDB8+XLHJ8iNGjEC/fv0wadIkTJo0CSkpKdixYwdmz56NYcOGuR1iaPXBBx8gMjIS6enp+OWXX/DHH3+4TRbRs2dP/PTTT/j888+RkpKCvXv3Yv78+TAYDC51bsKECXjrrbcAwCF4NJlMeOihh/Dss8/CZDJh1KhRKC4uxrx585CTkyP5N0BEpEUMcoio3rn99tuRnp6Ojz76CK+88goKCgrQuHFjXH755WjdujXeffddnDx5EtOnT/eYfctq3rx5mD59OqZNm4aIiAikpqZi/vz5eOmll7Bp0ybbGjQA8PLLL+OVV15BVlYWOnXqhHfeeUd0qBAAdO7cGZ9++ineeOMNPPbYYxAEAZ06dcLcuXNx3nnnuS1P37598c4772DmzJm4//770apVK7z00kuSe6fc+e9//4tZs2bh/fffR15eHpKSknDVVVc5LKrqbMKECYiNjcWCBQswefJkxMXFYdiwYZg6darLPJPLLrsMH330EcaNG+fS2/Lyyy9jwYIF+OKLL5CdnY2kpCRcfPHFePDBB2EymWR9jgEDBmDw4MF4/fXXsXbtWixcuFDW+90xGo1YuHAh3nzzTSxYsABnzpxBcnIybr/9dkyePNnr+5988kksWbIECxYsQIcOHTB79my3AeS0adNQXV2NWbNmoaqqCq1atcJ9992HgwcP4vfff4fZbLYdl+TkZHTu3BmNGzd2mfdz9dVXIzY2Fu+++y4WL16MmJgY9O7dGzNmzEDr1q39PyhERCoxCM6zYomI6rmTJ0/ik08+wf3338/J1hRw69evxy233IKPP/7YoQdLKTk5ORg1ahRmz54tmqqciCgUsSeHiMhJixYt3K5BQ6QXe/bswW+//Yaff/4Z7dq1w+jRo9UuEhFR0DDxABERUQiqrKzEBx98ALPZjJkzZwYs4QIRkRZxuBoREREREYUU3tYhIiIiIqKQEtAgJzMzExkZGfj2228DuRsiIiIiIiKbgAU51dXVeOSRR1BWVhaoXRAREREREbkIWJDz1ltvIS4uLlCbJyIiIiIiEhWQFNIbN27E4sWLsXTpUowcOdLv7QmCAItFG/kRjEaDZspC+sA6Q3KxzpBcrDMkF+sMyaGl+mI0GmAwGLy+TvEgp7i4GI899hiefvppNG/eXJFtWiwCiovLFdmWP0wmI+Ljo1FaWgGz2aJ2cUgHWGdILtYZkot1huRinSE5tFZf4uOjYTKpEOQ8//zzyMjIwKWXXqrYNo1GAxITtbPqeHx8tNpFIJ1hnSG5WGdILtYZkot1huTQW31RNMhZunQpNm3ahO+//17JzZ7ryVE/gYE1ki0uLtdEJEvaxzpDcrHOkFysMyQX6wzJobX6UtuT4z2tgKJBzjfffIMzZ864zMN57rnn8OOPP+Ldd9/1eds1NeofVCuz2aKp8pD2sc6QXKwzJBfrDMnFOkNy6K2+KBrkzJgxAxUVFQ6PjR07FlOmTMH48eOV3BUREREREZEoRYOc5ORk0ceTkpLcPkdERERERKSkgK2TQ0REREREpIaArJNjb9++fYHeBRERERERkQ17coiIiIiIKKQwyCEiIiIiopDCIIeIiIiIiEIKgxwiIiIiIgopDHKIiIiIiCikMMghIiIiIqKQwiCHiIiIiIhCCoMc0rUf1hzBT+uy1C4GEREREWlIwBcDJQqUs2VV+Hb1YQDAqN4tERXB6kxERERE7MkhHasxC7a/LRYVC0JEREREmsIgh4iIiIiIQgqDHCIiIiIiCikMcoiIiIiIKKQwyCEiIiIiopDCIIeIiIiIiEIKgxwiIiIiIgopDHKIiIiIiCikMMghIiIiIqKQwiCHiIiIiIhCCoMcIiIiIiIKKQxydMYiCPh10zFkZZ9VuyhERERERJrEIEdn1vybjc9XHsALH25UuyhERERERJrEIEdnjuWWqF0EzRAEQe0iEBEREZEGMcghIiIiIqKQwiCHdMtgMKhdBCIiIiLSIAY5REREREQUUhjkEBERERFRSGGQQ0REREREIYVBDhERERERhRQGOaRbTCFNRERERGIY5BARERERUUhhkEO6xRTSRERE9Y/ZYlG7CKQDDHKIiIiISBf++fcUJr72J7YdOK12UUjjGOQQERERkS68t3wPBAGY/c0OtYtCGscgh4iIiIiIQgqDHCIiIiIiCikMcki3mEKaiIiIiMQwyCEitywMJImIiEiHGOSQbjGFdGD9uukYJs9cjcxTxWoXhYiIiEgWBjlBcupMKY7nlahdDCLJPl95AJXVZrz/4x61i0JEREQkC4OcIKgxW/DUO+vx7HsbUFllVrs4REREREQhjUFOEFTX1K3MW1pRrWJJiIiIiIhCH4McIiIiIiIKKQxySLeYQpqIiIiIxDDICTK2ywODidaIiIiIyIpBThCwAR54DB6JiIiIyIpBThCwAR4YXCeHiIiIiMQwyCEiIiIiopDCICcI2OFARERERBQ8DHKIiIiIiCikMMghIs84p4yIiIh0hkFOkAlsMSqG6+QQERERkRgGOUTkGeeUERERkc4wyAkyA1uMimEKaSIiIiISE5Ag58yZM3j00UcxcOBAZGRkYOLEiTh06FAgdkVEREREROQgIEHO5MmTkZWVhYULF+Lrr79GVFQUbrvtNpSXlwdid7rCOTlERERERIGleJBTVFSEli1b4v/+7//Qs2dPpKSkYNKkScjNzcWBAweU3p0ucIga6RrjciIiItKZMKU3mJCQgNdff9327/z8fHz44Ydo1qwZUlNTld6dLrD3hoiIiIgoeBQPcuw988wz+PLLLxEREYH58+cjJibG522FhamfI8FkMjr8X6owS93rw0xGvz6L0e6tWjgmajKZ6nrIwsL8O66B4mud0RKDgXUtmEKhzlBwsc6QXKFSZ3htCg691peABjm33norrr32Wnz66aeYPHkyPvvsM3Tr1k32doxGAxITYwNQQt/Ex0fLen1FZY3t74SEGCQm+h7sRUaF2/7W0jFRg9lQ92Nr2DAGsdHhHl6tLrl1RktMJmO9r2tq0HOdIXWwzpBceq8zvDYFl97qS0CDHOvwtOnTp2P79u1YtGgRXn75ZdnbsVgEFBeXKV082UwmI+Ljo1FcXA6z2SL5fZVVZtvfRUVlCDf4PnytsqLa9ndBQanP2wkFRcUVtr8LC8tQVRHQ6uwTX+uMlpjNlnpf14IpFOoMBRfrDMkVKnWG16bg0Fp9iY+PltSrpHirMD8/H2vXrsUFF1yAsLDazRuNRqSmpiI3N9fn7dbUqH9Qrcxmi6zy2L+2RuZ7nVns3qqlY6IGs7kuWKyp8e+4BprcOqMlAljX1KDnOkPqYJ0hufReZ/Rcdj3SW31RfHDd6dOnMXXqVKxdu9b2WHV1NXbv3o2UlBSld6c/zEFAesM6S0RERDqjeJDTqVMnDB8+HP/3f/+HjRs3Yv/+/Zg2bRqKi4tx2223Kb07IiIiIiIiBwFJkzBz5kwMGjQIDz30EK6++moUFhbi008/RYsWLQKxO33hkjmkN6yzREREpDMBmandoEEDPP/883j++ecDsXkiAIAgcBwVEREREbnSV8LrUMB2ORERERFRQDHIoRDB6JGIiIiIajHIId0yGDhZJCgYPxIREZHOMMgJAoGtRCIiIiKioNHeEvEhpLrGgs9/O4C01g3VLgqR79hhRkRERDrDICeAft9yHH9uPYE/t55QuyhERERERPUGh6sFUH5xpdpFCGlMIU1EREREYhjkBBmb5aQ7rLRERESkMwxyKCSwHU5EREREVgxygoxzuJXDFNJEREREJIZBTpCxx4F0h7EkERER6QyDHJ3hmjtERERERJ4xyCEiIiIiopDCIEdnDBw7ZMMU0kHCw0xEREQ6wyCHiIgAABZBQI3ZonYxiIiI/MYgh4iIAACvLNqC/8z+G5VVZrWLQkRE5BcGORQSOHItgDhCst44eKII5ZU1OHC8UO2iEBER+YVBDukW18khIiIiIjEMcoKMHQ5ERERERIHFIIeIPGNkTkRERDrDIId0iymkiYiIiEgMgxwiIiIiIgopDHKIyDPmdyAiIiKdYZBDREREREQhhUEO6RZTSBMRERGRGAY5ROQZ8zsQERGRzjDIISIiIiKikMIgh3SLKaSJiIiISAyDHCLyjFOfiIiISGcY5AQbex+IiIiIiAKKQQ6FBA5dIyIiIiIrBjmkW0whHSSMH4mIiEhnGOQEkMDWIRHpEe8fEBGRzjHIISIiR7w/Q0REOscgJ4AMvB1KoYDVmIiIiHSGQU4AbT94Wu0ihDQmGyAiIiIiMQxyAii3sNzlMX+b5ZznQ0RERETkGYMcIvKMcXX9wyGKRESkcwxygszftgPn+YhjO5yIiIiIrBjkBBkb48rhOjlEAcITFRER6RyDHCLyjLEkERER6QyDHCIiIiIiCikMcki3mEI6SHiY6x/23hERkc4xyCEiIiIiopDCIIeIiByx946IiHSOQQ6FBjbKiIiIiOgcBjlE5BnnZxAREZHOMMjxw9Gcs3jqnXXYvC9P+ptk9DjkF1egsKRSfsGIiIiIiOoxBjl+mLvkX5w6U4a5S/5VfNtV1WY8Mm8Nps75B2aLRfHtE0nGoYD1D3vviIhI5xjk+KGyyiz/TRIbD2fLqm1/V1UzyCEiIiIKVafOlOKzX/ej4CxH8CglTO0C1DsS74ob7IIhrgdDREHFUw4RUVD996NNqKwyIyvnLJ64qY/axQkJ7MnRKINdlGNhg4OIiIgoZFlHBx3JPqtySUIHgxx/GAI3cN3InhzSCs7PICIiIp1hkKNR9j05jHG84yEiUhADWyIi0jkGORrFOTmkGax+REREQcEmn3IUD3IKCwvx7LPPYvjw4ejduzeuv/56bNq0SendhDx3c3IEtjiJiIiIiDxSPMiZOnUqtm7dipkzZ+Kbb75Bly5dcOedd+Lw4cNK7yqksSfHOx4WogDhb4uIiHRO0SAnKysL//zzD55//nn07dsX7du3xzPPPIOmTZvi+++/V3JXIc++AW//t4GD5YmIiIiIPFI0yElMTMTChQvRo0cP22MGgwEGgwHFxcVK7kq3fLlByp4cUhXj6vqH3zkREemcoouBxsfHY8SIEQ6P/fzzz8jKysKTTz7p17bDwtTPkWAyGR3+b98OkFo+k8kg6bX2rzHavcdoFH9NfWSy+/xhEo9rsDnXGT0ygHUtmLRQZ0xGI79zHdFCnSF9CZU6E4rnKS1ec/VaXxQNcpxt2bIFTzzxBMaOHYuRI0f6vB2j0YDExFjlCuan+PhoAIDBbjEbqeVLSIiR9NqwyCrb3w3io23viYwKl73PUFVtF2YmJMQgMT5KxdJ4Zq0zemQ0Get9XVODmnUmrkEUv3Md0vN5htSh9zoTkucpg3Y/l97qS8CCnJUrV+KRRx5B7969MWPGDL+2ZbEIKC4uU6hkvjOZjIiPj0ZxcTnMZgsEu7RnBQWlkrZRVFSGmDDvY0HOltUFOYWFZYg21b6nsqJa9j5DVVFRhe3vwqIywGxWsTTinOuMHpnNlnpf14JJC3Wm5GwFv3Md0UKdIX0JlToTkucpQXufS2v1JT4+WlKvUkCCnEWLFmH69Om48MIL8b///Q8RERF+b7OmRv2DamU2W1zKI7V8NTWu7xXfR10AZf8ei91btXRM1GC2+/xmicdVLWJ1RjcE1jU1qFlnzBYd19d6TNfnGVKF3uuMnsvujgBBs59Lb/VF8cF1n332GV588UXceOONmDlzpiIBTn2nhbwDWkx+wDWDiIiIiEiMokFOZmYmXnrpJZx//vm45557cPr0aeTl5SEvLw9nz55Vclf1itoBxld/HsTDc/9BUWmV9xdT6GGmLSIioiDhRVcpig5X+/nnn1FdXY1ff/0Vv/76q8NzV1xxBV555RUldxfS7AMbtTtRflp3FACwctMxXDkiRd3CEBERERF5oWiQc++99+Lee+9VcpOkISYj7y7USxwVSERERDqjr4TXWlPP2vxazo/OdjgRERHpH1s0StFuqzVEqT30zB/hGg5yiIiIiIis2GpVQXFZFdbuykZ1jft1XbQYC5lM9azrioiIiIh0KWCLgZJ7ryzaguz8Mhw51RrXj+modnEk09ycHC1GgqFIY187ERERkTfsyVFBdn4ZAGDL/lyVSyKPnofakR/4vRMREZHOMMgJMsf2Im+RExEREREpjUGOVvHuORERERGRTxjkqMjgQ0eOwOiHiIiIiMgjBjl+4GAz7eB8ISIiItI7tmeUwyAnyCqqavx6v0HF0ErgL69+YjRPREREOsMgJ8imf7zZ9ren4WqCm7+pDo9LkPBAExERkc4wyCEiIiIi0gBf5muTOAY5JBlv6BNRfVJZZXb7XEl5NX7fchwl5dVBLBERhTrODFAOgxw/GPwMt6XOr7GfC8PsakREgbfj0GncN3MVlqw+LPr8vCX/YtEv+zFvyb9BLhkREUnBIEdNnmIchvKkUxaLgH1HCzzeBSfSukW/7AcAfL/miOjze48WOvyfiIi0hUGOinzpB1IzuxrVUzKr3I/rsvC/z7Zi1lfbA1MeIiIiIi8Y5JB07Fyqn2R+76u2nQAA7DtWqHxZiIiIiCRgkENERA7YY0xERHrHIEdNzBPoF3YsEQUGE5wQEZHeMchRkce8A0ErhXRaLBMRUSDwHhQRkb4xyFERL6JERERERMpjkKMDzCZNqmIwTkRERDrDIIek03C0JWi4bLrHQ1vvMPEAjwERkd4xyNEottmJiIiIiHzDIMcHFosyEYiBk3KISIOYXY2IiPSOQY5Mf207gTtf+R2b9+WpXRRidxcRBQrvQRER6VqY2gXQm1c/2QQAmLvkX0RFmPzalt6uoQwpiEIX57UREVEoYU+OHyqqzP5tQGdRDttA9ZTO6in5j5PuiYhI7xjkEJFnDG6pHmKYR0SkbwxydICTgImIiIhCH0fNKIdBjop4p5CItIg3VoiISO8Y5KjKfZjDScBEFEw84zhhin8iUgFPPcphkCPDv4fOqLJf+3iHd1jr8EiQVlksAir9TUyiIiYeICIivWOQI8PeowVqF4Eo+NjelW36J5tw38xVKCqtUrsoRESkIxzIoxwGOTIo3dbzpUtSzTusUnuRcgvL8ekv+3G6sDzAJaKg4AlXtsxTZwEA2w+eVrkk5CvG9kRE+sYgRw6FB0qqdRG1WAT8e/gMSsqrA7L9GZ9vxW9bjuP1L7cHZPtEFFgcFktERHoXpnYB6jWVopw/t53Aol/2Iyk+Eq9NGqL49k8XVQAAcvLLFN82EREREZE37MmRIVSGL2zelwcAOFNcKe+NGr65yzGsRH7ib8gBMxwREekbgxyd4TASIgo0ZlcjIiK9Y5Ajg9J39jw1JNgzIQGPERERERGJYJCjJolBk33AwzusRERERESeMciRwRAi2dV8xY4TovqBw2KJiEjvGOTIoLegRGkCx9CRBKwl+sTAhohIfTwXK4dBjkL2HS2Q/R5m7yEiLeKwWOV77omIKLgY5Mjh4Zo36+sdiu7KPpJnVE96wqYhERGRb3iTSTkMcmTwWO18ikNYkZXCQFA7+E0QERGR2hjkkG6xMU1EgcJbUNpTWW3GjC+24peNx9QuClHA8KatchjkyKB4djVeRSkEsVrrE/OKkNat3nYSu48U4IvfDqhdFCLSAQY5KpI8/I2ND9IRVlciCoSKqhq1i0BEOsIghyTjnV4iqjfYJUmkKzVmCzbsyUHB2Uq1i0IaEaZ2AfSkPg4v49o4REREpHW/bjyGr/48hNioMLz14HC1i0MawJ4cWRSOcnzYHCekERERETnafugMAKC0gsMaqRaDHBmU7snxlAtdi1NytFIOUZouHBHpTT3suNe++jicgoh8xiBHBsVPrz5skItE1eFQOiKieoTnfCKSIeBBzoIFC3DzzTcHeje6ZrEI+H7NERw4Xqh2UVzwkkJERERaE7K3fNnwUkxAg5xPP/0Us2bNCuQugsvDL8qfuTJ/7TiJJasP4+VFW9xtnIiIgipkm1BEIYFNI/ImINnVcnJy8Nxzz2H9+vVo165dIHYREqyX0FNnylye0+SPl0MFiIiIiEgHAtKTs2vXLoSHh2PZsmXo1atXIHahCqXnw/iytaBnV2NcQ1Qv8B6GI85xJyLSt4D05IwePRqjR49WdJthYernSFi/O8fj83LLaDAYEBZmhMFYdzW1biPMVPeYyWSwPW4Uea1c9hdv6zZKyqtx5FQxurZvBKPdCyyWupaP0WiQvc9Afm/22zaFGWXta9nfmYiLDsfoPq0CUTQbk8no8H9dMvj+PWrhd6smkw+/GbXqjH2MY3/Oqa/EzpPuqH2sQuI8I4ES1z+qFSp1xr4eyPnNapof19xA0Wt90cVioEajAYmJsWoXA5mnit0+ZzDIL2NYuAmJibGIigy3PWbdRqWl7nVxDaJsj0dFub5WrrAwk8s2Hp33K3LyyzDpql64aFA72/NmuyAnKjpC9j4D+b2VVtcdpPj4aMn7OplXgq//PAQAuHJMWkDK5iw+Pjoo+wkEk8ko63s0GutOglr43aopJjbS52MQ7DpTXWO2/R0XF1Xvvzv7i7m3Y6GVY6Xn84wU0dERtr+1csz1Ts91xmBwrAdibRu90mr59VZfdBHkWCwCiotd561oiSAIKCgolfWemhozCgpKUVlZbXvMuo3CwrrPe/Zshe3xygrX18pVY9eYsW4jJ792f39uOoaBnZvYnrfvySkvr5K9T1/LKEVRUbnt7+KickRKvMGQnXfW9ncgywfUNpTi46NRXFwOs9ni/Q0aZDZbZB0ni6Xucwb6+GpdWWml7GOgVp2prqnbV0lJRb3/7uyPvbdjofaxCoXzjBTl5VW2v9U+5noXEnVGcKwHYm0bXRK0V36t1Zf4+GhJvUq6CHIAoKZG/YPqjewyCrXvsQ8krNuwr0Rms8X2uF370edjYj/23nkbgiA4PGa226HFIsjeZyC/N/tjVGN3jLyxmF2Pd6CZZZRPcwTfj5NuP7NCzD78ZmzvDXKdcfjdm30vd8jwcJ50ppVjpevzjARi10ryj57rjADHeuCpbePzPgQBBhUm6Gn1O9FbfdHX4LoQo7uJrRInJuvtYxEFir5+C8w8QERk9e3qw3hozj8oOFupdlHIRwxydMD+7kSgs6sJTLFEpBjd/pr0FZ0FBo+B5uj290S69MOaIygurcL3a44Edb+s58phkKNRWqzkksvExgGRvmnxBEREZIdNDfIm4HNyXnnllUDvol5Req0eb3zp2DEaDDBruEfIfpigWuNtiYiISEEabnfIwRaJctiToyItNq5D5BwhWT37uEQkUbBvKBERkbIY5CilHrSWtTxfx+eSafcjUQhgM5mIKDBC9fIdqp9LDQxyyIESP65gdVApEXMFOpEDkV5o+B4GEWnI6u0nsWL9UbWLQeSVbtbJ0RspvR4egwG1GhwKtHRqh+Fpt8VkP0yQDTsiEeyC4jEgcuPDn/YCAPqmNUHjhtGqlYM/UfKGPTkB8upnW9Uugk8U6clRYBtEoUC3MbRuC05EwVJeZZb82qzss8g8VRzA0pAcWp5+oCQGOQGy71ihYtuqL5WRiIiIQkuN2YIXPtyIFz/ahPLKGrWLU+/tzDyDh976G9sOnla7KAHHIEdFWuzxcA6nfIqvtPjB7NgXj/EjBZLGfwrkAb87Is+k3oCtqrbY/i6rYJCjtpmLt6O4rBqzv96hdlECjkGOmjxMytFz21uLqbEdOBRPz0eaSDn8JWjPniP5+L+PN+Fozlm1i6INrKSq82VkSaCaBKwO5A2DHBVpMhTwcNaQem5T5XP52CXDnhwiEZo8OYWuGrNF9PHXvtiGwyeLMeur7UEuEVFgMKMpBRODHAVZBAG5heVqF8Mvnk5AWjs1+Voeh+FqShSEiEJOsDqkF/2yD/e9vgq5BWVuX3O2rDo4hSHyQkvXTJefqII/Wnc3HkJNSXlon1sY5CjovR92Y9rba/HX9pN+befwyWLMW/Kv6HMBvwtybvOVtqwp2umaVox9AbV0xibSCv4ugub3LSdgtgj4ieuOkM74NBJCJ+eW9btz1C5CUEz/eJPaRQgoBjkKWrur9kfx/Zoj0t7gJhj4v4834XheqTKF8sGmvbm4b+Yq/Lguy6f3GzjWhQiAbq7nRETS+HBS0/yNTxEVMtJj61lOgb5HH3nDIEch9r976XNXpP3y7bcX6ABCAPDej3sAAF//ecinbejphMbxwUTn8KfgJLgnMs4PpFBl325hNadgYpATEPr9GQtC6KdYDvXPR9qho3jfkW4Lrg2nzpQiJ9/9HBsivfL3xqAu1/3TY5kJAIMcVWmzx0PwUC7+0ImIPKmsMuOpd9bjiYXr6s3kZaqfpAY8HDGhH3uzCvDa51tx6ox6UyaUxCAnAPT/c/Yv+pKyTs6OQ6c9ZhMKJIe8A/r/soh0Ycv+PLzy6RacLgrtMeBny6tsf1fXMMih0OLvNVOXl1xt3pEOiFc/34o9WQWYt3Sn2kVRBIOcAJB6EsgvrsTi3w/gdFGF5+05/B3YU4TzcDXn56Twdj7Yk1WAWV/twLQF62SVzVOBBAClFdXIypa7aJ4uT7lEgRWAn8Wcb//F/mOF+HjFPuU3riFMvEL1hdQ2AW8m6k/h2Uq1i6CIMLULEIqkjjk9nleC43klsradG+RMGIE4Nx0+WRSArQKPzV+L8soaPH5DBtLaJEp6D8+9RLWCNaTkrE7WZfD15i17iqUrq6jGF78fxOBuzdC5rbRzNumcgr8JAcDRnLNok9xAuY1SSGFPTgAE8rq249AZj8/nFZbj45/3+TXp1d+eWaXuY546U4p5S/7F0RxpvTPllTUAgG0HT3t8nZThdKRfZosFR7KLYWELU1ROQRksFrteULHjxJ+IQpSpg6Falb9ZdRh/7ziFVz/fqnZRSKee/2Cj2kUgDWOQEwCCxfcrkqdeoM378ry+f+aX2/Hn1hN49fOtqDFbcLasyut7HPYv69VuKBREzPpqOzbty8OLHwVusapQbTzUZx/+tBf//XATlv512OtrBUHA8dwSmC36mjthEQRkZZ+VXe41O0/hiQXrbOOtP/xpDx5/ey0qqmoCUUxxdr+5vMJyvP3dTmSeKpb0Vosg4Eh2MSf0h4jcwtCenxWK6uWcHNItBjkKsf/hF5f5Phxjypt/iW78dGE55i751+v7rT04BWcr8cIHG/Gf2X/L69URHHs63lu+R/p7z1HqJnBeYe1cJbPMoJGBi7qqqtVtgP7zbzYA4Ic13hez/XXTcTz7/gYsWLY70MVy64QPw1aX/nUYL3y4EZ/8LG9+y0/rjwKoTQIAAKu3n8Lpogps2JMraztKmbd0JzbsyZV8I+O7vzLx3w834YMf9wa4ZL6fx+zPnzwVidNlGmFywTk5pHUMchSi1J3F0grxO6r5PkwCO3G6NgXgM++tl/we53H5m/b60PjR+FAXx3VylDn7/rntBNbvzpH02pz8Mixfe8Q2vE4JFkHAniP5KHNTf6SqrrFgxfqjtrojV3llDUp0MucCAH5aVxsI+VTPFVBdY8Ez723As+9tQFW19BW2rQHc6u2nZO1PCz/NLLvhp9kyh9X+sPYIAGDtrmzbY1puMGutaJ/8sg8Llu0KyjGrMVuw8Ptd+Odfxzq6bnc2prz5F/YdLdBEfSS56uE6OaRbDHJ0wp8TQ41Z3nu1MifHVzsz8x0CjoMnijD76x3IOZey2uKUlc1f+cUV+HhFbeNBiiffWYdvVh3GV38cVGDvtf7YcgKvfbENL3+6WfJ7Dh4vwic/70NZRV1QsmJ9Fr784yCeeVd6YGzvwPHAJJWQorCkEm9/JzPtpUqV1TonptIusFEy6PVFMNsevp7P7DOXnTxdiq/+PIjH316rq8BaLRaLgD+21N6MCcYwsb93nMK6XTkuowEWLtuN0ooavPHVdtk3B0Ohebxq2wm8+NFGFJXKG0quRQIEVNeY8cKHG/HFbwc8vpLk8bROjSAIOJpzVvVrhh4wyNEJP6b5yONhP9JTSHtuOSo18V9w84+Tp0uxYNku23ocL32yGdsOnsbcb3di6/48PPXOejcb8Y2n3pO8gnJU19Q2ZItKKrHrSL7tOCoZEKw7d2f7RJ73HpiqajPmfPsvXlq0GX9sPYEv/zhkey7zlNwU3I7UzOnw4U97VRt25Ul1jQU7M8/YAppDJ4swaeYq/LrxmAqlUfsWRK3t5xKo2Jdmx6HT2JNVAABYuzMbz7y33nZjQszT767HT+uO4nRRBVZuCsCxtCvcpr25DskaPL7NIbuaQokHFG4kSv0s/vAWeFZVW7D3aKFf+yirqMGyfzJtQ7Krqs2SE47sOZKP1dtP+rV/X3y0Yh8yT53Ft6sOeX+xROWVNbbr3fK1R/D7luOKbduZ8+HduDcXWdln8YuP5zOLRcCrn23Bhz8Ffgiqnjz1znq3NyN2Zubj+Q824rn3NwRs/6UVNSHR68YgRwcE+H+xXLhsl+gkZefHBGilGeS/4lLHi2xeUTne+tb7vCarQyeKbMkeTheW44+tJ2wBiwM3jZp9Rwvw8Nx/8Mi5eVaPzl+L17/YVvdaySVxb83OU7WTtu3K4G3I2p9bT9jmZADyhwz5ShAE5BaUBezEmefD3elg1PUvfj+AmYu3493va+f9vL98D6pqLPjc6c5nMC4n7oLQYF/MjolkTJz11Q689vlWlJRX450fduNEXqnLmjruyx+IUtaZt3Qnlv2TiZcWbcbandkeX+swHNbLdv0NNopLq/DhT3slpeVXKlAqKa/GkWzHRBHBqj9VTuffT3/dj6V/ZeK59zfgbFkV7n19Ff736RZJ23rti2348Ke9kpNeKK1SxvBUb/4z+y88Nn8t9h8rxDerDmPRL/slB3v5xRW+Z6IU5M+ZPZbrOP/w0Mki7D1aqEzAqWA91EID//AJ8d/1hj21I1W8rbHoLzVHZiiFQY5OePu9rdudjdlf7/DwfA427sl1+eFOfO1PHLT7IQkC/L4dr9kMzSLHsKi0yu1ciOmfbMbcJf/i5OlSPPnOenzy8z58v+aIy+sc5/gAv248htcXb8MfW08AqFsXyNvQjBqzRdaJdU9WAd79YQ9e/GiTwzCeaQvWenxfiXMQZLdPqd9djdmCP7eecElq4entP6zNwrQF6/DVn57vYB46UYSCACxEll9cgT+3npA190UJf2yprQeb97tmR5TzW/l7xyl8/PM+tw0SiyB4rT9a+Wl6KuXsb+rOY0o2BKUoLKlEcWkV/vn3FCoqHfe97J8jOHi8CO/84CVJhd2X+tz7G7D7SL7bl76+eJukcglC7U0TZ5/8sg+rt5/E8+9vxKY9OZi/ZKfD8NN/D5/B5ysPnDu3SNqVV4+/vRb//XCTrTyb9ubiP7P/dvmc9nV7875cHDheKHk5ADGHThbhp3VHHR47cLwQAFBVY8G2A6fPPSavYXYmwA1Ff3zyyz58+st+r6+zDkn3tsSEs/U7T+HB2X9j/hLfVreXWqXsX/f2d7sczsHB6FUMNcFacLiwRP8LgnIxUB3IL65EQlyEx9cslJAdqqCkEk8sWOfQBSoItcO57Ln7+Xi6E1hdY0FVjRmxUeGi7y8pr0ZUhAlhJqPL86eLyrFq20mc16cVGsZFev0cvhIrv7W79/rzOmJ0n5YwGV3j/tNF5bYAxTqcxrZNQUCx3dhqAYLLHXq35REE/LrpGHYezsedl3TBY/PXIKVlAh69PgMAsHV/HvLPVuK8Pq1E33/STXIAb8NEPJ0epQ4lXLnpOL48N6fo/WmjUWO2wGR0fW9JeTUiw00IDzNiyeralM4r1h/FNaNSRbd7JLsY08/Vx/enjXZ4rqrajC3789CtfSM0iPH8exDz/AcbUVJejez8Mlx3XkcAygydXPZ3JvKKynHHxV382p63Ruj7P9bObejWrpHLc9U1Fjzz7nq0aByLKVf1dHl+T1YBVm46hgK7i5b93XjnXZeUVeOjFXuR1qYh+ndOhlHku/WLh8968LjjTRdBEPDjuixEhptk3zV251huCd75fheuGNYBGZ2aAKgdA+8wlNUDqTcjikqqMOOLbS512crxfOJ5m7O+3oH5U0c4PGZ/Dnjh3XUAgJioMNx4ficAwBtfbgcANG4YhVEZLSWV2Rv79cjS2iTa0pFbP2dltRmR4SaH98z1sRFt79tVjinhXYJ9L1XUYhFgMNR+9y0ax/pdHrkqqmpw6kzdTSFBqP0MZrOA8DDX605xWZXtBsnlw9sjNipc1v4EQYBZEESvaVbfnDuHi92AsW6jqLQKYSYjcgrKkNIiwaWW+tLgrqgyI8KpjnhTY7Zgw54cdGnrev4DgMxTxdjvQ8/Dt6sPo6C4Andc4t/5OxC2HzqDlZuP465xXdGsUYzoa47lliA+NgIJsfKvifUBgxwdeP/HPXjwateGi1zrdkmZcCq4vVj8tf0UNu/Nw4PX9HL5wT06fw2KS6sw+z/D4LyBopJKPDTnHzROiMKr9w122e6rn23F6aIK7M0qwFO39HVbsr1ZBTh1phT7jhViTJ/WiIr0fJJ0CWo8tCE+/+0ABABj+7V23Y79+5y28dmvB/Cb3fjn7Hzx45tfLH638POVtQHRvCX/oqrG4tDosQ6t69S6IVo3jbM9brZYXOfeyDg3O5/HrR/pt83HHYaxeWK9gwrU3u15dN4a9ElrgqE9mzu8bsqbfyGxQSRenzzE6zbPFFV4HNf99Z+HsHLzcbRsEosX7xzg8ry3C5Q1+Pv38BlbkOOrkvJqrN2Vjez8MltDZFRGK7RoHON1PSv7ctqXuKrGjBc+2IieqUmYOKGX7fEzRRUOvYAl5Y4Tlr/7OxPf/Z0JwP26I6+JLLb43w/dp23+9Nf9KCmvxqptJ7F1/2ncd3l3j5/JV1LaFNYhOJ7sySrAZYIAo8RGyrwl/yKnoHb46vvTRuOff0/JSpd/NEdeym971h7b8DB5jTzBUptBccWGY7h5bCdsP3TGodFsJXau8aW3YuWmY/hl4zE8cn0GmjaMlvSerOyzeOHDjRiZ3gJJCVGy9+nsr+0nYREEjEh3DdAemPWXw8RrT43tg8eL8OrnW5AQG4EzxZXom9bE77JZLIKs4H/6J5sdztsCgBc/2oQTeSV4c8owREeGQRAErN+dg/bN4xEZUVc/pPZ22F/zDp8sxqufbcUVwzvg4oFtRV/v7uey9K/DMFsEVFaZsXJz3fXt4WvTkdoqwX6HbtkHu87xqOAwekDaMfxhzREs++eI2+fth4LL8cO50Rnn92uNNskNxMul0tA1awKld77fhWdu7Vf3hF3RrDdqnW+klFVUIzzMKPs8E2oY5OiE2Jp/85buxH2XdZN8kpCcOMDN4yXl1Sgpr8aTC9fhiuEdcOngdrbnrL0ZB48XuZw4d50bxnDa2oh1et46rvTQSc9jo+1Xxd6wJxf/vbO/9w9jx9vHX7szG5XVZgzqmozGdhd1T+/7zWmCp7usZA/O/tu1PHYbrvSwtkxRaSVaoy7I+eDHvVizMxuJDep6vbzVgBN5JfjitwO4bFgHl+fyiysx59t/JQc4zlZvPwmzRcCGPbkuQQ5Qu2bTrkz3Q3bKK2sQEW7Eo/PXuDxXWFKJv3acwvBeLbDxXJpnKckVpPLlxt2B44WY/fUOl3Tv1TVmvP3dLpchIwbU1aFH5v2D/GLxIQBPLKi9E5+VcxY3XNgFf249gYyOjV2Oi3XenHWb1gBHzA9rjkgbIuRUye17AzfuzcV93rcgi/Qmg+DQ++TOwRNFeOGDjRjSvRlGpLdEeJjRYwO0vMpxKJrc9cA89SgdOFbo8pjlXAAmCAKmzvkHFVVmzJs6XNY+BdTOIwGAd3/Y7fautdh5vrZHzP22rQ32opJKhIeZEBMVhs/O3YCZ880O3D+hBwpLqtAovu6cI7a9Zf/U1sU/t53ElSNczzVyVFaZ8cG5yeh9Ozd1ed45s5Sn3/K7y3ejxizgzLnf3iYJC2vbK62oxr6jheiZkoSvzw23/WvHKQzu1gw3ju3k8b2V1WaEmQyi562s7Nrf5oHjheiZ0hjrd+dg4bm5e2/cX3djSEBtcpkt+/Nw57iuiAw3obi0Ci9/ugXD7M+5dt/Jy4tq5yZ9/echlyAnp6AMG/bkolSk17+yyuw2mNh28DRSWyY4PCZ23PcdLcD/PtuKiwa0wdUivfbuquKanafQsnEcThdVoI9TIOptKF6Zn5nGqmVm+lux/ij2HS3A5Ak9EGYK7MyPs05rL3q7bJVWVOOBWX8hNioMbz0o7zwTahjk6ITY8IhNe3ORN6IDmiaKd2P6tB+Jr1uy+rBDkOOJ/R22L347gPTUxvILJmKft8w8LnePPL88K+cssnLOYuWmY3hzyjDR7QiovRNbXlnj05Ape5In/Nvtv6S8GmvOTXy2n7fi7aQ366vtOFNciV1HNmP8kHYOz50prsAZNz1N7rjrjXB3N9Xd3IOS8mpMefMvJIt0xR/JLsaHP+3F0ZwS7Dh02uX5rQfy0DQxBi29DD2pqjajwse5HWaLBTM+34bmjWNxywVpOJ5bYms8ONt/vEj8QmwXkbgLcJy9tmgztuzLRZe2iS7PCc5RjgffrvbcAyLVoZNFmPPtv7h2dCoGdm3m9/bkzD2TOhzmWG4Jvvj9IL74/SDaJjfAc7f3c3lNSXk1flyb5TDEVAlmiwUWS23j0Tp8y96rn27BtJv6wGwRbAGk3EnD9odMSuDn8N7a9DWiz33x2wGs3n4ST9zUR/Su8PG8Ukw7F4B743Be8HPoT43dnT1fFxguKa/Gy4s2I7fAv5TZr32+FUdzSpCe2hjbDtadi37bctwW5FRVm/G/z7agc9tEXD2ytmFfUVWDSTNXS+4JO2A/0dzp+FmDnzbJxzBucDv8sOYIcvLLbEEXULfYrzfPf7ARlVXi50Q5SQjcDWFf/PtBW3nEgpyyihrRoenv/lB3s6FPpybIzi9DbFQYHrk+I/BzfT30Nont3Dpce8OeHAzu7npzT0kuIzO9HIvMczeM3a27WJ8wyNEJ95ONFd6RIP3iZLZYRMf7enu7pwv0rxuPoUvbRLSyG57lzqe/1k3IFDsMro9JO1hny6od7mTbn8gFoTZ1bW5BOV69b5Ck7Ulhv49TZ0odhudYhyD9sOaI+0ar00E/eKIIZRU16JmSBEEQJDeupVLigrN5X55toUDnBAaA43CqQyeKHealHTxehLe+qR3OZ22QuSvS1Dn/ONzlKy6twrs/7MbI9JZem8/7jhZi37Ha/y7o3xqHPWRiWuJTQCFegi37anutnOeA1b3L4LaBUWO24GhOCdo1ayD6vC/mLdmJopIqLFy2W5EgRypfU5pn5ZxFVbUZP288hoZxEfhrxylcMyoVKzcdUyTNuHP9v/vVPxEZYcJ1o8Xnmu0/XptMo6Kqrh7Kzd5k/3pPiTlErxUebvhYh4i+t9z7vE5vlGqHHs8tsd3MsW3by8adhyqWV9Zg9tc7RIf0OduTVYB9Rwswfkh7Ww/gsn8yUWMWMGF4B9vwRPsAx9n6PTnIPHUWmafO2oIca/0VHUZq9yVYr+OuM1ZdWe/q+zM/TSzAKSqt8jqv47fNxzFhuOceuhN5JV4zXT797no8f3s/tElu4PZ7tZ8nVHvzKLBRjsej6eG36i5YVJY6w+U0kGDObwxydMJdZft5w1HcemFnqVvx+orSimqUV0r70X6z6rDrBHKD453XLfvzZJ2brJP23U3U9YecH+yUc2mfa9/osBXbXUG5mWykcp78vOiX/WjfPF7WXXlrMomrR6a4ZDNTYnKlwxbstvfRCulrHcxdIj2dt7MsuyFYp4vKkRQf5baeOQ9jKK2owZqd2VizM7v2fSKqa8woLq12aDA+IfFutjOjwQCzklcLoXYCtbuf8/8+24JDJ4pdeuw8btLL8/40qIpKq7B62wk3z3qvi/vt5n/J8f2aI1i+Nsv275c+2YymidLuqPuissrscc7jw3P/UWxfnhZ4tla1dbuzHR7zVgXtz9tSArBfNh5DbJRTE8Ig+qcsgiDgWZH1P7xuz+kFr36+1TYczBvrnLW/dpxCempjXDs6FUv/qh165y7xi9Xri7fh4gFtRH8jUo/B7K931M57c5/1p+5PQaidoyPjAJ84XYp3v9+Ny4a2R3pH8ZEUb32zA4/fkOE1++Qhu3TlztXk4PEivLTIdUFqsfr068ZjuHNcVwmlrz3/BCsnQGFJpSJZxUrKa+fEOCfh8IVr1XJ/MHZl5ssemRHKGOTo3KptJ3HVyBRJr5XSTCkskT6Mw5ol68Of7MazW4fSnPPLhqMY6ZzVx64g3tZ08YvI3UuJo3zcbkYQxP/2l7eJzD+IpK625+6UJ5auWe614sTpUqzdmY1B3evu4LsLlKQOwZG70jlQm6mqbv91jz82fy0uGSQ+sXavm54Qse1Ybdybi/nnhhz5O6/AO/mVyFu8cehEbW+T1KErVu6SYwD+3UOdv+Rfl/kjcoIma2IHuewDHCuxz3HYy1xAOeRkmpJ7/pD6emsPn33GTUGk3y/zVDH+PWx3o8aHedZL/nKcD+aQdMOHSjP76x2ivSVSgi773S37O1NygGOv4Gwl/th6Ar3shlTX1Hg+V+3KzMeuzHzccmGaa5lkHIP5S3c6BFQOSxPY/b1y83GHZABSWOeKzv5mh9sbiIdPFuOeGau8bst+6GC12eLwGcUCHHesp4BgpUMWI9YjOnVO7c0I+/lnnr5IsZpZVlE7DDsizIi3HxnpZyml9/ruPpLvdmj46aJyvP7FNozp65pcCQDOllXZ0rCHEgY5IUDqugCBOJUUnK3E6u2nbP/edjDP637sL7crNshriPlDgG9Rjrvzi88LqPlgq5eTT6Dvcr3zw250aBGP37Ycx9i+rR3258uuX/hgo1/lcQ6ylq/NQssmrnNzTp2RnqRg5aZjsAi1cxSsNgZgaFOwyNntyk3H8MnP+9w+789nEJsgv3xtFq4cIe3mjJLOiAzb/Gm9azDkjbvjIec4+TNczfMLXR8qrzS7PP7iR47Z9eyDAqVSdcvlaTiYN/bnhKUeknFIMeur7ba/pS6iKvcnIrZVg9t/aNPrX2yTNMdWfDi5jLk/Xuq+/fcl1bYDpx3W5LJYBIfF0R2GeHvYv9hT1t9SlVOAXF1jxpHss0hpkWAbFvn3jlMoKa/GhQPaeN2HxSJgzrf/uv2deLoh9NUfh5BTUO4wzN/erK92qLYwbiAxyNEJTxdPT4uAOm1FkbLYc05tuXr7KYdJ5KKnBrsHnTPkuOPL6sOiKaR9OAT2KXvd9erUB9M/2YyS8mqs3HTcIb2pL064WeNHKrHfg+hXK6PVac0mpTSDh7FlvlShQKzE7W3egljP3aa9uVi+Ngv3XNbN7RoOnqixCKNYD+J2HxrWStx99qdH2ePrBMFlEdW1u7IRZrJPCuB5G8G8gSOZl0L7GogvWLbLtzcGgg4CG+eq4XNgat2OhM9sHYXhji9Dx390urnxyqdbkBSvzDp97jI7zvl2J/49fMYhO611/bOMTu6DReuh2ne0wOPxFlvvaMX6o6g2W7yOnhALcOQEolrFIKdeUb7Cil5Y7M6CAuDx7CT1YqpEyQXUTuyU+8P9aIXdHW6nsdG65OOF1D4Zg/1kSzV6KsR3Kb8gwSi70rsQBInlVnDHYtdsaxax937Y7bC+lf0CsJ48On8NYiLVvwR5mt8SUB6SAQC+Dem0bvZ7kRTAf+2o63H3dupSYhV6pYcheduar3MNvfZaBap6eNluhf0NQL1ea6xEih/oQFoQBI91QmxNLbGeXgAeT7g/rD3iMm/L3X6tw0N/23wcFU4ZWhd85z7YtrY1ajzUVWsSH2fWLHApLeLdvjeUBTa5N9VLzj9DTxc7wcOPNhDtT38btc6Z1rRCzgVeBzcLvQraytRK7MbDNnypQ4K3jQaAp+Ntn9ihqLQKU978C4+JrHlEjrx99TPdjK33ZveRAmRl+zfsRK3hau5I+Z24G4bj974lvk7sNyL3PGX/Od//sS6Ji8a+DUW3JuUI2Yaay/DCBxsdhp85k7GOq0dFJVU4XeSYcMRxHVHX41VcWoWf1h+1BSAAcMTDHDIp9d/bWl/VXuaWie9Y/lu0hkEO+UX0JC7jxpi7uzkuKSh9aQwG4gdq35MTCmeAes7b3WafLgwy9yGbxIqt5H6lttX2Ha1N9FCk8Do0euHPnBzn9+71tg5YACnSkyOz+vnbM6702kdWvpTqRF4JvvrzoOzEOvbHYL/dorK+9uppma2KSYtyZJ/PjuaW2JKwiPHlRtmJvBIs/H6Xyxp3zks02G9biXaIdRRFKNygDDb1xwqQRMEfAy6FeIzjEAm4vMb+RO7uRsu8pTsd5794KX2who4dza3LgqalnhxZFO4FCVqviv0+Rcuh/H6krLHhyckzpYpfmSxSh6spuU8f2lhf/XkQTRI8p2z2d5VytShx/J3PH4qeT/wsoBpzcjzt0Zc7+Wp65r3aFNgbE9wnLhGdjO/mIDw2f60CpVKG773PztuRkXgA8On79xSsy+3JsU9UcMAuALXtSxCwZPVhpLZMQFxMuMPjUtY/8ianwL9rkaej7WleYl5hOeYt3YlLBrXFRUODnyzGX+zJqUcCMvxL5LG8wroJxWLByfG8uknnxWXid9+cF4esrJLfyhI7wSnZONTSnBy1MnipRXJg5X1xkID6ecMxj7vwtQ5JKraCn81+3QWpd8x/WncUH3vI2EbapURPjlyHPdx1V7XT3I/zvKeU+mILZmrpmhJo1o8qqYfGx8PiKVg3yIhy8osrHDKxic3d2bwvD8vXZuHNr3c4zPdR6rd0NKfEr3P6sVz3y1S86SZ5lQDg4xV7kZV9FvOW7PR95ypikKMTyjRiA9Ci87Ng7rKiOJ8W3v1B/mrcKzYcdZgsX0u5Y6ClYetyPlUoxENSs6st83F9ISWp0dMFBO6zuWs45BdX4J3v5f9O9eiwm1SrZhlJDNz1TlfXmLH7SL5P5bLalen5/d6GPykxJ0du/ftxnedU3mqupyKF3NKJNTq1dE1xx6ciipwz5AR0Ww54X5pCjFI9klKW6bC/+eMQ5AgCKqvMePs7/4KE+Ut3oro6uMMWi0urdNvbbsXhajqhzOk9ANnVArRL5xOgL2kqdxw6gylv/uXwWKj25MihdJs7288hXYFU5G1x2yAEIB57cnzYntShOxVVnlcu99XzH2zEYLuFYa0/g09/3a+5CeuBUiiyiCAgbwFWsdNHjdkiaUFGf/284ZjH5xW5+yzzt+XpHK9mvXJ3l9uFAqcSscUpQ5WtJ0fCcdu8Lw8dWyXI3ofFAuzMPIPFvx3EDed3Quc2DSEIwBtfbsOuIwWSt+NtqYtV207i8Mm6QMj+M733wx7R1M6++HqV6+LegbT494No37xBUPepNAY55BeHFbNFCPDxTrbMa9rZMucem8DTVIyj4ng1f9e88YXox9XojV6lvxrBh0m4SiourcIKu8Z8dn4ZsrLP1qtkA4H47W/al+uQ5jmQ9mR57unRWrD62+bjqp3ipM7LUyIVubfrqRb4tmad/3ztyZm1uDZIfe3zrQCAy4e1lxXgSLF2V7bb55QKcAD/54j6IvOU+6xvesDhavVIIC5b3tIWBov9nAFPlLxOLl97RMGtkRxKNfJVH67mU9ZA7U3CfnvZLjSIDvf+whChxLnUua1YXhmYnjcx3no4s3L8b9goWUWlDBdSm7vePRIneyiZD1GuWWRY5tK/MmVvR651u3ICvg+ShkGOj5onyV/h2y8aa9RI5Wt7TG4jQvLdJQWPo2qLCIrQ69A5XxWW6KdB4TovrM5HK/a6fU5PcvLLUKCj78R//v/e1PzNetuz1uZW6eH8VloR/NEEeiH29VlvTEqNXbwNGROjVo/kig3Sh61SYDHI8dE1o1LVLoIuHPXxjqDci1qJxOFqWp+8GgzKT4QP/oVki8gQAF++W7Wz0m09IH+umUV7HTkAzmX/qSeUaHNrv9nuJwUrqRopreX6fcsJtYugK9bexFKJawl5yg7mjnOWVqp/GOT4qGFcpNpFkE2NhpGvd1LkXtO++P2g9xcBqKwO3pCQYJJzvLTYQJbr0EmR7FY+fDA1xjj7TRBUD85IAdpvt/tFySp6prgyJM5b9dXOTNe5RtYe7te/2Baw/S4JwtA00jYGOT5KjNdfkEMUCGokfajPtuw/HdT5G+RKmZ6c0I5yPA3TlKu8sqaeDYcMLR/8GBrDckl/GOT4KNiTbDPdrMugB+VV+hlLq1fZKnbLe1rwLpiysvWdBUYqJSaFk3+8rekihQ5GYPll2T9HFN1efRoOGUi+zG2xV10T3LVaiPzBIMdHwV7g74c1/l9Uj+cFP9UvwLs4wSBnfYWv/gxurn0icvXBj9rITEn1y+Q3Vvv1fm9rLBFpCYMcIiKiIMspKFe7CESyHc9TrkdND1nzSN8Y5Pjhf/cOUrsIRERERJpktrgf3rYr0/OitET+YpDjhyYNo2EyMucLERERkbOcfPc9llsPyk+hTyQHgxw/vTRxIIDQSMtLREREpJSi0iq3zxmZC58CjEGOn5o0jEbThtEhngyUiIiISB5P8244EoYCTfEgx2KxYPbs2Rg2bBjS09Nx991349ix0M7GkdamodpFICIiItIUT7kF2JNDgaZ4kDNv3jx89tlnePHFF/HFF1/AYrHgrrvuQlWV+y5LvevXpanaRSAiIiLSFIuHKMfInhwKMEWDnKqqKrz//vuYMmUKRo4cic6dO+ONN95AdnY2fvnlFyV3pSld2zZC08RotYtBREREpBmehquxI4cCTdEgZ+/evSgtLcWgQXWplePj49G1a1ds3LhRyV1pitFowA1jOqldDCIiIiLN+Pcw00STesKU3Fh2djYAoHnz5g6PN23a1Pacr8LC1M2RkF9c4fBv5/L0TmuC+y7vjvlLdwazWKpq0TgWyY2isXU/00ASERFpiclogNmiblqk3zYfd/tcdY37NXRIm0wmfeUrUzTIKS+vzYceERHh8HhkZCSKiop83q7RaEBiYqxfZfNXdEwkGjeMxunCcky7tZ9oeS4eloKLhnbA1n15eO6dtSqUMriuPq8jSitqGOQQERFpjNaHg/2yMbSTUoWi+Hh9Tc1QNMiJiooCUDs3x/o3AFRWViI62vcDY7EIKC4u87t8/nrzP8MQHx+N4uJyFBSUun1d+2R1A7JgKSurQllFjdrFICIiIqIAKy4uh9msfg9cfHy0pF4lRYMc6zC13NxctGnTxvZ4bm4u0tLS/Np2jYa6Nc1mi6bKo5aKKjMsKneFExGRPGEmI2rcNFTCTAbUmHleDwUGgwHgKn6kkHlfb8elg9siKtykdlEkU3RwXefOnREXF4f169fbHisuLsbu3bvRr18/JXdFGvD3jpPQeG84EVG9Mqp3S6+v8ZS5t3enJgqWhtSk9eFqpC8/rT2CA8cK1S6GLIr25EREROCmm27CjBkz0KhRI7Rs2RKvvfYamjVrhrFjxyq5K9KAs2XVaheBiIjsDO7WDEN7NMeLH21y/yIPjV8DW8Yhw8DbkKSw1skN1C6CLIoGOQAwZcoU1NTU4Omnn0ZFRQX69euH9957D+Hh4UrvilTWummc39tIbZWAg8d9T0pB5E7nNg1xLLcEpZw3RvVIWWUNGsT4fr1lsziE8MskhcVFKx42BJTipTWZTHj00Ufx6KOPKr1pXenWvhF2ZYZ2fvgLB7TBkVNn/dsIhwtTgMRGhSM2OpxBDoUEqbMr3M21kbUjCgmehiUS+SI8zAhBR1PS9ZXwWkf+c1VP/PfO/oiLDt0erEgFJp8JjHKIiLyT2GCtMQt+DVNiuziU8NskZZmM+gob9FVaHQkzGdGqif/DubRMkbHbjHEoQATwEk/1j/+ZP/mrCRXsyaH6jkFOgIXyHE4lPhpjHCIi76T2zlgE/86qoXzNIiLfxcdGqF0E2RjkkKr8vB4TuSWwclEIkRp89O3c1Od9jO7dkv04IYSZ8khJURH6WR/HikEOqYwNUSIipUSGm3zujbnx/E5sGIcQfpWkpPAw/YUM+iuxzoT0OSakPxwRkXYo1WANM7nfkMFgUOW8ntIyPvg7rQf0ELDGRYcjIc73YVDa/4Sho3lj/c0zZ5ATYHo4yfjFz4+X3ChGmXLIMCK9RdD3SSoJ9d8fkUwmk+fLvhq/mKdu7qvCXkOfVs5+d17Sxe1zCXERGNg1OYilIV89cE262kWQjUFOgJk83DUjYEiP5kHfZ0SY/saVknyckkOhRZlrSbSXcfW8LxA6tPJdeiyHv+dpjXzG+qBRfJTaRZCNQQ75TIlzi1GFs7BWTvxERFIpdd66aWyatz0psyNSnfNIkoyOjVUqiXsC/Lsh5c+aUBT6GOQEWEj//BgtEBEFxUUD2iiynaaJ0R6f52k9dDh/l22bNVCnHAFsCbG+kicMckg1DWLCVdkvT4pEpDftm3ufnH/D+R29b0jw3Ojk6bHO7Rd3VrsIfnH+LmvM/i4UqzxBEHhNpoBhkKMBiQ0i1S5CvcLu7fqB6+SQUp66pY/s90RHKjv3T6mGoNdfBVucNmmtG6pdBD85fpeqzanwUqWknKob+pGBjeovBjkaF6HhvOT+XgpVa4PyGk5EHlzoNDQs3EtGMnFKn2ikbM/7a7wF/1qNcc7r3Sr4O9XAwejdqYnP73UuvlKfZkiPZvLKocA+p93YW3zb6n9F9ULzpOBnwlWCdlvQhMdvyMDbj4xUuxiaFB0ZFpT93HGx+9SXFBxNG3qeQ+AO+3FIKb4sBaBG20tKMVs0jvW8DYXKorR0NSbNq3AnbtLl3R3+ndzI+/nv8mHtRR8PVGKfQd3kBTmeKpUgSKu3MVH+DW+/ZlSqX++vz9JTG+P/7h6odjF8wiBHA9z9wNPaJAa3IDL5u25cqyaeL7b2+1GSnO3p9e5FKPEnDbtWG2ykbc71xqiBiiTlvGV9iaegLMynXqnQM25wO7WLIKpXqmMwN25QO6/viXUXAASo3rZqKm9RSE9DxKVmV/O3HeDcO0vSNWwQiXANjyryRJ+lpqBLio/C3IeGI7VlgmLbvPmCNElnN6XvRoXynBy9BWVS6lOPDklBKEloe/KmPujbuanaxfDLTWM7BW1fzZx+R56Chrho3+4wGw0GzHpgKKZe08un9wNAm2THxmZkeO08IC3MR/NnmJWoEDhtuxtyZc++ql0yqC0ivaxrBLif1xuoQ6bWVxEf6zovR0pVv2scR2S4005Cxj09//QY5OjMeX2UHZfsrpvbmcFQO0Rs2k11J2l/I3uxE5b4vvX8EwsutQKC/l0C14CeMLxDwLYdCJ1aN8TwXi0CNp8uKT5KcrKS2y/ujPenjUZqqwSXYTB6MzrAczKeu60fXr13EJ6/vR8S4xyPr7tTUNPEaMS4GTor5bQVHxuBpo0cA6oZkwaLb8/p31cM74Dnb+/v8NiQnr4vrtylrbIjB6Se36VqqPD21NBJZiKDxAaRHhuYlw9tj3GD2wV9/Ru512RPozYGdGkquZfS3W/Dm8YJvg15DkXO147z+7b2/iYdN8EY5OhMbwVPZiPTW2D8EGlBjrU3xWgw4KqRKRg3uG3QThy+DBUZN7it2+dCKWaSOuTPXvOkGAzp3gyd2zRUrBxNE33sQbL7Ltz1QkWES8tS5XwDQK2b2def1xG3XeSYeta5PrZv7v3u2ewHh7k8ltoqAc/c2hevTx6C96eN9rqN7u3ZC+bOrAeGOvy7bbMGaNwwGm2Spa8losQNGOctuA1gnV54qdNwq2fvHGAbiia3XC/fMxAPnetRUqKnu3lSDC4b0g7Tbuzt0zlKTIOYCDx+Q4Yi2wIk9noH4GIxpk8rW4+bv3qlNsaE4R3cf99eyh/mx1BgqXp3aoKWTcSHt915SReMG9xO4rnagDCTEU/d0geNE+RliTMqPN7UfsjnnZfoq5eog1MqejnDYPWIQU49JueHb79ewMUD22LC8BTR18nJuiJ173Iv2FcM7+Bwd+KWC7yt8C2Nuzu2Vt3aJeLxGzJw4/mBHVYzvFcL298XDXAfzLlz9ahU3DmuKx67wfvQCSXMfWi4+yftLm7Nk2Jl3U12HiYUEW7Eu4+NcnisUbw20rM7/166SQg+xHpKh3RvJusOuRYCem+/G7XEx0b43cgzGoBLh7Tz6b3CucrvXAJ35zt3wcfTt/TFbRd1Rt8uyT6VAwCSE2MUnasz/e6BSIiLRKfWDfHfOwf4vJ2eKXa/E4P3eapSv8+J47siRcrQ6wDcKbnh/E547vZ+bp93yYim4I/Yfluv3DsIn7xwEV6+d5Ciw9CthvdqjomXdvUYBGR0bCK53lmLntIiATeMkXeNNSkc5Nh/JT1S9HUjyblGS6lfeh7izyAn4FScNe+FnNO3u4uL8w/k1gvlLJ7m+llait31c3rZY9c73s1zHgLgfMLu2i4REeF1Vd3XQzjz/iEenx/duxXS2iQiyctdptgo/xp9zr0ESm3XH56uIXIy4fl1MRIcA3cBAkxGrZ7ifJuLJrfJ5byF5EbBn7N196VdFdtWsIflWLnL7GQwGDCkR3P8795Bsn9/zj0xvurQIh6j+7QKuWG97Zs3wO122S2lfDqpDeaBXWVmBwsiTw1KpW7YAbVZ9uKiw9GycazsIEdKVYuKCMPAbs08nv+DVWWVntcrNfaNCDNqbn0f5/l6kg6Njk8tWm0BhJDAj5mxTiju5eGOwot3DcDkK3rgebs7SL6m5nUnPibc77uBYr8l+3bvU7f0QWenu/1RIhMz7S/4AoCGsfZ39H37xSrV5f3kzfIXFpRCcjChUJW0v0M/xmlcr+QUo06HdEBX3+9GhxpFLsxO23j42l64aEAbTL6iO269MM2nuVTOw+RaekhJ/OJdA2QvQOjp96HUvJEHr+4JQFpj5c5LuiDBTe+Z9fg1aRgtK8i4+9KuGD/03FBhyV3akjcfEsJNRtkf+cGrfU/ioBkG0T8BwG09rA/sf16C3UVs6rXpkt8biJ+QAcA947uJPjc8vYXo41oSqDTjWsEgRwdu9pJVqGvbRLxx/xA8cFVPt68xGQ3ok9YEbZIb4LHrM3DRgDaKJzG4bkxHWa8X/225PuhwZ0tw9yo7Ii2XB67sgbTWDfH4DRkBbyt42n5CbASaJykzRt1lv0E+V9n3WMVFh+Opm/sgzGSQtx6B01c1uLu8O6xzHhyOfp2bIi46HGP7OQZaWutif/qWvra/m0iZzxaA4jdOiMbVo1LRJ60pRqS3VOTuv6fhGp4CIHc83VXuk6ZMgoueKdJ7hIb0EJ/MP7p3S1w8sG64qJxhRm2SG9gaF/b1tE+a+4xk2qrNQWAwyLofYzQY5E3slzkU7ZpRqWib3AB3j/O/Z9L+u/T0G3EpoYqVwH59JedipLSMhy/knH7cnc+l3PjwNrrCX+5uzg11c+4AgPsn9HAZlaIGKdeA+Bj/1ihSE4OcgPP/rDTKLquQ2NbiosOREBcJo8GApyT0EnRum4irR6Uqvl5CoIYAOKdzdWaRcLFq2SQOj9/YO+hrD/3f3b6PR5dLaqM+Mlz8ex/Yzb9elJSWCZj/8Aif1yMwQP7485ioMNx3eXfMmjIUCecyYl0zKhXxMeG4XmbQHWgdWsTj4evSMW5wW7cNZ2d3X9rVcY6Xwh3DSqQadveNPXJdut/bdpbYINLzHC+Z/Inx0lMb+34OdXPcL+xf+9u57rwA190ANpaHyczwduUI8eyJcosY6Js8SQlReO72fhjk5UbMs7f19fi8s8kTejhkxfT0MYJ142ZMX9cboJ1aJeCJm3rjjfuHwLmUT90s7zNbyfo89i+Vedpyu46Qz+oK4O2a5a6onVVaB9H51GM/QMVdAD+2n37XGGKQE3Def43+nrbs1yNIaZmAthLynstx64XKjQP2Rux84TV7icgh9nTekXoxdM7g4vV91i5xu9fJydTkC/tueykVaXD3ZkgTufPVpW0i7rqkK/7vLv+CMuscGMkNDtdOOiT5kCzAvsv9wgFt8MYDQ9FMhfkngN3ipSLHoFu7RpgwPEXS0EcDaof92fe4qr/6iXRd2zUC4FsgJTo375zoyDB0badOA8ETX+NF+9+KtcHUTMIq91p1s4R5I2P6tMKLd/bHHRd3kZw8xWtj0s3xn/XAULx63yBJ+1CCu3O+u4xg8THhuHhgXSPS0+cMVm+9u974jq0a2m4mKSLYPVMK7c/fe0P9uzRFjIpzaO3Z17eGbjI7SlmrSasY5KhodO+WAIArR4hnKpOiZ0qSa4NJ5Afo6x3bhY+OxIj0lj69V4zzXT4ppfK2Jki75q5d5Uqcy6Qs3CYmKsL9ycs2Dl9EP5HFGqU0GKSaMWkw7hrXVXQMrsFQO+eohYzhRYpcL0QqwMv3DPLYyJUiGJOwG8SEY+b9Q3BB/7phcgO6JtcNP/E3IhH7CBpY5DGQ3C1M55zu/D8ehuZqhS+NGGueDEmZvzSoc5uGknq3xvRthZZN4jC0Z3O3AX+a03fu6zUsPjZCdLmDYP6SBnZNljR3xBvnMjdNdB8MR7jpsZfC23eo1OlVzma0NFwzzMMaaPbZTwGIVjRr5kxfj6OSa1CF+JQcBjmB574G3Xh+J8z+zzD0Sq0bH+68grXL1oJcIZUY0hYbFYbLhrbHnAeHYWx/+ztWrq8Vmzzv0KUt8p5xg9riqpHSA0UpDeCYyDCXCdPeutatawF0bJWAEektcO1o17thozKkB4xTr+2FkTImLrZwmuvTx2nFcbkTwNUSZjIi2kOgaCW30ROIdNIN4yLRxC6Bxz3ju/kVYD13m/vUskBwGmaXDPJ+Z90hC57Ix03ysa49eG6tlouchjzeNNYx2A8PM6G9yM2NYHJNxVr3d9vkBrj/ih6StmNfX6znmNiocMx9aLhoUhVJ2/TpXf6/2d0NHl+uI5cMaud7QRTSIEZ+Y1Ls8E0c381Dz7JvB3zKVT09Jpt56ua+mgoMxMiakyPS6+8sQSSTmX3WQyWG+yUnRuNWu5uPrnPx6v52d4lS89zlml1N67XEPwxyVGQwGFzW+vAmTspJV2N1tk1yA1w2tL1LGlbnE87ES7uK9iQ43OmzJh6weygi3OQwAdi6def3iDwjj5s3vnLvIDx9S19btjqDwYBbL+yMC/o7NtTcrRfSMyVJpPxAx5YNXU5A1h6OHh2SEBluQnpqYzx9S18M7dEctzqllhZbZ0UKT2mc7SdGe2pw+1sFBTdb796+ke/b9DNCMBoMeFjkbuzwXi0wKqMl7p/g1Kj14SA4DF0S2UCgO3IaxUfiiuHicyTszZs6wvZ3g2jHc9Jzt/XDf+/sL2u/zRrFYOb9QxB/7vw2uHtzvOjD0Mm2AR4eas/Td/Hc7f3QqqnnG1Zi7L//6MgwvHCHvOOoVTPvH+KQNc9bNU5tleBy/vKlMXbXON8Xarx7XFdZ6e+tFF3XxsNzDTxMBp83dTha+1D/AOAmd4mO3HyuCInXGf/T19ft391vz7mEN4zpqOhvqHFCFF6+Z5DHz+JcBrHDNuLczUtfh7P37iSeoMT+2u0ue66nmzNi1Br2rRRtDAqshy4a6LlHw9nkK7qj4GylSyYW0QapTke0DOzWDN07JCGvoAxDejRHYoNIhJmMEFvqxFMDQ4D8Hq+E2AgUlVbZ/i1nga+mDaP9SsdtTXu6cNkur6+1DtN58OqeMFsEhJmM6NAiHB1aiNwZknAMDIbaY2mfoebR6zPwzve7cOPYNMz+eofD6y8b0h6b9+V533AQSFrETKH2xr2XdUPntom2Rri9MJNRfFihxN/hJYPaYu/RApdhDgaD6zaSPczVGNQtGWt35UjbqZ/Cw4yYOL4rzhRVILWV49AqX+YEvjRxoMtjyR6G4rjTvUMjZOWclfEOkYOsoJcmDkRJWTVeWrRZ0uudh2752pOjlBmTBmPF+qNYufk4gNr5kWmtG2LTvjx8+cdByduJiw6X1+iW+JU0T4rBqTNlos+NSG+Bwd3lJUGw19ppVIUSSTrEeDpHWUcHyJEQG+FxyLQ3o3t7z7pqX+anbpGWdODxGzIwc/E2HM8r9alcvpzLR2a0VDTBkuhQb+d/O71m0hU9MPvrHSgprwZQm+DHOnc1OjIMSfGROFNcKasc145ORftmDbB6+0kcOllsezw+NgJTruyJqAgTkhvF4I5Xfpf1mZwD1gev7onUlg1llU1rGOSo5OqR4hP73HWnukudem2gs/AEkshHjYsOx8PXOaZVNFsssjbr7VIkdrK0f89153UUTf3ob3u5lZd5JleOSMG63Z4bqdax5QaDwe/V2gHgf/cMwp6sAoeMQZ1aN8RrkzwvfAoA0QFsgLn7Hdh/T0o1Orq1b4RdmfkeX9NfZDV5pe7XxsdE2LITHXXTQH/ipt44nluCbu3c92TdfWk32UHO6N6tsGFPru3fgiD9c1mzKQaq8ac1DWLCcbas2u3zYsetWaMYwEvno1jiAXf/tmruJeOkvU6tG2L/sULJr7fXKD4K14xORfOkGHRum2hLf3/hgDYuQU5sVBiuHuV+2LDBzd9SidWz6XcPdNuQ87daKvH7Hj+knU9rf71wR3/k5JfJS4nthaf5O1I0t7ujb39+lnodahgXidF9WuHjFfsk73NU75b4Y8sJl8ebNJQ2HFZ0KJk/9ULKR3UYRCIgtWUC3pwyFHf+7w/rgw4iwuVfRyPDTRjWqwW2HTztuGuD95tMzr8LgwG4amQKyipq0NjpZm3HVg196s3UEg5X0wBfx4l2a99I8QU9tUjs+Ihd+/ukNUGLxrFI83Jh8JYdZmy/1qKThn0dhjD74ZEYkd4C91zW3faYNVuJ/RC2pISooGYBAoDGDaMxrFcLWXe7bhjTEQO7JiPDTZe5J53bNAzYYqjeNE6IwiWD2rokeBAbgqY1HVs1xKjeyq9q36l1Q8y833tA60mgxnRrbaj4jEmDMWvKULtHHFsLSoR6UtcbflxGUpT/XNXT4xwpbymPw0xGjOrdyuP6Xp3bNMSb/xkmeQ0wb8cqEPPnlDRj0mDR3kdn7ZvH+7QuWuumcbZFvp1ZEwo4z8H05smbfD/vjh/SDqN6K5eAqI7nCm/fk+mctfSe8d3wxE2+JQdydt/l3b2/CHWltVjqarCkTJl2hZdzg0IuX0+ZFw+UN69ZT/QdooWgxAaRModb6JfkH6RYz4vIVXLyFT0gCAIMBgOqa9z3/gzp0QxHss/iz611d4gC2Z5q3yIBd47rihq7Mj1xY28sWX1Y0vwHrRnTtzab2K8bj7l/kZsD2qxRjMfFHuWQ27i++9Kutp6wjRK68dVmHUoYaA2dgn6lgxafUyt7+VVeP6YjXvpkM8YPaYdl/xwB4NtdUanCw0wID6vbvlLfjf2nlNJgAqTPgwBq65GnFLDtmikzCdrbyulyqtUNY1znhcitl15f7sf3JzWJSyAC9dlThqHGLMi+w+5rRq7YqDBcPszpOuXj55IyX8X9ex1f7EsPmb1u7RLRLCkW5/dt5TBU3WMZzhXYbBfkmJzG07v7SE/d3AfbD532eR05KZxvVt5+UWes3HwcfdOaYMlfmQBc57v628OqdezJ0QK7mnXxoLYY1K0ZplypbIrUiDBt5jlXug1nPQl5OnmajEbcckGaQ5riYA+4aZPcAP+5upfLxEP7nh2TAsPRrO69rJti2woGd5O27Y+I3GFSYmlknXVtl6hc76gOrxiBHnr2xv1D0FAkA5IvUlsmYOGjI3H5sA7o36UpIsKNGJHeAk/d0geDuklbmNj6u/Bl4VjF0rg6jIl3f57WcnVqouCIgnGD2/l0bN0lK7GypiEf4mUxz7rtBYfcQCgi3KT6Giu+1kX7oVT3T+ih+ILkzjzdKGkUH4Ubz++Epom1N97G9JE+F8niEOQ4DTF1kyAhpWUCJgxPcbhRUvt+5Y7BvZc59kgN69UCL9zRH4kN7IJyuZkHdI49OQEmpf7YvyQq3IS7LxVfddYX14xKRUVVDZLcLESmJqm/LYeGrcT3KrYydJB//zFR4Zh6bS+YjEZFLwBic0p8IfXC77aRIvFLv2pECqLCTejf1XHIRqAbHvExEfjPVT2xJ6sQ/x4+g9/OTbi2d/mw9lj6VyZuvqCzyBbsSC2sm0NigMFrw01pznXusqHtsWV/Ho7llnh8n8logNkieF3TKiEu0mP2Pgd2L4tzk0nKWt57xnezJeKIj4nA0ZwSrN2V7XUXvTs1wYJHRrg0PDy57/LuyCssd0kD6+upwr7B5GtGRDVcNLANNuzOQZd2jXC1m8Uj3ZJYrf1pfznH6/dP6ImdmWdsSzaondShPmrXLB4PX5uOpIQoSVm7rDemIsKMirTFrxyRYptL5jwX7obzO2H7odPIK6xw+37rKASz4GG4msxy3jWuC978egcuH9YeH/y4V96bnbibj2N/rD3+9EIw3mGQE2Bqz8kNZNeoVO5PTtJ+UcHI4+52Dyp8f93bS8/splXjBrVDbkE5BjgFV7ES70DGRIXhGpF1hoIhPMyEnilJ2HesQPT58UPaY2y/1n5lMJIkiBecey/rhq/+OIRJVzjeCezSNhGXDW3vNUvPM7f2xXd/Z/q1sLEzo8GAx2/IQGW1RTSrnT3nRByDuiXj5w1HkVtQ7nU/cgIcQHzRXn/UmOuGsXqaxG1/KpJzE0fuDR+pr756ZKrbBDr+bblOfEwEBnZLhgHul1uwziX3NkclJirM4WZPQlwkbhrbCb9sOIbcQtd6oszPz+0dDLs/ZexJ5vXIZeK9vLdL3q4c3USWAeiVkoRfRIY/h5kMmD91BIxGae0Al8Pj9JYL+rfGT+uzcLasGsN6uq5B59xeu/mCNPy1/SSOZNdOIbCufSdYPHwRMr+jNskN8Prk2nmR/gY57qS2SsCdl3RBs6QYLF192OG5EIxrHDDI0YAQ7y1UlC/zeOpH7qdandskil4slCL1+EdHhmGy3WKId4/rivV7ckTXA9IqT40PSQGOBn7XUntN+ndJ9qu3r01yAzzgZoitP71RaW0SfXpfVEQYXp44EAuW7cKGPbno2i4Ru4+IB61imviQiSomKhzFHrKvuWN//g/08B01+fo5J17qeajtc7f3w4r1R3G50/xGKdfV0b1bobS82jZfwZ7cNez0wJdfoniiHu8HN0XG3Msu7Rrh6Vv6YvnaI9h6wDFjmKf5ZHIZDAbMvH8IikurvfY6A7WLd7dpGofpn9SmgI86N5zc7CnIsaP2TW57Q85ljPU0Wk0DlyzFMcgJsIAGMFr6BfnAl2Pj5wgg2a/R26++V2oSHry6J1o2jsM3qw8FdF/uhhCJGdS9mUOaarVNvqIHPvxpD+4ZH8C5SiqnsL18aHtNNNSsd9jryhKcH5XBYMDtF3VBesfG6NmhMZ5cuBbFZdVoLGHobnJiDKZe28trD5K9SVd0x7s/7HadpO1F44RonN+3NqOj5Ma/t0OowdnEYSYjLh/WHhVVZkWHT7dJboCJIr9judnH7E26vLvXLJz2jAYDLL5n2NDkqvOPXpeOZf8cwS0XiqwB5sU947uhb5q87JsdWsQrfr4SO6omo1FSgCO2EbHsap4Ee7gxuWKQE2DSMqBo7wSnJJ3HYg7c5e0PpIeu6YUPf9qLOy7xvnq3wWBAz5TGQSgV0L9LU+zNKlBsLQdPk97TWjfEvmOFGJne0uuaNlL0SWuC3p0a2xoXlwxqi5Wbj+OyYe1tr4kMV/euusGPRR16piRh/ND23l8YBBHhJsyfOkLRRBpSRUaYbOv5PH5jb/y0/ijGDZLWmyh32GirJnF4/nbfVlf3JfGBHDed3wmvfr4V44e0A6DeFWf8kMDXyadu7oNdmfk+pzxu37yB2/TNzh68uhcOnyzCydOl2OTHIsmpLRPQsVWCX2vZDOyajHW7c3CJh/ot53vv0q4RurhZl0ssJrMuzGqA/5nPtESsRz/c07XB7uX+DGm2fp9K89Qe02Kw7S8GOQF2z/huWLhsFy4d0h7v/7gH5ZU1ahdJUVr9TcgtV3JitKQ0kjee3wnn9W6F//t4EyqqzD6WTp4eHZJsY3a1xGQ04vaLvQdeSnj4unScKapAsoTJqlLZn9CvHJGCK4Z1cJhEOqZva+zMzEdfNwvxet+Boi9ThVK/b09DTsb2a63MTrxonhSLO4JUXwPBn6+ic9tE2QkW9CqlZYKsoVL+6JmShJ4pSZi3dKfP2zCgdvL6E36sYwMAd43rikuHtJM0oT8QplzVE9+uOuwxyAo2uY12bzdkrdvr2q4RBnZNRms3WUBvviANRSWVaNnY997EYAnWb0UtDHICrEXjWDx/R+3dvfd/3CP6GqUDhatHpWDGF9uC1njwxt3nC2yAJG/jE8d3w5d/HMT5fT0fM6PBgBaNY3HVyBQs+mU/RmUEYoE07YpQOCNRVKS07YWZjIoGOGKcs+RER4b53fCQwv66muBnWuJ+nZti495cXNhf/YQjUrzxwFDEyxj2SLXknN2sr60PAY5PnC5ESiYUkZRdVaHroNFo8GnhUaUkJ8ZIXlRTu1yjHLHvx2gwiA6RtFKiXSClD1+JnpdQngcIMMgJMu/VVomRXV3bNcLch4ZLXizsgQk9sO9YocOE9WaNYtClrW+TfvWoUXyUS455T0b3boWeHZI0mZo7UMYPaafYGjL3jO+GXzYexS1j0/DY22sV2abWTLy0G+Z8+y+uO0/6UKSEuEg8fF06miSJ3yH05t7LuuGmsZ3QQMZcEk8US8Xuhr9BHYUi9cY3t2kah1vdzEFRq4ekPtHqyBBZFKy+PTok4d/DZ5TbIDwPCw+J4++EQU6IkrMackanJsjo1MQW5BgMwPS7B0i6S+DPb8IAg88nhBaNY3HgeJH7bdtnV/NjUlByovsLW2MFF8ALBMUWtQTQrlkD2ROqPRnQNTmkxm2LkboGSzuntQ16pTZGYmIsCgpKZe/TYDAoFuBQ4EhOoKJAlshQa7hcd15HfPHbAVwjd20eN3p0aIQlqw8jIsxoG3Vh77nb+uF0UYXLws3KUf8Lsl8YW0tio4Lby6u16cP/ubonKiprcP+svxTbpqeFdp2bSqFw7mCQowFarEhKTkCz/+EotdV7xnfDktWHMcbL8DJP+qY1xfG8TDRp6L43Ji46HK/eOwgR4fob6nHxwLYoq6hBRid5WW7EKLmieX3iKcCZfvcA5BSUo2Orhj5vf2C3ZKzblSN5ojSpr03TOL8yfwEBvmZo8Hpkb2y/1hjULVmxYL5ds3j8987+bjNutW3WwO0ii95o7lC6KdCg7s1QVlGD1FbS5mcY7SpgbIAyOA7v1QLpHWUm0QlAlKJm+8xoMCAmKhzTbuyNVz7dosg2rzuvIzbsyfX6uvTUxoFfCy4I9P8JSL/8OHk0io/CneO6+rX7iwe1RYvGsejUpqHH12m9x8adiHATbji/k1/bePyGDKzafhLXjQ5s9ic5xvRphZWbj8tfZV1jmifF+j2G/rYLO6N/52R0aReYoaXW9WIuGdQWy9dmBWQf9c2zt/dzaCSSfEr3VrZq4tvwUKtgfZuBSklsNBhwvow5vEajAQ9fl45qCQv1yiqHsW5+yG0XdVZsu1KJDfqQO2S3Q8t4hUpTp1Prhmib3ABZOWf93lbDuEiktkrAQQ8jYQD4lDpcixjkBJG7UVO+jnvXWteqVYcW8Th8stj2b089JXJJXdxQShsizGTkHXAv0tok+rwgY6BcP6YjLhrYVt5aByEqItwk/26nBK/cMxDllWbbnJlB3ZoxyFGInAAnOiIMJqMBFovgNMzE8zYMHv5F+tO/S1Nk5ZSge3vxlM5StW+mXAO8m5v00v4YP6Qddh4+gxHpLRTfdqC9PHEgDp8sVmwYtvMwe0UDXDeb8mdov1YxyCEXMTLm84h59PoMHM8rQWWVGWt2ZuOqkXV33H29gXlh/zY4XVzhMn+B6h+DwcAAJ8CaOs1Fa9E4Fk/d3AcJcZzvE0xGowFzHxoOAUB+cYXaxSG5FIov772sOwRB8HsYeaumcXjipt5IlLHQaTA1jIvEq/cNVrsYDpIbSRvJkdwoJuAZQD154Moeim4vVG6NMMgJIrcxskZq08PXpuPLPw763U0cGW5CSovasb1dne72JDeKQec2DREbFS7rjuY1o+UNTQp0VijSB9YC5YT6egpa5e98QI6M0x5fvhKl5sn6MwewPoqKCMPs/wxDmAqLGTvw0smS0dH/ubeh14/DIEdz5HQXOq/r4a9u7Rvhhfa+rdgtldFgwGM39A7oPkhfwkwG1JgFdPNzKAZRfcHARVsmjOiAfw+f8SsRTiCE4gr2Yto2a4Cs7LMY2C0ZLRvHuV2T0Bt37a+4ACVX0LQQqTsMcjRAblW68fxOWLE+CzeO8W9SeSgzGID4mHCUVZqZGUzjXrlnEA6eKELfNM6PotA0pHsz/LMzG8N6Nle7KBQAyYkxmPPgcJcbj+6uPfZZq0KkLamqR69Lx56sQvRMSULmqWLvb3BDyz0ZYmWLi/atCd/A3QLMWj4APmKQE0TjBrXFN6sOY6CfE9PO69MK5/VppVCp1JXWpiGaNYpB8yRlx7IaDAbMmDwEgiCE/Iq+etcoPgr94wOzqGp9uZOpJ/XxK7nlws4Y3L0ZUjlUyCu9zn22D3Ceva0vikur3a6zFh8bgTsu7oLwMCOvTwqIiQpHn7Ta4Vr16fwyYUQK8gorMKyXvJsnN41NQ0WVGWM8tCND5TAyyAmiiwe2RY8OSS4Lb9XnhliYyYj/u3tAQH5QvHgQac/153XEW9/+iwv7t1G7KEETHmZEFz+zUQXrOsH01v5rJyGL2VD26mmPhgNsseA/PiYCj16fIXtbiQ0iRd+n4Y/vM7YCg8hgMKBNcgOYjCF02BW4IBoNhnod6BHVJxmdmmDOg8NkJxMh5TROcN9zetHAtkiKj8S4we2CVyAKiJvH1g5pv2J4B5VLEjz+JB2q70PbYyLrkpxER+pvAXQx7MnRmKiI0KhYRETuxETVw4m8wWR300js/tHkCT3w+coDuGRQW5fnEmIj8Op9g3njKQSktUnEwkdHclSDRBPHd8Vj89eqXQw3At/PEh5mwv/dNcD2dyhgkKMRt1yQhpLyapf1KYiIiJSUnBiDB6/u5fZ5Bjiho94FOH5U3cYJ0YiJDENZZY1y5dGZFo1jvb9IRxjkaMTIjJZqF4GIiEIM1wyj+qR1kzgA+k/77DwHJxTnywQDgxwiIiKNqy+hSioXnSU/REaYMG/q8JDrwbp0cDu8/d0uDPAzO299E9Ag59lnn0VVVRVeeeWVQO6GiIgopMXHRtj+VnohaC145d5BOJFbgp4pSWoXhXTOfh0iuVJbJWDHoTOI1Nj86P5dkpHSIgGJ8ZFqF0VXAhLkWCwWzJo1C4sXL8YVV1wRiF0QERHVG9GRYfjvHf1hMhnkpXnWSTzUtGE0mtbz7Fakvjsv6YJfNh7D0B7qpvhukxzn8liSh6yIJE7xIOfQoUN46qmnkJWVhRYtWii9eSIionqpVVPXhg8RKadBTASuHJGidjEwtl/9WUcskBQPctatW4eUlBTMnTsXDz74oGLbDQtTf3yl6dwYT1OIjfX0h8lu2IQWviOtYZ1Rl8HusOulfrLOkFzOdSbMVHdeDg8zMlsaueB5RrsGdk1GdJS2pszrtb4ofhRvvPFGpTcJo9GAxETtpLWLj2eXutXo/m3x4U97kdq6oaa+I61hnVFHr45NsXX/aQDQXf1knSG5rHWmpMpieywxMZZBDrnF84z2RESEafZ6pbf6IivIOX78OM477zy3z69duxaNGjXyu1DOLBYBxcVlim9XLpPJiPj4aBQXl8Nstnh/Qz2x4NGRiAw3oaCgVO2iaA7rjLqG92wGwWJB13aJuqmfrDMkl0udMZttzxUUlDLIIRc8z2hXZVWN5q5XWqsv8fHRknqVZAU5ycnJ+PHHH90+n5AQuNSPNTXqH1Qrs9miqfKoLdxkhMUiwGJhJnd3WGfUM6JX7dxAvR1/1hmSy1pnosJNeOrmPggPM8JsFsBVNsgdnme0RxAEzX4neqsvsoKc8PBwpKSoPyGLiIiI3EvhejNEVM/pawYREREREVGIEtjxqhgGOUREREREFFIY5BARERERUUgJaCLuTz75JJCbJyIiIiIicsGeHCIiIiIiCikMcoiIiIiINIB5B5TDIIeIiIiIiEIKgxwiIiIiIgopDHKIiIiIiLSAC+UohkEOERERERGFFAY5REREREQUUhjkEBERERFRSGGQQ0REREREIYVBDhERERGRBjDtgHIY5BARERERUUhhkENERERERCGFQQ4REREREYUUBjlERERERBRSGOQQEREREWkBMw8ohkEOERERERGFFAY5REREREQUUhjkEBERERFpAEerKYdBDhERERERhRQGOUREREREGmBQuwAhhEEOEREREZEGcLiachjkEBERERFRSGGQQ0RERESkAYLAvhylMMghIiIiIqKQwiCHiIiIiIhCCoMcIiIiIiIVNU6IAgD069JU5ZKEjjC1C0BEREREVJ89f3t/nDhdgtSWCWoXJWQwyCEiIiIiUlFMVBg6tmqodjFCCoerERERERFRSGGQQ0REREREIYVBDhERERERhRQGOUREREREFFIY5BARERERUUhhkENERERERCGFQQ4REREREYUUBjlERERERBRSGOQQEREREVFIYZBDREREREQhhUEOERERERGFFAY5REREREQUUhjkEBERERFRSGGQQ0REREREIcUgCIKgdiG8EQQBFos2imkyGWE2W9QuBukI6wzJxTpDcrHOkFysMySHluqL0WiAwWDw+jpdBDlERERERERScbgaERERERGFFAY5REREREQUUhjkEBERERFRSGGQQ0REREREIYVBDhERERERhRQGOUREREREFFIY5BARERERUUhhkENERERERCGFQQ4REREREYUUBjlERERERBRSGOQQEREREVFIYZBDREREREQhhUEOERERERGFFAY5ElgsFsyePRvDhg1Deno67r77bhw7dkztYpEKFixYgJtvvtnhsT179uCmm25Ceno6Ro8ejY8//tjheSn1x9s2SF8KCwvx7LPPYvjw4ejduzeuv/56bNq0yfb82rVrMWHCBPTq1QsXXnghli9f7vD+yspKvPDCCxg0aBAyMjLw8MMPIz8/3+E13rZB+nLmzBk8+uijGDhwIDIyMjBx4kQcOnTI9jzPM+RJZmYmMjIy8O2339oeY50hZzk5OUhLS3P5z1pvQq7OCOTVW2+9JQwYMED4448/hD179gh33HGHMHbsWKGyslLtolEQLVq0SOjcubNw00032R7Lz88XBgwYIDzxxBPCwYMHha+//lro0aOH8PXXX9te463+SNkG6cvtt98ujBs3Tti4caNw+PBh4YUXXhB69uwpHDp0SDh48KDQo0cPYebMmcLBgweFd999V+jatauwZs0a2/unTZsmjBkzRti4caOwfft24fLLLxduvPFG2/NStkH6cu211wpXX321sH37duHgwYPCAw88IAwdOlQoKyvjeYY8qqqqEiZMmCB06tRJ+OabbwRB4LWJxP35559Cjx49hJycHCE3N9f2X3l5eUjWGQY5XlRWVgoZGRnCp59+anusqKhI6Nmzp/D999+rWDIKluzsbOGee+4R0tPThQsvvNAhyHn77beFoUOHCtXV1bbHXn/9dWHs2LGCIEirP962Qfpy5MgRoVOnTsKmTZtsj1ksFmHMmDHCrFmzhGeeeUa46qqrHN4zdepU4Y477hAEoba+de7cWfjzzz9tzx8+fFjo1KmTsGXLFkEQBK/bIH0pLCwUpk6dKuzbt8/22J49e4ROnToJ27dv53mGPHr99deFW265xSHIYZ0hMQsXLhQuvfRS0edCsc5wuJoXe/fuRWlpKQYNGmR7LD4+Hl27dsXGjRtVLBkFy65duxAeHo5ly5ahV69eDs9t2rQJ/fv3R1hYmO2xgQMH4siRIzh9+rSk+uNtG6QviYmJWLhwIXr06GF7zGAwwGAwoLi4GJs2bXKoD0Dt971582YIgoDNmzfbHrNq3749kpOTHeqMp22QviQkJOD1119Hp06dAAD5+fn48MMP0axZM6SmpvI8Q25t3LgRixcvxiuvvOLwOOsMidm3bx9SUlJEnwvFOsMgx4vs7GwAQPPmzR0eb9q0qe05Cm2jR4/GW2+9hdatW7s8l52djWbNmjk81rRpUwDAqVOnJNUfb9sgfYmPj8eIESMQERFhe+znn39GVlYWhg0b5vb7Li8vR0FBAXJycpCYmIjIyEiX13irM9ZtkH4988wzGDRoEJYvX47p06cjJiaG5xkSVVxcjMceewxPP/20y3fPOkNi9u/fj/z8fNx4440YPHgwrr/+eqxevRpAaNYZBjlelJeXA4BDgwUAIiMjUVlZqUaRSEMqKipE6wZQO3lcSv3xtg3Sty1btuCJJ57A2LFjMXLkSNHv2/rvqqoqlJeXuzwPeK8z9tsg/br11lvxzTffYNy4cZg8eTJ27drF8wyJev7555GRkYFLL73U5TnWGXJWU1ODw4cPo6ioCA888AAWLlyI9PR0TJw4EWvXrg3JOhPm/SX1W1RUFIDahoP1b6D2y4qOjlarWKQRUVFRLo1K6w85JiZGUv3xtg3Sr5UrV+KRRx5B7969MWPGDAC1J3zn79v67+joaNH6ADjWGW/bIP1KTU0FAEyfPh3bt2/HokWLeJ4hF0uXLsWmTZvw/fffiz7POkPOwsLCsH79ephMJtt33r17dxw4cADvvfdeSNYZ9uR4Ye2Wy83NdXg8NzcXycnJahSJNKRZs2aidQMAkpOTJdUfb9sgfVq0aBEeeOABjBo1Cm+//bbtblbz5s1Fv++YmBg0aNAAzZo1Q2FhocuFwr7OeNsG6Ut+fj6WL1+Ompoa22NGoxGpqanIzc3leYZcfPPNNzhz5gxGjhyJjIwMZGRkAACee+453HXXXawzJCo2NtYhQAGAjh07IicnJyTrDIMcLzp37oy4uDisX7/e9lhxcTF2796Nfv36qVgy0oJ+/fph8+bNMJvNtsfWrVuH9u3bIykpSVL98bYN0p/PPvsML774Im688UbMnDnTofu+b9++2LBhg8Pr161bh969e8NoNKJPnz6wWCy2BARA7RoYOTk5tjrjbRukL6dPn8bUqVOxdu1a22PV1dXYvXs3UlJSeJ4hFzNmzMCPP/6IpUuX2v4DgClTpmD69OmsM+TiwIED6N27t8N3DgA7d+5EampqaNYZVXK66czMmTOF/v37CytXrnTIC15VVaV20SjIHn/8cYcU0qdPnxb69esnPP7448KBAweEb775RujRo4fw7bff2l7jrf5I2Qbpx+HDh4Vu3boJkydPdliHIDc3VyguLhb2798vdOvWTXjttdeEgwcPCu+9957LGjdTp04VRo8eLaxbt862To59vZOyDdKXu+66Sxg7dqywYcMGYd++fcLUqVOFfv36CSdOnOB5hiSxTyHNOkPOzGazcOWVVwoXX3yxsHHjRuHgwYPCSy+9JHTv3l3Yt29fSNYZBjkS1NTUCK+++qowcOBAIT09Xbj77ruFY8eOqV0sUoFzkCMIgrB9+3bhmmuuEbp37y6MGjVK+OSTTxyel1J/vG2D9GP+/PlCp06dRP97/PHHBUEQhFWrVgnjxo0TunfvLlx44YXC8uXLHbZRWloqPPXUU0Lfvn2Fvn37ClOnThXy8/MdXuNtG6QvxcXFwnPPPScMGTJE6Nmzp3DHHXcI+/fvtz3P8wx5Yx/kCALrDLnKy8sTpk2bJgwZMkTo0aOHcO211wobN260PR9qdcYgCFxUgYiIiIiIQgcHbxMRERERUUhhkENERERERCGFQQ4REREREYUUBjlERERERBRSGOQQEREREVFIYZBDREREREQhhUEOERERERGFFAY5REREREQUUhjkEBERERFRSGGQQ0REREREIYVBDhERERERhZT/BymT6FW9ZotoAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"QTable diffs over time player 1\")\n",
    "sns.lineplot(data=diffs[:, 0])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"QTable diffs over time player 2\")\n",
    "sns.lineplot(data=diffs[:, 1])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Expected rewards over time per player\")\n",
    "sns.lineplot(data=expectedRewards, dashes=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
