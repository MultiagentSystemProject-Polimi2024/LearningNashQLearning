{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nash Q learning basic implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nashpy as nash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 4#Number of games\n",
    "N = 2 #Number of players\n",
    "A = 2 #Number of actions per player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player1 action / Player2 action / starting state / ending state / probability\n",
    "#Player 1 - column player - 0: .3, 1: .4\n",
    "#Player 2 - row player - 0: .1, 1: .2\n",
    "TRANSITION_MATRIX = np.array(\n",
    "    [\n",
    "        # Player 1 - Action 0\n",
    "        [\n",
    "            # Player 2 - Action 0\n",
    "            [\n",
    "                \n",
    "                [0, 0.5, 0, 0.5],\n",
    "                [0, 1, 0, 0],\n",
    "                [0, 0, 1, 0],\n",
    "                [0.5, 0, 0, 0.5]\n",
    "                \n",
    "            ],\n",
    "\n",
    "            # Player 2 - Action 1\n",
    "            [\n",
    "                \n",
    "                [1, 0, 0, 0],\n",
    "                [0, 0, 1, 0],\n",
    "                [0, 0, 0, 1],\n",
    "                [0.5, 0, 0, 0.5]\n",
    "                \n",
    "            ]\n",
    "        ],\n",
    "\n",
    "        # Player 1 - Action 1\n",
    "        [\n",
    "            # Player 2 - Action 0\n",
    "            [\n",
    "                \n",
    "                [1, 0, 0, 0],\n",
    "                [0, 0, 0, 1],\n",
    "                [0, 0, 0, 1],\n",
    "                [0.5, 0, 0, 0.5]\n",
    "                \n",
    "            ],\n",
    "\n",
    "            # Player 2 - Action 1\n",
    "            [\n",
    "                \n",
    "                [0, 0.5, 0, 0.5],\n",
    "                [0, 0, 1, 0],\n",
    "                [0, 0, 0, 1],\n",
    "                [0.5, 0, 0, 0.5]\n",
    "                \n",
    "            ]\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSITION_MATRIX[0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state / player1 action / player2 action / [player1 reward, player2 reward]\n",
    "PAYOFF_MATRIX = np.array([\n",
    "    # State 0\n",
    "    [\n",
    "        [ [2, 1], [0, 0] ],\n",
    "        [ [0, 0], [1, 2] ]\n",
    "    ],\n",
    "    # State 1\n",
    "    [\n",
    "        [ [1, 1], [3, 0] ],\n",
    "        [ [0, 3], [2, 2] ]\n",
    "    ],\n",
    "    # State \n",
    "    [\n",
    "        [ [2, 0], [0, 2] ],\n",
    "        [ [0, 1], [1, 0] ]\n",
    "    ],\n",
    "    # State 33\n",
    "    [\n",
    "        [ [1, 1], [0, 0] ],\n",
    "        [ [0, 0], [2, 2] ]\n",
    "    ],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAYOFF_MATRIX[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_probability(state, player1_action, player2_action, next):\n",
    "    return TRANSITION_MATRIX[player1_action, player2_action, state, next]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(state, player1_action, player2_action):\n",
    "    return PAYOFF_MATRIX[state, player1_action, player2_action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "State: 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "State: 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 2\n",
      "Reward: [2 0]\n",
      "State: 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [1 1]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [1 1]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 3]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "State: 3\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 0]\n",
      "State: 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "State: 0\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "Total reward: [0.814 0.802]\n"
     ]
    }
   ],
   "source": [
    "state = 0\n",
    "totalReward = np.array([0, 0])\n",
    "n_games = 1000\n",
    "for _ in range(n_games):\n",
    "    print(\"State:\", state)\n",
    "    player1_action = np.random.choice(A, p=[0.5, 0.5])\n",
    "    player2_action = np.random.choice(A, p=[0.5, 0.5])\n",
    "    print(\"Player 1 action:\", player1_action)\n",
    "    print(\"Player 2 action:\", player2_action)\n",
    "    next_state = np.random.choice(range(Q), p=TRANSITION_MATRIX[player1_action, player2_action, state])\n",
    "    print(\"Next state:\", next_state)\n",
    "    r = reward(state, player1_action, player2_action)\n",
    "    print(\"Reward:\", r)\n",
    "    state = next_state\n",
    "    totalReward += r\n",
    "print(\"Total reward:\", totalReward / n_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeNashEq(state, payoff_matrix):\n",
    "    game = nash.Game(payoff_matrix[state, :, :, 0], PAYOFF_MATRIX[state, :, :, 1])\n",
    "    eqs = game.vertex_enumeration()\n",
    "\n",
    "    try:\n",
    "        eq = next(eqs)\n",
    "        return eq\n",
    "    except StopIteration:\n",
    "        a = np.random.rand()\n",
    "        return [[a, 1 - a], [a, 1 - a]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([0., 1.]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeNashEq(3, PAYOFF_MATRIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 0\n",
      "Nash equilibrium: (array([0., 1.]), array([0., 1.]))\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [1 2]\n",
      "State: 3\n",
      "Nash equilibrium: (array([0., 1.]), array([0., 1.]))\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "State: 0\n",
      "Nash equilibrium: (array([0., 1.]), array([0., 1.]))\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 1\n",
      "Reward: [1 2]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "State: 1\n",
      "Nash equilibrium: (array([1., 0.]), array([1., 0.]))\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "Total reward: [1.001 1.003]\n"
     ]
    }
   ],
   "source": [
    "#Simulate plays with nash policy\n",
    "state = 0\n",
    "totalReward = np.array([0, 0])\n",
    "for _ in range(n_games):\n",
    "    print(\"State:\", state)\n",
    "    nashEq = computeNashEq(state, PAYOFF_MATRIX)\n",
    "    print(\"Nash equilibrium:\", nashEq)\n",
    "    player1_action = np.random.choice(A, p=nashEq[0])\n",
    "    player2_action = np.random.choice(A, p=nashEq[1])\n",
    "    print(\"Player 1 action:\", player1_action)\n",
    "    print(\"Player 2 action:\", player2_action)\n",
    "    next_state = np.random.choice(range(Q), p=TRANSITION_MATRIX[player1_action, player2_action, state])\n",
    "    print(\"Next state:\", next_state)\n",
    "    r = reward(state, player1_action, player2_action)\n",
    "    print(\"Reward:\", r)\n",
    "    state = next_state\n",
    "    totalReward += r\n",
    "print(\"Total reward:\", totalReward/n_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qTable = np.zeros((Q, A, A, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paolo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nashpy\\polytope\\polytope.py:109: RuntimeWarning: divide by zero encountered in divide\n",
      "  hs = HalfspaceIntersection(halfspaces, feasible_point)\n",
      "C:\\Users\\Paolo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nashpy\\polytope\\polytope.py:109: RuntimeWarning: invalid value encountered in divide\n",
      "  hs = HalfspaceIntersection(halfspaces, feasible_point)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.17496329090135054, 0.8250367090986495],\n",
       " [0.8250367090986495, 0.17496329090135054]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeNashEq(0, qTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectedPayoff(payoff_matrix, player1_strategy, player2_strategy):\n",
    "    expected_payoff = np.dot(np.dot(player1_strategy, payoff_matrix), player2_strategy)\n",
    "    return expected_payoff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2 1]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [1 2]]]\n"
     ]
    }
   ],
   "source": [
    "print(PAYOFF_MATRIX[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expectedPayoff(PAYOFF_MATRIX[2, :, :, 1], np.array([0.5, .5]), np.array([1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 0\n",
      "Nash equilibrium: [[0.96317722 0.03682278]\n",
      " [0.96317722 0.03682278]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[1.  0.5]\n",
      "  [0.  0. ]]\n",
      "\n",
      " [[0.  0. ]\n",
      "  [0.  0. ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.05712217 0.94287783]\n",
      " [0.05712217 0.94287783]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [1. 1.]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.86805056 0.13194944]\n",
      " [0.86805056 0.13194944]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [0 2]\n",
      "QTable: [[[0. 0.]\n",
      "  [0. 1.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.61789309 0.38210691]\n",
      " [0.61789309 0.38210691]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [0 0]\n",
      "QTable: [[[0.  0. ]\n",
      "  [0.4 0.2]]\n",
      "\n",
      " [[0.  0. ]\n",
      "  [0.  0. ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 1.11022302e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[1.51071006 0.75535503]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.23648528 0.76351472]\n",
      " [0.23648528 0.76351472]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [1.60428402 1.30214201]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 1.67722509e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[2.08760562 1.20992811]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.21489053 0.78510947]\n",
      " [0.21489053 0.78510947]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [1.5        0.09266987]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [1.         1.        ]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.75789416 0.24210584]\n",
      " [0.75789416 0.24210584]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.         1.        ]]\n",
      "\n",
      " [[0.64171361 1.0208568 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.78111306e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.63718426 2.13504225]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[3.09867651 1.95898095]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [3.37346583 2.92153802]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [3.74529944e-16 1.00000000e+00]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [3.92620352 3.24436139]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[4.11981967 2.77723503]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [4.53358317 3.91992525]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [5.08022485 4.52793273]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [5.18804029 4.37486038]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 2.28695933e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[5.13512595 3.63856167]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [5.66923626 4.93737434]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [5.88866851 4.92411184]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[5.92303038 4.28892557]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [6.29980166 5.43170065]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [6.66982149 5.88853059]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [6.7041229  5.65983552]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[6.64316435 4.90839699]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [7.00932719 5.79327656]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [2 1]\n",
      "QTable: [[[7.12531305 5.27150912]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [7.30839447 6.2139489 ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [7.50432246 6.2155781 ]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 3.9553433e-16]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[4.69899247 3.16719847]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.38515595 0.61484405]\n",
      " [0.38515595 0.61484405]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [3 0]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [1.         1.        ]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.         1.        ]]\n",
      "\n",
      " [[3.32258579 3.49665964]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [6.63175822 5.37466844]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[3.58669515 2.15333088]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.43996739 0.56003261]\n",
      " [0.43996739 0.56003261]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 2\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 2\n",
      "Nash equilibrium: [[0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 1.84440562e-16]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 0\n",
      "Next state: 3\n",
      "Reward: [0 1]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.         1.        ]]\n",
      "\n",
      " [[4.31399618 4.3981972 ]\n",
      "  [0.         0.        ]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 3\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [6.9685824  5.83720159]]]\n",
      "State: 3\n",
      "Nash equilibrium: [[0. 1.]\n",
      " [0. 1.]]\n",
      "Player 1 action: 1\n",
      "Player 2 action: 1\n",
      "Next state: 0\n",
      "Reward: [2 2]\n",
      "QTable: [[[0.         0.        ]\n",
      "  [0.4        0.2       ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [5.91896926 4.77993315]]]\n",
      "State: 0\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [2 1]\n",
      "QTable: [[[3.18995858 1.78440667]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[0.85198567 0.14801433]\n",
      " [0.85198567 0.14801433]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[0.54778931 0.51080977]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[0.99301038 0.95972879]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[1.39370935 1.36375591]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[1.75433841 1.72738032]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[2.07890457 2.05464229]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[2.37101411 2.34917806]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[2.6339127  2.61426025]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[2.87052143 2.85283423]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 3.98364873e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[3.08346929 3.06755081]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.27917325e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[3.27512236 3.26079573]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[3.44761012 3.43471615]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.78452017e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[3.60284911 3.59124454]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.99995755e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[3.7425642  3.73212008]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[3.86830778 3.85890808]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.36835545e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[3.981477   3.97301727]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.0833293  4.07571554]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.66675776e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.17499637 4.16814399]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.25749673 4.25132959]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.33174706 4.32619663]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.01150665e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.39857235 4.39357697]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.10424538e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.45871512 4.45421927]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.51284361 4.50879734]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.56155925 4.55791761]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.60540332 4.60212585]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.39128101e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.64486299 4.64191326]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.68037669 4.67772194]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.71233902 4.70994974]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.74110512 4.73895477]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.76699461 4.76505929]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.79029515 4.78855336]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.64786996e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.81126563 4.80969803]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.83013907 4.82872822]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.84712516 4.8458554 ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.86241265 4.86126986]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.87617138 4.87514288]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.88855424 4.88762859]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.78423185e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.89969882 4.89886573]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.90972894 4.90897916]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.91875604 4.91808124]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.82614526e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.92688044 4.92627312]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.9341924  4.9336458 ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.94077316 4.94028122]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.94669584 4.9462531 ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.95202626 4.95162779]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.87231696e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.95682363 4.95646501]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.96114127 4.96081851]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.88496658e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.96502714 4.96473666]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.96852443 4.96826299]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.97167198 4.97143669]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.97450479 4.97429303]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.97705431 4.97686372]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.90705036e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.97934888 4.97917735]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.98141399 4.98125962]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.98327259 4.98313365]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.98494533 4.98482029]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.9864508  4.98633826]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.98780572 4.98770443]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.98902515 4.98893399]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99012263 4.99004059]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99111037 4.99103653]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99199933 4.99193288]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.9927994  4.99273959]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99351946 4.99346563]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99416751 4.99411907]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99475076 4.99470716]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99527569 4.99523645]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99574812 4.9957128 ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.93299323e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99617331 4.99614152]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99655597 4.99652737]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99690038 4.99687463]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99721034 4.99718717]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99748931 4.99746845]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99774037 4.99772161]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99796634 4.99794945]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.9981697  4.9981545 ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99835273 4.99833905]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99851746 4.99850515]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99866571 4.99865463]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99879914 4.99878917]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99891923 4.99891025]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99902731 4.99901923]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99912457 4.9991173 ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99921212 4.99920557]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99929091 4.99928502]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99936182 4.99935651]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99942563 4.99942086]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99948307 4.99947878]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99953476 4.9995309 ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99958129 4.99957781]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.93831282e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99962316 4.99962003]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99966084 4.99965803]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99969476 4.99969222]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.9384703e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99972528 4.999723  ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.93851266e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99975275 4.9997507 ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99977748 4.99977563]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99979973 4.99979807]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99981976 4.99981826]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99983778 4.99983643]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.999854   4.99985279]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.9998686  4.99986751]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99988174 4.99988076]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99989357 4.99989268]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99990421 4.99990342]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99991379 4.99991307]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99992241 4.99992177]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99993017 4.99992959]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99993715 4.99993663]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99994344 4.99994297]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99994909 4.99994867]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.93882326e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99995418 4.9999538 ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99995877 4.99995842]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99996289 4.99996258]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.9388424e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.9999666  4.99996632]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99996994 4.99996969]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.93885219e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99997295 4.99997272]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99997565 4.99997545]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99997809 4.9999779 ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99998028 4.99998011]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99998225 4.9999821 ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99998403 4.99998389]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99998562 4.9999855 ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99998706 4.99998695]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99998835 4.99998826]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99998952 4.99998943]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999057 4.99999049]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999151 4.99999144]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999236 4.9999923 ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999312 4.99999307]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999381 4.99999376]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999443 4.99999438]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999499 4.99999495]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999549 4.99999545]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.93888764e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999594 4.99999591]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999635 4.99999632]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999671 4.99999668]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999704 4.99999702]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999734 4.99999731]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.9999976  4.99999758]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999784 4.99999782]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999806 4.99999804]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999825 4.99999824]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.93889148e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999843 4.99999841]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999858 4.99999857]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999873 4.99999872]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999885 4.99999884]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999897 4.99999896]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999907 4.99999906]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999916 4.99999916]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999925 4.99999924]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999932 4.99999932]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999939 4.99999939]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999945 4.99999945]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.93889314e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999951 4.9999995 ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999956 4.99999955]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.9999996  4.9999996 ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999964 4.99999964]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999968 4.99999967]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999971 4.99999971]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.9388935e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999974 4.99999974]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999976 4.99999976]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999979 4.99999979]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999981 4.99999981]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999983 4.99999983]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999985 4.99999984]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999986 4.99999986]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999987 4.99999987]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.93889373e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999989 4.99999989]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.9999999  4.9999999 ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999991 4.99999991]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999992 4.99999992]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.93889379e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999993 4.99999993]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999993 4.99999993]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.93889381e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999994 4.99999994]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999995 4.99999995]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999995 4.99999995]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999996 4.99999996]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999996 4.99999996]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999996 4.99999996]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999997 4.99999997]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999997 4.99999997]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999997 4.99999997]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999998 4.99999998]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999998 4.99999998]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999998 4.99999998]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999998 4.99999998]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999998 4.99999998]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999999 4.99999999]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999999 4.99999999]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999999 4.99999999]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 6.93889389e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999999 4.99999999]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999999 4.99999999]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999999 4.99999999]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999999 4.99999999]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999999 4.99999999]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999999 4.99999999]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[4.99999999 4.99999999]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.9388939e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.9388939e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.9388939e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.9388939e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.9388939e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.9388939e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.9388939e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.9388939e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.9388939e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.9388939e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.9388939e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.9388939e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.9388939e-17]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "State: 1\n",
      "Nash equilibrium: [[1. 0.]\n",
      " [1. 0.]]\n",
      "Player 1 action: 0\n",
      "Player 2 action: 0\n",
      "Next state: 1\n",
      "Reward: [1 1]\n",
      "QTable: [[[5.         5.        ]\n",
      "  [2.50668544 0.45467766]]\n",
      "\n",
      " [[0.         0.        ]\n",
      "  [2.82903431 2.89866386]]]\n",
      "Expected reward: [1.0062 1.0036]\n",
      "QTable: [[[[3.18995858 1.78440667]\n",
      "   [0.         0.        ]]\n",
      "\n",
      "  [[0.         0.        ]\n",
      "   [0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[5.         5.        ]\n",
      "   [2.50668544 0.45467766]]\n",
      "\n",
      "  [[0.         0.        ]\n",
      "   [2.82903431 2.89866386]]]\n",
      "\n",
      "\n",
      " [[[0.         0.        ]\n",
      "   [0.         1.        ]]\n",
      "\n",
      "  [[4.31399618 4.3981972 ]\n",
      "   [0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.        ]\n",
      "   [0.4        0.2       ]]\n",
      "\n",
      "  [[0.         0.        ]\n",
      "   [5.91896926 4.77993315]]]]\n"
     ]
    }
   ],
   "source": [
    "#Simulate plays with nash policy\n",
    "ALPHA = 0.5\n",
    "GAMMA = 0.8\n",
    "EPSILON = 0.1\n",
    "\n",
    "qTable = np.zeros((Q, A, A, N))\n",
    "\n",
    "state = 0\n",
    "totalReward = np.array([0, 0])\n",
    "for _ in range(n_games):\n",
    "    print(\"State:\", state)\n",
    "    nashEq = np.abs(computeNashEq(state, qTable))\n",
    "    print(\"Nash equilibrium:\", nashEq)\n",
    "    player1_action = np.random.choice(A, p=nashEq[0]) if np.random.rand() > EPSILON else np.random.choice(A)\n",
    "    player2_action = np.random.choice(A, p=nashEq[1]) if np.random.rand() > EPSILON else np.random.choice(A)\n",
    "    print(\"Player 1 action:\", player1_action)\n",
    "    print(\"Player 2 action:\", player2_action)\n",
    "    next_state = np.random.choice(range(Q), p=TRANSITION_MATRIX[player1_action, player2_action, state])\n",
    "    print(\"Next state:\", next_state)\n",
    "    r = reward(state, player1_action, player2_action)\n",
    "    print(\"Reward:\", r)\n",
    "\n",
    "    next_NashEq = computeNashEq(next_state, qTable)\n",
    "    next_qVal_0 = expectedPayoff(qTable[next_state, :, :, 0], next_NashEq[0], next_NashEq[1])\n",
    "    next_qVal_1 = expectedPayoff(qTable[next_state, :, :, 1], next_NashEq[0], next_NashEq[1])\n",
    "    qTable[state, player1_action, player2_action, 0] = (1 - ALPHA) * qTable[state, player1_action, player2_action, 0] + ALPHA * (r[0] + GAMMA * next_qVal_0)\n",
    "    qTable[state, player1_action, player2_action, 1] = (1 - ALPHA) * qTable[state, player1_action, player2_action, 1] + ALPHA * (r[1] + GAMMA * next_qVal_1)\n",
    "\n",
    "    print(\"QTable:\", qTable[state])\n",
    "    state = next_state\n",
    "    totalReward += r\n",
    "print(\"Expected reward:\", totalReward/n_games)\n",
    "print(\"QTable:\", qTable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
