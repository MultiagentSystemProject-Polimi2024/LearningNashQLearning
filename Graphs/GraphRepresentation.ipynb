{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes for state representation in multiagent MDP with Nash games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MC(states, transitions) -> Markov Chain\n",
    "A Markov Chain is composed by a set of states and a set of transitions\n",
    "    states is a list of State objects\n",
    "    transitions is a dictionary where the keys are the states and the values are dictionaries\n",
    "    where the keys are the actions and the values are the couples (next_state, probability)\n",
    "\n",
    "e.g. transitions = {state_1: {action_1: (state_2, prob_1.2), action_2: (state_3, prob_1.3)}, state_2: {action_1: (state_3, prob_2.3), action_3: (state_2, prob_2.2)}, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MC:   \n",
    "    def __init__(self, states, transitions):\n",
    "        self.states = states\n",
    "        self.transitions = transitions\n",
    "\n",
    "    def possible_actions(self, state):\n",
    "        return self.transitions[state].keys()\n",
    "    \n",
    "    def get_states(self):\n",
    "        return self.states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State(name, reward) -> State\n",
    "every state of the Markov's chain is composed by a Nash game\n",
    "    name is the name of the state\n",
    "    reward is a dictionary where the keys are the tuples expressing the combination of actions \n",
    "    of the game and the values are the tuples expressing the reward for each player\n",
    "\n",
    "e.g. reward = {(action_1.a, action_1.b): {(reward_a, reward_b)}, (action_2.a, action): {(reward_a, reward_b)}, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "\n",
    "    def __init__(self, name, reward):\n",
    "        self.name = name\n",
    "        self.reward = reward\n",
    "    \n",
    "    def nashEquilibrium():\n",
    "        \"to be completed\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph representation for the state space using NetworkX library (https://networkx.org/documentation/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each state, we create an edge from the state to each state reached by one of the actions aviable in the initial state.\n",
    "The nodes are created automatically.\n",
    "Then the edge is given two attributes: the action that allows the transition from the first to the second state, accessible by the key 'action', and the probability of the transition, with keyword 'probability'\n",
    "The state object used as node already contains the name of the state and its reward, so it doesn't need any attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_1 = State(\"1\", 0.5)\n",
    "state_2 = State(\"2\", 0.9)\n",
    "state_3 = State(\"3\", -1)\n",
    "states = [state_1, state_2, state_3]\n",
    "actions = [\"action_1\", \"action_2\", \"action_3\"]\n",
    "transitions = {state_1: {actions[0]: (state_2, 0.7), actions[1]: (state_3, 0.9)}, state_2: {actions[0]: (state_3, 1), actions[2]: (state_2, 0.3)}, state_3: {actions[1]: (state_1, 0.9), actions[2]: (state_2, 0.5)}}\n",
    "M = MC(states, transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "for s in M.get_states():\n",
    "    for a in transitions[s]:\n",
    "        s_next = transitions[s][a][0]\n",
    "        G.add_edge(s.name, s_next.name)\n",
    "        G.edges[s.name, s_next.name]['action'] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n"
     ]
    }
   ],
   "source": [
    "print(nx.adjacency_matrix(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \"with_labels=True\" prints on the node the toString() value of the node. Knowing this, the state need to be inserted in the graph with their name and not with their State object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutEdgeView([('1', '2'), ('1', '3'), ('2', '3'), ('2', '2'), ('3', '1'), ('3', '2')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'circle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-2.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#X21sdW50aXRsZWQ%3D?line=0'>1</a>\u001b[0m options \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mnode_color\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnode_size\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1000\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m3\u001b[39m}\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#X21sdW50aXRsZWQ%3D?line=1'>2</a>\u001b[0m nx\u001b[39m.\u001b[39mdraw_networkx_edge_labels(G, pos\u001b[39m=\u001b[39mcircle)\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#X21sdW50aXRsZWQ%3D?line=2'>3</a>\u001b[0m \u001b[39m#nx.draw(G, pos **options, labels = {node: node.name for node in G.nodes()})\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#X21sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'circle' is not defined"
     ]
    }
   ],
   "source": [
    "options = {'node_color': 'green', 'node_size': 1000, 'width': 3}\n",
    "nx.draw_networkx_edge_labels(G, pos=circle)\n",
    "#nx.draw(G, pos **options, labels = {node: node.name for node in G.nodes()})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
